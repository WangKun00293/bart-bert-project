{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WangKun00293/bart-bert-project/blob/main/BART_generate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "761f18d711b44d329a1caafa0b872c7d",
            "bd4cf63efec94473b041d9c7edad214c",
            "85cbd1584a9d42af95a83f385871a1a4",
            "c3767516a9364777b8cee836f5e2f8af",
            "935349d2607c41dfa39327e712a4912f",
            "8aeadd11d8814ec8bce35a44b178bd73",
            "4640460d5c96434c9f7771758b81ab6d",
            "4ea46b2c9984448e92986879abdfb42b",
            "72170cdd6c1641809f1e63736c31cb93",
            "add03508372b4b91bd17d2fb28856d6e",
            "58e8df7c292d4fe68402ab7afd63d870",
            "9122452013c64672a93fb1000a7e9e36",
            "9367998ad8f24c8bbf2b8d417dbe70c1",
            "b52ef5ddd5894e8781b73156973047c5",
            "f17c45946d71461da8ef46b92edbfe5a",
            "aab0a219037c4bb296ccfaf1a669b3da",
            "141501418f4a4cdebc4eb653d9295325",
            "43f3eff6d858456bb1d79f88117d37df",
            "d96bf1ae6ca74356b73ed8e0ed371c9f",
            "9a4f514a72874a5281fec6015dc8ba66",
            "7aa374e3de514b68b246319561262e67",
            "e99fdc3971474412ae37cab66b606fc9",
            "05c63c13a9414d4e84931f7dcff1adb7",
            "66afba8f4681433fb2e5b41101693edc",
            "2a5c79f04dc6414fa2ce943db27c4cea",
            "f2b705dffecc4322aea851ca163bd09e",
            "b4bd09cdf9534dd392320723cc8bf136",
            "a270f291fcce451fabd95dd1c3d0a086",
            "af9d306cd298457f83d99ee226eb7853",
            "92a66cc723384aa190732ab4366a331b",
            "a98a3132bb7e4b24bf03af6c95862288",
            "1c64486ba02c443c8adc1423e548f536",
            "7eff27766be846248763a9087f460040",
            "37ff07d2c46246abb87a9a4536d64de9",
            "156b16fcf60a41c39217cd040a574ef0",
            "9e882ba570974e9485c2170e9cf370e4",
            "1161fc6e31244a30a483c3702e9e67b6",
            "5de974b94bc242b9a94c5146aeb4ac19",
            "8b4b47a290bb487bb645d57c4037e01c",
            "6ee1cb1dc4374f9d948a0117ffa136d3",
            "b7c7b539361c45adb56f4803d4ca25ed",
            "35a09ee026a849fa8e1c5760e58e1b67",
            "12439567a3a3426b90d049ccf4f52abc",
            "ee84cfce172745b89e15d25118564331",
            "1e237ac8698f4fa89901ae00cd4f36ea",
            "a7e0ae59b6444b54871c3e8781693701",
            "5db3867762d146f28d9b995c8e3d1ba2",
            "5df94a1c4ad24cd4a3ac4b8108c83b67",
            "080b47772ba745919ef5f1bfd42697eb",
            "234936c7064c48f4b3e248b1fdb05423",
            "358f3bea4abb4b2fa9689eba241512c9",
            "a9a3b49fdb8c4778a0c1a125d7a9f320",
            "32ef10298f4f4f9185e52d680f406121",
            "f7ef86b8c72c40cc97dd75beab1aa1fe",
            "9dba8b8361af472282ce199008a0e06c"
          ]
        },
        "collapsed": true,
        "id": "6VPjsAg_29N_",
        "outputId": "b25eb0ae-087f-4f55-dbab-ea5768bf4566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 fsspec-2024.5.0 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.4.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "761f18d711b44d329a1caafa0b872c7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9122452013c64672a93fb1000a7e9e36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05c63c13a9414d4e84931f7dcff1adb7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37ff07d2c46246abb87a9a4536d64de9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e237ac8698f4fa89901ae00cd4f36ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "ag_news = load_dataset(\"ag_news\")\n",
        "## load dataset\n",
        "import pandas as pd\n",
        "train=ag_news[\"train\"].to_pandas()\n",
        "test=ag_news[\"test\"].to_pandas()\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_2=train[train[\"label\"]==2].sample(n=2000, random_state=13)\n",
        "train_3=train[train[\"label\"]==3].sample(n=2000, random_state=13)\n",
        "df_train=pd.concat([train_2,train_3]).sample(frac=1, random_state=13).reset_index(drop=True)\n",
        "\n",
        "test_2=test[test[\"label\"]==2].sample(n=1000, random_state=13)\n",
        "test_3=test[test[\"label\"]==3].sample(n=1000, random_state=13)\n",
        "test_set=pd.concat([test_2,test_3]).sample(frac=1, random_state=13).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz2kfchJ3JFh",
        "outputId": "0fb5ee83-9e8f-47c2-c957-c34eff6116f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7uVlScsKykI"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
        "    text = re.sub(r'[&\\\\@#\\$%\\^*()_+={}\\[\\]:;\"\\'<>\\|`~]', '', text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkFcbPsgK25m"
      },
      "outputs": [],
      "source": [
        "df_train['text'] = df_train['text'].apply(clean_text)\n",
        "test_set['text'] = test_set['text'].apply(clean_text)\n",
        "\n",
        "df_train['label'] = df_train['label'].replace({2: 0, 3: 1})\n",
        "test_set['label'] = test_set['label'].replace({2: 0, 3: 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqUV5LMBLXHQ"
      },
      "outputs": [],
      "source": [
        "label_map = {0: \"Write a Business News\", 1: \"Write a Science/Technology News\"}\n",
        "# label_map2 = {\"Write a Business News\":0, \"Write a Science/Technology News\":1}\n",
        "df_train['prompt'] = df_train['label'].map(label_map)\n",
        "test_set['prompt'] = test_set['label'].map(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "jls8IyV035D4",
        "outputId": "883ffb78-b606-463a-ee20-6d491f24437f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 4000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4000,\n        \"samples\": [\n          \"2 Companies Get Contracts to Protect Jets Teams led by BAE Systems and the Northrop Grumman Corporation were chosen Wednesday to build and test prototypes for antimissile systems to defend commercial planes against shoulder-fired rockets.\",\n          \"Japans Mitsubishi Electric to focus on small LCDs due to competition AFP AFP - Japans Mitsubishi Electric Corp. said that it plans to wind down production of large-size liquid crystal display LCD panels to focus on smaller panels because of price competition.\",\n          \"Bit Bytes  Halo 2 At gaming stores, lines went through doors as people arrived at midnight to get the first copies. Halo 2 was definitely worth the wait.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Write a Science/Technology News\",\n          \"Write a Business News\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-11ee1ec3-fd89-451a-a265-7d2fba9e16b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oil prices hit lowest level in 7 weeks Crude o...</td>\n",
              "      <td>0</td>\n",
              "      <td>Write a Business News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FCC frees VoIP service from state regulations ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Human gland evolved from gills The human parat...</td>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A bargain hunters paradise Massachusetts barga...</td>\n",
              "      <td>0</td>\n",
              "      <td>Write a Business News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Walking in the Void of Space NASA -- Venturing...</td>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>Hollywoods Lion Kings All the morning headline...</td>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>Carriers, handset makers vie for interface con...</td>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>Wal-Mart Clouds November Retail Investors floc...</td>\n",
              "      <td>0</td>\n",
              "      <td>Write a Business News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>Cisco warns of IOS flaw Cisco Systems Inc. war...</td>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>OPEC May Decide Oil Price Target in Sept. OPEC...</td>\n",
              "      <td>0</td>\n",
              "      <td>Write a Business News</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11ee1ec3-fd89-451a-a265-7d2fba9e16b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11ee1ec3-fd89-451a-a265-7d2fba9e16b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11ee1ec3-fd89-451a-a265-7d2fba9e16b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b06192e-48b0-48e0-a272-db2f2e12c95a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b06192e-48b0-48e0-a272-db2f2e12c95a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b06192e-48b0-48e0-a272-db2f2e12c95a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6b891e20-3fce-4a04-8a59-99fe4f35d752\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6b891e20-3fce-4a04-8a59-99fe4f35d752 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                   text  label  \\\n",
              "0     Oil prices hit lowest level in 7 weeks Crude o...      0   \n",
              "1     FCC frees VoIP service from state regulations ...      1   \n",
              "2     Human gland evolved from gills The human parat...      1   \n",
              "3     A bargain hunters paradise Massachusetts barga...      0   \n",
              "4     Walking in the Void of Space NASA -- Venturing...      1   \n",
              "...                                                 ...    ...   \n",
              "3995  Hollywoods Lion Kings All the morning headline...      1   \n",
              "3996  Carriers, handset makers vie for interface con...      1   \n",
              "3997  Wal-Mart Clouds November Retail Investors floc...      0   \n",
              "3998  Cisco warns of IOS flaw Cisco Systems Inc. war...      1   \n",
              "3999  OPEC May Decide Oil Price Target in Sept. OPEC...      0   \n",
              "\n",
              "                               prompt  \n",
              "0               Write a Business News  \n",
              "1     Write a Science/Technology News  \n",
              "2     Write a Science/Technology News  \n",
              "3               Write a Business News  \n",
              "4     Write a Science/Technology News  \n",
              "...                               ...  \n",
              "3995  Write a Science/Technology News  \n",
              "3996  Write a Science/Technology News  \n",
              "3997            Write a Business News  \n",
              "3998  Write a Science/Technology News  \n",
              "3999            Write a Business News  \n",
              "\n",
              "[4000 rows x 3 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-E4kknUXL2D"
      },
      "source": [
        "## BART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2VKS6vUXL2D"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenizer, df, max_length=512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.inputs = df['prompt']\n",
        "        self.targets = df['text']\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.inputs[idx]\n",
        "        target_text = self.targets[idx]\n",
        "\n",
        "        # Tokenize input and target text\n",
        "        input_encoding = self.tokenizer(input_text, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
        "        target_encoding = self.tokenizer(target_text, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
        "\n",
        "        return {'input_ids': input_encoding['input_ids'].flatten(),\n",
        "                'attention_mask': input_encoding['attention_mask'].flatten(),\n",
        "                'labels': target_encoding['input_ids'].flatten()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo3Ezo3GXL2D"
      },
      "outputs": [],
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmzWCtkPTgCT"
      },
      "outputs": [],
      "source": [
        "train1 = df_train[df_train['label']==1].reset_index(drop=True)\n",
        "test1 = test_set[test_set['label']==1].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3kJ-MlP7Thuh",
        "outputId": "d5b1ddf3-b0d6-47ff-c830-73995060a3ee"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 4000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4000,\n        \"samples\": [\n          \"2 Companies Get Contracts to Protect Jets Teams led by BAE Systems and the Northrop Grumman Corporation were chosen Wednesday to build and test prototypes for antimissile systems to defend commercial planes against shoulder-fired rockets.\",\n          \"Japans Mitsubishi Electric to focus on small LCDs due to competition AFP AFP - Japans Mitsubishi Electric Corp. said that it plans to wind down production of large-size liquid crystal display LCD panels to focus on smaller panels because of price competition.\",\n          \"Bit Bytes  Halo 2 At gaming stores, lines went through doors as people arrived at midnight to get the first copies. Halo 2 was definitely worth the wait.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Write a Science/Technology News\",\n          \"Write a Business News\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c67e9122-1312-418a-8cab-800641f88114\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oil prices hit lowest level in 7 weeks Crude o...</td>\n",
              "      <td>0</td>\n",
              "      <td>Write a Business News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FCC frees VoIP service from state regulations ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Human gland evolved from gills The human parat...</td>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A bargain hunters paradise Massachusetts barga...</td>\n",
              "      <td>0</td>\n",
              "      <td>Write a Business News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Walking in the Void of Space NASA -- Venturing...</td>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>Hollywoods Lion Kings All the morning headline...</td>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>Carriers, handset makers vie for interface con...</td>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>Wal-Mart Clouds November Retail Investors floc...</td>\n",
              "      <td>0</td>\n",
              "      <td>Write a Business News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>Cisco warns of IOS flaw Cisco Systems Inc. war...</td>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>OPEC May Decide Oil Price Target in Sept. OPEC...</td>\n",
              "      <td>0</td>\n",
              "      <td>Write a Business News</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c67e9122-1312-418a-8cab-800641f88114')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c67e9122-1312-418a-8cab-800641f88114 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c67e9122-1312-418a-8cab-800641f88114');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f11aab65-8afb-41b6-88cd-79aaf70297e6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f11aab65-8afb-41b6-88cd-79aaf70297e6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f11aab65-8afb-41b6-88cd-79aaf70297e6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d434405d-ca80-4ebb-831e-55c5c191c786\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d434405d-ca80-4ebb-831e-55c5c191c786 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                   text  label  \\\n",
              "0     Oil prices hit lowest level in 7 weeks Crude o...      0   \n",
              "1     FCC frees VoIP service from state regulations ...      1   \n",
              "2     Human gland evolved from gills The human parat...      1   \n",
              "3     A bargain hunters paradise Massachusetts barga...      0   \n",
              "4     Walking in the Void of Space NASA -- Venturing...      1   \n",
              "...                                                 ...    ...   \n",
              "3995  Hollywoods Lion Kings All the morning headline...      1   \n",
              "3996  Carriers, handset makers vie for interface con...      1   \n",
              "3997  Wal-Mart Clouds November Retail Investors floc...      0   \n",
              "3998  Cisco warns of IOS flaw Cisco Systems Inc. war...      1   \n",
              "3999  OPEC May Decide Oil Price Target in Sept. OPEC...      0   \n",
              "\n",
              "                               prompt  \n",
              "0               Write a Business News  \n",
              "1     Write a Science/Technology News  \n",
              "2     Write a Science/Technology News  \n",
              "3               Write a Business News  \n",
              "4     Write a Science/Technology News  \n",
              "...                               ...  \n",
              "3995  Write a Science/Technology News  \n",
              "3996  Write a Science/Technology News  \n",
              "3997            Write a Business News  \n",
              "3998  Write a Science/Technology News  \n",
              "3999            Write a Business News  \n",
              "\n",
              "[4000 rows x 3 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Giohe9DXL2E"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataset = TextDataset(tokenizer, train1,max_length=320)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16)\n",
        "val_dataset = TextDataset(tokenizer, test1,max_length=320)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjbTdCE0v4Yw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def generate_text_with_beams(prompt, num_texts=5, temperature=1.0, top_k=50, top_p=0.95, min_length=50, max_length=320, num_beams=5, no_repeat_ngram_size=2, early_stopping=True, seed=42, repetition_penalty=1.5):\n",
        "    if seed is not None:\n",
        "        set_seeds(seed)\n",
        "    model.eval()\n",
        "    generated_texts = []\n",
        "    for _ in range(num_texts):\n",
        "        # Encode the prompt to generate input_ids and attention_mask\n",
        "        encoding = tokenizer(prompt, return_tensors='pt', padding='max_length', max_length=max_length, truncation=True)\n",
        "        input_ids = encoding['input_ids'].to(model.device)\n",
        "        attention_mask = encoding['attention_mask'].to(model.device)\n",
        "\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,  # Include attention mask in generation\n",
        "            min_length=min_length,\n",
        "            max_length=max_length,\n",
        "            num_beams=num_beams,\n",
        "            num_return_sequences=1,  # Generate one sequence at a time to ensure diversity\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "            repetition_penalty=repetition_penalty,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            early_stopping=early_stopping\n",
        "        )\n",
        "\n",
        "        text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        generated_texts.append(text)\n",
        "\n",
        "    return generated_texts\n",
        "\n",
        "def generate_text(top_p, top_k, temperature, num_beams=5, num_texts=20, seed=42, repetition_penalty=1.2):\n",
        "    prompts = [\"Write a Science/Technology News\"]\n",
        "    all_prompts = []\n",
        "    all_texts = []\n",
        "\n",
        "    for prompt in prompts:\n",
        "        generated_texts_for_prompt = []\n",
        "        num_iterations = num_texts // num_beams\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "            set_seeds(seed + i)\n",
        "            generated_texts = generate_text_with_beams(\n",
        "                prompt=prompt,\n",
        "                num_texts=num_beams,\n",
        "                temperature=temperature,\n",
        "                top_k=top_k,\n",
        "                top_p=top_p,\n",
        "                min_length=50,\n",
        "                max_length=200,  # Adjust max_length as needed\n",
        "                num_beams=num_beams,\n",
        "                no_repeat_ngram_size=2,\n",
        "                early_stopping=True,  # Enable early stopping\n",
        "                seed=seed + i,  # Adjust seed for each batch to maintain diversity while being reproducible\n",
        "                repetition_penalty=repetition_penalty  # Adding repetition penalty\n",
        "            )\n",
        "            generated_texts_for_prompt.extend(generated_texts)\n",
        "\n",
        "        # Ensure uniqueness and limit to the desired number of texts\n",
        "        unique_texts = list(set(generated_texts_for_prompt))[:num_texts]\n",
        "        all_prompts.extend([prompt] * len(unique_texts))\n",
        "        all_texts.extend(unique_texts)\n",
        "\n",
        "    return pd.DataFrame({'prompt': all_prompts, 'text': all_texts})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Mj6Jnt0wA6-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from scipy.linalg import sqrtm\n",
        "import pandas as pd\n",
        "\n",
        "# Load BERT model and tokenizer\n",
        "bert_tokenizer_base = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model_base = BertModel.from_pretrained('bert-base-uncased')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model_base.to(device)\n",
        "# Function to get embeddings\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        inputs = bert_tokenizer_base(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=320)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = bert_model_base(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "        all_embeddings.append(embeddings.cpu().numpy())\n",
        "        torch.cuda.empty_cache()  # Clear unused memory\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Function to calculate mean and covariance\n",
        "def calculate_mean_covariance(embeddings):\n",
        "    mu = np.mean(embeddings, axis=0)\n",
        "    sigma = np.cov(embeddings, rowvar=False)\n",
        "    return mu, sigma\n",
        "\n",
        "# Function to compute Fréchet Distance\n",
        "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2):\n",
        "    diff = mu1 - mu2\n",
        "    covmean, _ = sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "    return np.sum(diff**2) + np.trace(sigma1 + sigma2 - 2*covmean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_oBwlgPwKXk"
      },
      "outputs": [],
      "source": [
        "df_original = df_train[df_train['label']==1].sample(n=200, random_state=13)\n",
        "original_texts = df_original['text'].tolist()\n",
        "original_embeddings = get_embeddings(original_texts)\n",
        "mu_orig, sigma_orig = calculate_mean_covariance(original_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "965e7943bc3a4f23b026ab7aa8f64c70",
            "8d1d8b217eb347afa42143847aed05b9",
            "b06929cbb4cf41e2bf3667b549ef8b8e",
            "d148ea63aa064758a46a5e95b7298c6b",
            "62d7d709790547e48cab9ddbdd2b8c31",
            "be5cbd516a044ae586d29decded20858",
            "3d70416124a84a6fb66a06af78ae50ce",
            "c9070f75c0a744019c7e353386327359",
            "6d39901a44a54390a2bdb285ef92cbbd",
            "dea527f0f0034367bdce013fe64518fa",
            "04879d38f54345cabd60c79829c0eba2",
            "de469265f88b49969cadabf54a5de347",
            "8c2b3e3600b44b0d86afe8f47d311391",
            "9efa490f6e524eeea71591267efc043f",
            "694ec704c08243e0b87759743bc6c240",
            "e9bd906b7be743599f636a61a4713c25",
            "82e2ffa24e804ec386ea906ece361eb1",
            "b85536ad97524c53b0fd5767c668b74b",
            "9d0e65fd12934bfdb354f4271a32f349",
            "09eee5d0a6fc4712a110936b5bf4c602",
            "5ac55a6e00544fd1bc959382c249e954",
            "ed879db3ed54456ab5e8775efa1c3622",
            "1ef5a35a7e48450283e9f7a722d262cc",
            "3effd805319448aa9c39199688cf9f56",
            "daaef582ee694e50b688f07b00197a69",
            "ef6964a6b13045abaa908c6eb6422e8c",
            "8ad4dfd0a9e3485dba95a1c4aa08ae8f",
            "dc4cccb3a57d4889916ad57defd06fad",
            "60b2a12682d7452185f6274199453298",
            "d9482f584bae4f578f4dbf10c443af23",
            "ab6f867497c34b48826c62dc9e6b05c5",
            "4f983f2230604e6485e221c2354ab8db",
            "2a8286b3857f4c9aa3157f4671908182",
            "a504ae481bbb457895f8fcb2cd7b0cab",
            "b600e775939a46778aed5c59b69d7457",
            "53f9754d15a343a081adecb5e98987d7",
            "4491a484420d46969a5b7315e340cd7e",
            "3a2556e9912f4446817ac19c5463eb39",
            "691d349f7a3b48c380216446ac3b208e",
            "f44d9c9fb27149f2a8127e1a3118b83a",
            "651dd80cde494caeb4567606cf483a90",
            "86fa510d2dbe436c8a612c37bd562b60",
            "c9a8dafaea284384809576bb39d09b6f",
            "cc5c9e53e58841588490708730d896bc",
            "d7b79d67b605469d85e5123811f6b4ca",
            "229dd07d4ce84a2ea2b14065bcefa4e4",
            "07eab06b5be149fca2454c2a27db664b",
            "394a79fd44d74220962713ad8081df70",
            "072090e6558640839b0b90186bf90891",
            "0620d665bc524893a45e75cd2d3f3303",
            "4863a4adbd5a42b5a9b8f3b18e377b81",
            "8d9cc78bd6314e2e997e58a3083659d6",
            "9aeb4fad43ba498ca694b2e3f784b8eb",
            "e7c181608c7b41a1b998912d85d77517",
            "5fd8e78618c441acb670a7825af40a71",
            "0361f7dafa2f4783a473ea76d732d647",
            "359986ac7f5e4b9c9a36005daf85a437",
            "f1db911ee1ff4e799e71775bd7c27048",
            "ab39a84f8c194e2493e5ad7818e30c99",
            "d98acb9554564223ae9fecb25daa56e2",
            "230655e997314c629a5975442b7d0af1",
            "66de47d7d0014d2dbac1c865136ea37f",
            "17d165feaa9f4d6d8029385021327145",
            "780ba1e00fc04c4d96c1c3d72afb9bac",
            "c966efc191634de2a6e50d8a44c73218",
            "30900e857aaa4fdab3a9009dadb4fbfd",
            "a011297b0f64403a89d0010ac249186e",
            "a2e207fde76049feb6233c367353115a",
            "19066cc964b844f6ae0723d1b34f65c1",
            "3790e254cf69419ea995b0f72a120274",
            "ed7ef226c9f5488faf615ea2553d36d4",
            "88a53771ef634327b9c34599d9425891",
            "5c85d32632144a90919612a44ecc0ad6",
            "7654392aed63450abf382225d11c640f",
            "771549f5cf5a441eb558d94bdfa90372",
            "cd19d63ce510410e9f9143fa88b90742",
            "86d28a9b29c847769ee3ef7e6ae93c5e",
            "c4efe2d121284b13b30c2bbb736a64a6",
            "725a3caf66c64a3d913c427fb4776990",
            "2e974dabbb554bbba65fe349ea754304",
            "36901e7e137d4cf49b2d6dd3f2bd3208",
            "f681bca2f7894f8987e1e5ba1e6ee76a",
            "2a09fd9ac21d49ebb0f26ce61d08b509",
            "489691e78cf44a3aaf776727665bab12",
            "8c05e305b7ac4b2f92f6c2fe4043eab6",
            "d5a781fba01d450d87a9041cee5efa2b",
            "8a14e5845e2c4a1fb299acaaf9cd1e39",
            "f10a36d5c00f4ea59723b6237b2e63d0",
            "501a22b845c947299ff1a46768e20fef",
            "c8f1dac253934ff38d47c19d70b4ac72",
            "328b2b816ca741ab9116d11a3813d18f",
            "665a33d3de3e4302a28357f18ee23926",
            "b3dfc607f3414cb481b2f29493f65467",
            "9de15977a8364f2c90ce1bee7fa78ce4",
            "2544bca8b3174ee6b5d9b15ebf63dc72",
            "bed257ce2e194e1ebeaf63f9f00ddbf1",
            "76404ee57b274cc4a2002458d95253ca",
            "f31e29c0409a43f2a2cab1dbe439545b",
            "5c8ac31fe8a74354872d486a5d09780f",
            "719d8856f1da487e9de1b9ab93436e0f",
            "d4194478e6b34da1aee8cc237d3988ca",
            "a0319db053f649e7b1cf5a365e10e558",
            "15f43566654d4d74a558a994687a36a4",
            "f7ef5177bf61448b84eb7231d8f82692",
            "420ad1e42c1b42d4993716c710747f7d",
            "47ef47297ed94bf2b97d47f0bee7133a",
            "343154cf0b4b4145aff680c25da6626b",
            "b80574082ef5482e9d06c541c8700ebb",
            "a35e25b9cbb74503be36600dc8a74cc5",
            "15013eac87154beeac2815365dca477f",
            "8abf39c052364650b7c1ec36cdd8240d",
            "15385ca3a9ee46c29152730e9dac9ea8",
            "2fe018d0a62148189a366b04c862c609",
            "45071b742bbd437aa184bafb33bbd8df",
            "0585f40adb86401381122157c58f2ed0",
            "943223873f8e4be3a387a774aa79ed48",
            "ce1efd1210614a86a151473dd3dbae5a",
            "5fd8ed07d614428695c7e2b829704e15",
            "54480e55a96b419db962487d7ee72281",
            "ea3a6615fe954727bfbc0ef4ac542950",
            "c86e06bdd1ed4c50b384bc054f91871a",
            "058eadb794aa4c76b4d31584ae4efbb0",
            "3a330eeca25a4633a6221f320578a71b",
            "4dcf67356583469cae38a5cf901ad037",
            "d7fb9a305f354ff4abfb8984a32ff346",
            "a15578569f704d34aae98004d98704a9",
            "0034307043e54dc2bfac32b4d827170a",
            "840bbfd1c01248bf814f71ba6fe1e14d",
            "64f410ad63fc4c81ae63570750273c81",
            "f9c9fbdfd71f4b1fa120f3dcfa1f8829",
            "bd597fc7822e4fe0b7ddc92d93c89143",
            "3f70af4926944f4ca3367d9e3753c2d5",
            "82fbd7363cdd4f6687f6d4213a803d7d",
            "b771cb2b1cf24d92b05ae0c887a58095",
            "708d20779a904a2d82bf74fcd36f4cbb",
            "8b656123e6e343228a03a945672382b3",
            "97648ed5d7124012b83df73404d07ecf",
            "b278a386f652479cbe31182034b35ba8",
            "a43972bc4cc5413e9da8313329ef8855",
            "c37839d4b2d14b7a9b06607ebe76ceaa",
            "2ae456bd76e345f0a1ef190b9489fbfa",
            "10c8eeaadc024feab90eb4556b7d271d",
            "4853249065b54ebfbd4037a4fa5cb1b4",
            "5f709a2009bb48a4a65c0505db0ce0c9",
            "afa1a76697304d53a55c7c0a0ce1fb64",
            "c2f693763a99488e80950f7bf64fbfcc",
            "96d58c00a1df4dcaa471b63b05fe2f2c",
            "1c1451ad1fb748e5ba6f4f0f415e0e2f",
            "4fbf8ddb68034755b504843dd1e68b7e",
            "de361718ffb14a44b22c572a3ad9c7dd",
            "753b3cce639a4f409b8895624cc7a56c",
            "e4b7fc74172c474b8a878f8b8e3cad5c",
            "8fb35197d6554cf39e25e4265b2ccd7b",
            "f3526bafd7b64fc5b84fcd62f3b77dac",
            "5a2197442bbd4afd82a8ca7a62f7355a",
            "802f9034e17649e880deef91bb7f0510",
            "bb382fd6c7e44842b3468d75e6a74b1c",
            "d002a65676c349d0b2315e21c555dcf4",
            "83136484902b407d90b94162e93b1e9d",
            "4ffe52bd2c2d4ee39edfd308135dc718",
            "a930cfe422b4483391d36aacb5a4d55a",
            "e638417b2fbc4d28aac2007ecd8cc4a4",
            "5cf100f05f4849c5a4924464992c1beb",
            "804f8fee984d4a3d8ee6a79cb8e5bc37",
            "8f777bb96be94b56921bb7e0477cd8a5",
            "991a0eeaa6ae49c781037f0f4c9c24ed",
            "a50c59f44a2648e8866ae5e5d8c1c618",
            "706be66ee8fa4b3a92ca05faf81629af",
            "b19652fc9802453691c466957ba3a0d8",
            "35726b283c5c47ec8d2a5397c1d928e3",
            "5e5e74ba7f404ce499102782ad0f0486",
            "cf903969fe6a42a5bec0ca945a98a8d0",
            "eb40ce79789d4959bcaf1f0bb06c25de",
            "65a0ac07ac3f4f3080708c6e8f690651",
            "3b2652d6d2ea4975af1edb8c78c1d100",
            "3989dd99d258454fb30d9f3fdd539e67",
            "025615140bea4f4d8feec596e3c0264f",
            "7da87fcdce7e43b1b8100c869a96fa6e",
            "c83d19e90ff742f197bc632457c82182",
            "009e05fa4fca4a2bbfda4da90ec82dcd",
            "8b2d5f3503944a26a9b45bdc9494145c",
            "518f22ce28f24b3b917f8c3f8fc92124",
            "242ba65332d64ff9a2cbac10c58aae20",
            "a7393482795545cf894831838f553042",
            "07abf640a6854c6b840597fe20639148",
            "9891fc28e159413c87751539b88b33e9",
            "584acf1662cf42ae96c94296a465417b",
            "f016f06e9859466fb7fbebf3ddd96bc3",
            "dd4dbd0009634672b9aa7d54b5176cd5",
            "3cfc61e9d233454cba4ae3f90f44757f",
            "e9917949c08348c38916acf43c155ef0",
            "b13560dcaa1c43a4b80f7af3fa87e7a6",
            "774ceb1b73514de49931ffab24063adf",
            "aa705c70b40e4389845677a4393a62df",
            "a0e550bb3a794f38b80a3b6535b90b4d",
            "0d3f3d7f35714a76bc960e49bfd373c3",
            "d1f27cc40a5d491faefd30760ad6b477",
            "a33684a325e3454eb9260527c5773907",
            "a26d31972e5042f5a3846a5dc9d04fda",
            "b018449019574f37956bbfc61013c0d6",
            "b2df2dc370f84568bda0ed7465cf1145",
            "1dcc1f3aa0b54d45a91093bd23349df6",
            "3bc909d207b3481e89787f2eef270800",
            "66a635baf6824ad3bd32f5cc968c53c1",
            "a1e72de9241e4b03b5e8a0da38b50c27",
            "f543c8b541744cb4a744d0f2c60a3a51",
            "a74cc1d283a4431badfbde88c0917647",
            "dab9e311ec4a46fba3c7f7951dbc7858",
            "04594390da254e0ba6ec4b8bc761336b",
            "df786630c7f74138858c81d752c90b6c",
            "ade45075677a453b9f774a8eee0a7f9e",
            "15989b48a098448893b8d710837ef58c",
            "f8ef150757d943b99134e26ccf523ebf",
            "c525fa22d67e4d6e913a04f4e6eea5d8",
            "05b513be815e4911aef4e73de3791a3b",
            "34959a38006b4184989464ce27af9863",
            "e708e20d17a749bc89e93b3aa959be6a",
            "b490d62a596a431690231929456afefe",
            "009bb41488dc46c9bafaab17497444ca",
            "42a7dfbba175451b90f6eddac201eaea",
            "f80f06b949614880be5a65f22c378812",
            "7bcd52b37db74635b481550bf6d54c55",
            "189e61e8f1cf42549deb47d93229e164",
            "bd1ad9a342f648b7b0bb7410119ecd85",
            "40b4ecbe4338491e89d9137b331199c6",
            "46b897cec8ee4517b488623d6b074674",
            "c65b7e8014ff4270b2ae15eb02d528d1",
            "16db0b02d4734c4c86658d9fe896948e",
            "b4ad753ebee54bef816212418074e044",
            "94091fb8a5794aacb3ac7c73300f4f50",
            "6dc6cd9653454d16839cb0eb3d80b31c",
            "f4ac0fe218e8413d8c4eaceebdfba855",
            "84d916ead5394c919a08e810d1364f53",
            "4818bf8183f849aea6284d94b831ee67",
            "1fb12137357f448d8c7430f2ea2a4396",
            "ab5ab3177e034f1eaf836449c7a833a0",
            "ddb824092c974bae922bbfe5dab40eb5",
            "8fe75581995e47ebb97cf7d9928bb947",
            "4f65d1c0a4ae4a1abc6c9ec0b1a8cec1",
            "c8b83d4b8a484ca99d045ff3c571cdeb",
            "3dd5a7effb7d4280b9d00888bc3a9fac",
            "4e422eee520d4f54b6e86bd945a89157",
            "1aabeab51d8a4f55b4deba4ffeb4df8a",
            "1b41f2deeecc4054b78606b66b853c09",
            "8c1b48ef4419488886bba9337fa72c8d",
            "4b6c3b6f7da041d9a6f546ca70358390",
            "8e6b1b5b333f46998bf25260763e93cf",
            "7b194408e80f421497f109a131cb73fa",
            "c675efe85f234350a36de541ffc1b279",
            "1e54843761f24377ac03e427a9c7f9c3",
            "690550e359dd4bb2b37a074b0f5312e5",
            "baff671efb32420883eacfa67ae356ac",
            "4d0c14d1c1224f5aaa3002a271e1f41e",
            "c7b4dc2f50b04aacb31da04def0f89a4",
            "0b3d4f591fce4b44939490ec76a289b5",
            "ecc735efde854562b5ebe276742ba0e3",
            "eb82f351c98847a88b1897fd40ca3b18",
            "d05b5cf3ba1848c29f04711b22c426f6",
            "61e94180febf41ffb178440f7513588a",
            "b8d335f02852412cae01bdce429dc4b0",
            "4aaa820ad2ca45e69ce60ca5b5fde2ce",
            "b973988da7414ca2b4f7e635db823b30",
            "6536f5c84f3a484db27cbfa8d1fb7762",
            "08bded51586b4258b8be1e73faf2e45a",
            "d03e8f2a35a9423abb7e817bcc7da3ee",
            "72308617049d4aafae5d62c29f122678",
            "16e817c909084ff58e4209a34c0e856b",
            "31d1e809d0b24a54bbf060b76e6d92ec",
            "a67c69f3ad6b48dfa2bf0ac755a9a2b7",
            "b1acee51e2764a3bbbc8aa54182ece19",
            "f4bdab2577cc47eb9d8dc37e34bda725",
            "bb6d8d955c0f444183cdb6bf2219451e",
            "d33c2c50376a4ecda183ddce04598168",
            "ebcd6d0f3585404bb56ec3c338b1a7c8",
            "c14f176f4a6c4bfdb0876080c5e1b768",
            "4ee7447b85664724ab3c9d8952683f36",
            "44c32033146a411aa783fa536eb60bac",
            "204b591a7a1245668187dcd9105cc22e",
            "bbf294b4beca4bdd86f471c8389186fe",
            "931007ce327a485d8e21796fbcd20c9a",
            "938942929d8d4375ae3a073b1f447abc",
            "3cea94cb51274fbeb61336bf615aea16",
            "76092302bf6e4701834719953d21e66c",
            "450bb29297ea43c69ba9d54e17f5cdd4",
            "e57f1244d1f8409b8fbd15a4df228bae",
            "a50a8bbed26f47e1bbd7ae5e977ace6f",
            "74445178d8a54e9ba7f65963a93fee38",
            "994c1ea2aa9f42b1ab8e31b0dd7c395e",
            "29fb9fb9ebd244b6873b8bdfa9ad4ffa",
            "30b5ddef20b64fb58d23e4d60e1784fe",
            "bef9fd663cfb4a8f8c63227a830a6312",
            "f47aea23eab44b61879cdb249006c99e",
            "4358bc300fcb4311a5f967f64b502886",
            "13c198e63206499ca6e19c121a1989b4",
            "1e13c6727cdd430db163255d7c108db7",
            "3aff63e0bcfe4ee59b2065567651cebc",
            "99f5a702018246519dd0a42ba0bfa1cd",
            "e48ac6076a1b45539b0888bf4967e945",
            "608455027c534e50b7c495fc025c3045",
            "3725a7ef7841465bbf97bf7cb4e9f05f",
            "aecf822ef12646dbadb38b6e5ac47f6e",
            "f39270d4e4274a3eba99d27baef2c9bd",
            "b8526e78d6a44b149e168583a3f247b1",
            "4968586d6fa542fa8092f21f539eb195",
            "dae2625233d14df1be4839634bc17729",
            "13d3c7f136a94762973dc5d5f0d4e11e",
            "4724d75c9d7d4f969609cf0981b178f7",
            "4ff5592656d3428796f501e1bf143b55",
            "29bb2b9e94bd4e3183904c7b02c0b28d",
            "8f70f81625f64585938814b611955aaa",
            "de204259292e405f8cbe7cc1cf811749",
            "0c72032671bc482ab82cda817a188e3b",
            "3188ed6cd28b4a3e9983ca40ce70c06e",
            "8fd172b4dab04296821ede53bca72ca8",
            "ea05fb2b37a54a5f9572dce68f8d650c",
            "2d6cd10a2abb4cff887b40561e9268e0",
            "44a27877135b4eb69495603d4e950f9d",
            "2f345638f8cf4366b5128369995b9a68",
            "a0df101e3e9f4bc788b6c8ddc1261abc",
            "016a10f0c75c487c84e8f54fd551f388",
            "6d4e12ce5a57433aaee598ad2b8091fb",
            "2a2064b4dc94429eab360af66cdba4c1",
            "8b8f25b896254d10895d0b4726e397cf",
            "ee3deb5c7a7342f584479270233d9977",
            "9dd45bfd120c418589c22067bd8e9075",
            "92362be6847540408985c4cf0b8ea1e2",
            "3edb2e9c2d8e47368cc9e5b39eb4df14",
            "e122274536c64fe78a9b6b6554d5e9fa",
            "05dd47d568de43d5af666bad6eac3a0b",
            "6723be0ef57a4e2f93a1dc1e504b7bb0",
            "ae03cbfcf7424daba91a14c077e30ff2",
            "f13472adc6e146428282d841b593da1e",
            "23975e9aaa0448499000845d2db31a58",
            "6e80c664d6f947eeb8c7658c81d1dc4e",
            "7a040ca9cee8418489771bfa79a4025b",
            "78ab978f52fe4e97a32b1131d04361ce",
            "6608497474fa43629e47b2d10b0df2fc",
            "dab0b6f33b1b40f685213ead60dac74b",
            "004e1c5462cd4a0e8eaf70d01b69a22a",
            "c8a6f12702a84af198749fbfbc042c0f",
            "e3a060aa4c8945f2ab1ba219cd80d9e6",
            "d4f2804286ce45449915303b81e1197b",
            "38963f375d6b4a6f8da05ee6e64b9455",
            "5417c2d44485485cbd895dc2af9d7eee",
            "0d4f7f7614a24b66b2d9d31815dd5823",
            "3d0273d88be04c37ad8bdd38a0ea473d",
            "4ad8cf836e374bdcb3de3674c6fc42b1",
            "24196c5d3659424182077dccb40964f0",
            "5d02b021e61c4728a499af01e7b23c82",
            "11003d10a99e4f528d46f8693056a0c2",
            "4eecb02c69fc4dd09d024fc5d81ffe69",
            "26f1f2b757b54db5bc38a423dee5a355",
            "b66258dcd2784cbea45ccc69a7955239",
            "07662fd40f60447ea807a09d60a7d031",
            "a5f0ba1d51794bfc9269c0212dc5763d",
            "adc624687bb44a63838d398288776631",
            "29d31c09ea2c4255916dad9f9d3ff1ce",
            "d87cbebecf6c4654ad2cbe322af94e48",
            "4c172364de564941b741296a8e2a99dd",
            "e8593e8c38884d7a9079da5d3b681684",
            "0bc78ac1ab8048ecb7d1f8bb8fdb31be",
            "9da73cb197a04d7bb1fddbf229c0d82d",
            "db481bafa04f438fad478a0284aab28c",
            "b8088539af554a2185d297dacb4e0665",
            "a6ff2b722fb14763a709fcac71d05d29",
            "f76d529687d14b31a951a5ce9f0c1542",
            "6c5e1dfa71e041559f40d8d4b49f7314",
            "f5750eb61d8c4fd3bd3058f7c801fbfd",
            "4c6eead1617d480db17bf1ae3bf8616b",
            "6edc2c47a5f64902af52be516e52933a",
            "82fd31a14c5840baabe562a09b8a82d3",
            "05380ff23f4941628c860faa3f55f84a",
            "b10d7c15ecc6468e97e8decde5742c66",
            "b2d1a9c9ec3a479b82709655707b20c4",
            "cb9b1bb1b15e4e16b17b50b3a61d1a77",
            "36aeab115e3b451b87b1d9b7eaa7af20",
            "198c34506fa0496f89a2c4c032c1b1b0",
            "e9c4dc5ded284800afc127e7aa7a5a13",
            "7f12564c40ef4a3f99a7582ea1ccc452",
            "65854194123943b5926f0c66ddfe68c5",
            "7bb3d0599ac44e3ba59b0697916a7d7d",
            "dcfad54e0f9f42d6aa3a0808130b89e5",
            "b8ee42032ff040acb05e28788ea833ca",
            "b3bbb50162ec435b92934f9433029067",
            "d0663d6942bd4d0196f2184fa326733d",
            "0c1dc687bf9e40008458b37cf0549993",
            "618490f535d74b2e8ae64c995f3e06d3",
            "b80363e1118346989420247a0cefa087",
            "ac531368d60a4502b07ebf5174be2035",
            "091c110d168f4087b034bfd04784f7e8",
            "804b2e7af91e476e84de1ea4c67a592c",
            "a7c8141bb086428386f0efe3879e31c1",
            "779c0987baa64016b2e653ecf04d71dd",
            "dc5537dc938d426ba25dea972d95b155",
            "0193ef118a724161806d26fe28fe6baa",
            "3cd05e85ba284a1e8e55f575fd621807",
            "1401028bb7a944ec8c989745ff242211",
            "c967843483634663819203c2f1c62431",
            "063aabd7ae234734a1ca075d3b426320",
            "741af661b6f84b3cab7acc69e4454f6f",
            "95a88798579c4da793494dc6d8478e43",
            "7a79651928b74eb7a6153fc26b774c80",
            "6a941315293a4e52ada953e9536f9f01",
            "f82305c6c79644dc918cb695ce40c41f",
            "2e9d710b2bd94488b622595d7226ac7a",
            "d36a7bfd85e04425a0b92c82e9b12fca",
            "50b80c13515e4a8eb90afbfb06659323",
            "7c970faeef36420f9226836af7b0d62c",
            "6eb9d739a2244232af812847a935d268",
            "4898dd41ed3e413f9dc724ba0eb3d7ec",
            "8c57f480019b4d74a35f9d36073f9dfb",
            "c6918a8efabf4ea0aeb5a68e595ad1fe",
            "71e3c648d0244785afe94d0826975f8d",
            "f7684fab91284579b207ac0370634432",
            "a1e3ce41878f422bb92b318232322ff2",
            "76b3d560b48d4ca8b580e996c182e50e",
            "142efe8f28b6459484295d58a0230724",
            "fc702da946b846dc893d5681d9f2ebda",
            "55ee70b3ad914030be89ec377566cd1e",
            "d28cb689dac74847bc825a549fcf560c",
            "926316e01c2743108299c079cca3f95a",
            "825c149d91ea492aa6440e7a83107a15",
            "4f6816a63e0b40fcaed966146baff3d6",
            "a4fb80bf60364849b40c7f7153451715",
            "a5609ec6df6b4470aa044bf01209d153",
            "488b89e239474bbab0b50f3654ae3a0d",
            "d5d90b8f14d24cf19ae8922d893ac2a7",
            "520291d703264ca5a1459dbdc7defc4a",
            "6e4186a994f14517b85d8951c866dc43",
            "c86ddd1a493047688ee570caedeec8ba",
            "fdc58f09dbfc4048839d744844624105",
            "8fa3720f9f0045cb80d7f99aeb4ba02f",
            "22bbfd45e2ed482683eea081b3f6d31a",
            "ac2c1d14d8d14e3da4ede7323ecf1a70",
            "b4324fc3cc1747c298934da08e88dd85",
            "ad739575b745420796429b8dd66d00f5",
            "dcda99610e9c47519d34b698a29b4064",
            "f04424b3c9894699b03867dab14e2726",
            "b67f1d897e984dec8f044f2511ba454c",
            "b845c7b35d7e4ee6842baacdba8dbc7c",
            "e85c3bb87a2c4c7ea3b84afd8bf1e458",
            "64605a0cd8bb436a8a2d46d903867093",
            "bc16913fcc754a32b8572c949f74745a",
            "a9820283b006453baef66aa975fd2c64",
            "01befd30a6a74003927ba7623e368f99",
            "009cfbfec216498da51f6a8dfb6d6854",
            "dc6b188a7138482384ed954bd4b8bda4",
            "c6380ac7407345a08d45ebd1cdca20d4",
            "5955ea6c960541cea354d63cda49a978",
            "f61329aa52a24201ba99f9153e8ff42b",
            "855379acf66b4f28a402d714d26b2e60",
            "007fd98d8b3549f5b9fc35856e2c3500",
            "d3355f6167854337ae4ed3c61c9638f2",
            "b244b9111fc44d8a8848417c5551e349",
            "34214dcda61c4977bbe6073a1c1a91be",
            "7cb05ae76b5f4aa08146ca05a3bb6128",
            "9cdf8d03b6ff47749a5fe82d99c63bec",
            "1789e9f46f6e4723927b1c8e820b2d1e",
            "d07958226d604b34979d049a84619618",
            "3f6785eb59a34606bfe42aa5960d3ae2",
            "6edf6724282745fa8b7c6143b1420755",
            "92233aa4fa234a4fbb09178fb34549b9",
            "8194e73840974291b051b47ece031d09",
            "a138f969f304490592612c60f952557c",
            "f95dc1e7fc53489d9d9d4188ce0fb932",
            "0ed9103f9eaf4176a55b72d6815cd0bb",
            "a9dff215cf7f4f969ee669a94038ec05",
            "7d6142297feb4b268ef2eb975fc6aeff",
            "ad3c0c8cbbb04f478a366435406af007",
            "4daa55b41b3c497cb92610c7305ca71a",
            "6b6e8e66a48e4797966000c7f87427a7",
            "babff47cf74f420bb611e5bf578b68cc",
            "dc7f7f83b0c14ac09af868c80e57aa41",
            "847cc408966c42e086fa2a828dba5bdc",
            "7a7576ce225347b49f129e567cae4d4b",
            "6473e50bbd764e0285033e8e463c8beb",
            "dc464ca0e95d4037876b0746d95eb31b",
            "6161825aaa4c4ef9bebe0c84d44ced01",
            "f3a3cc70b9c04d1f8758b6078ab93095",
            "1f5263b3160c4cd4926743748573c885",
            "d755b2b94466419dbbbac446d4f8c187",
            "1264a58c5c0d47a593fb8c7901efac52",
            "58cbb7b17ed141cd87c8e7e45efd44d8",
            "73562d7361584418bc2db8c9580c3477",
            "95d2c222bc44456bbbeab4e44855d5e3",
            "ad9ba8db80fe422191be963c7e2fb1d7",
            "1cca852df90447cd99564cc35b3fbf84",
            "a2042aa687504295910b9a23dc7bb2a5",
            "6f08428d52fd4a6080e5b10cb4ec88ca",
            "8718855ee0344bee9e50211903defda4",
            "7e45c410c2cf44f7948bde268bc0ded0",
            "3dd8b777992949f194878aa09bd58a02",
            "43100b447c544f06bd35945bf7688187",
            "a745c2424b434c8e92ae83dd79c0ed73",
            "0351b0269c224434a76386aa2b38792a",
            "6dc59b4d0edd4cbbba9f17a25bf60213",
            "1643d46c19c846c698bb22cd2261b055",
            "7f967e39806e41a68fbdd40514c1fedb",
            "424db87f32fb4c45a6a54a1cc31727e6",
            "32611748eeaa47dcb26dbea7a938b46e",
            "7bd9bf0af291463a96f934d5e83c2cf4",
            "ae17ba255038431bbb27eb902cf90d61",
            "52a8567baeaa453dbece00c498edfe89",
            "3c6e30821e5f44f9a555fe11a1ca7660",
            "499e67b52042472a83dec4904171f379",
            "825a2eec79ad43138976ea9dd6d8402a",
            "e60ae62f3b944fbfb71d7479e60821d3",
            "6128678cc4754170a937da4d8fd5d679",
            "2186eae515584930b8f3eab73fe64bb5",
            "3ffce91a06d041d2a55afd2b0d5086b0",
            "e0ecfc462aed40fe90d9a0eb4a6622e1",
            "1c1682bdff5d45f28e707765a5c570a4",
            "5440a7e532ca476c99f8e163d6049618",
            "bd2416745b9d4004821de93b7178b8d9",
            "67f8aff385df4033b48ff4864c0ac11d",
            "119d12451f624d0ab45f0e526a2a091a",
            "9acdad46505445908fb3e287b52f751f",
            "e5a1938a9d3f40658c22035e38e4aa41",
            "0bde23bd6787422bb819349bd9851fbb",
            "440ce929f5c04d3f81769f73ef78f11b",
            "920308d09d804863bd8a8fb2ec5164f1",
            "2365eef0053b4471a38c6a5df485b6e1",
            "0b350e3906bd4d59b4d47eb84cf3e436",
            "2c4010a5617e4f2a9cc6f5bc6345ecbc",
            "d41481bff49547e0aff69f7d589570a2",
            "abba90656453465bb45a4d15dbd0b8bc",
            "b85ccbb076b047bb8213fea040d3fea3",
            "42d1c6a6e52948e0806969f65fc7a1a5",
            "2fd3cb58520140a99e8d6dc5b58fea1f",
            "093d65b7b3c94c398a2da97128917c70",
            "f5f9528768bd40a6ac0337f8902e7f45",
            "781ae1bf5b6c4ce1bc2473c9b78eca4c",
            "390d37a5b77d4b4b9f71e92469d0ba63",
            "c3d220ab40604f25a0f12b30635ce394",
            "be390185f22c4b469361c7dbdb419136",
            "a775a836950f428d8f367cd6f582d182",
            "7036754e8aa34c10915ae66c020cff7b",
            "af3cf14f47c34af58e1e5a048fc2d125",
            "2b45f56a0529462089afb6d257c449af",
            "6a51f93da7b7407a8252161e9a1bcecb",
            "2832b9e402e14fb68f42f4cb4d13a8c3",
            "50023855da4e47a38dbf1a060463d780",
            "43110b6173e949448c0de86fcde3f43b",
            "4a1f065d1e734cfdb378be14d979baa3",
            "337d23d99b6645c4a485795843cfebaf",
            "2cfa5c04cf1342aba42e79018ab1ca3b",
            "7a92ace17973467cad94b9d14e11935c",
            "401c184cdbc9481b8804c717e510e4d8",
            "efb195eef1134430a557607945c10f1c",
            "c654971b048f4c3abb25e128845cb7ab",
            "40a29138576b4d6a8827a2111a8794cf",
            "4a2a48242e5f461898ad44cb0f0effa7",
            "e89d3c86b3cd4e2d82284bebeb70b9c5",
            "5e50b23a6bdb4f1ba2895bf32775f90b",
            "e0ae7392cabe473eaa55cdc089ec0b22",
            "5bb4dda80d584a83b12647c4e8e52156",
            "c443ca8405e342c096be651c73077007",
            "51be508468ea45cbb913d2f8a129dde4",
            "88a7b07e32684331b9317c0e64c9df3c",
            "070ade613bdf4e0fa1ec817bb85d5f29",
            "6af2a2d95d5b425ab9377fa7a88f0e05",
            "daef91498c9847ca9651265826d84cb9",
            "5f7ade209e74444c8245f74c1b2295b3",
            "cc9ed38156984f00994b8b6afb87f0b3",
            "9300c414c95845a6b9a800ba6689c7fd",
            "c03aef77706c4a23afacc59c92cb8c76",
            "b7cfc575e9dc471c918f736c69f17146",
            "7386c51c579a4631b0e6bc6ee863ed8e",
            "015073ed0391475f919b51f84bb7a5fa",
            "6b67984748e64ee7acb38e501dfe172c",
            "46a9812e911e42d984af26c9d6cb6107",
            "f07ecc571b9b433fa35a1abcf998b01f",
            "5e6926769ff44a4eb4f49948eb2f9880",
            "3ca2da48afdd4e178e0f456c6ab9d5b4",
            "84a347dadf6741ef8b5b3f33faa3e6d1",
            "dcc99833f39843149d4db62a083d3f41",
            "72171374ac1f4c3c877c156c17f621ec",
            "cdc0fc5f0a69498e82806719aa2c6610",
            "529500814f4e4a97bf6ca2429f9aa1fc",
            "30419c1dd25943ddb9151ad63a791f63",
            "0287279cc7d14bef9210636cb7af6e72",
            "8c6c190f46a5495ebfe048cb75b82df8",
            "bf52c8c1b6a4412884a47d313910fd59",
            "efd7b7ba78d648cea45935b3cf8c2ea1",
            "2e5d672e83ff4fb39fcea7e57da2425d",
            "d6eaddec456346b2b0f5baa809b7ac9b",
            "3dc426eba0a54e53bcb47127e516389b",
            "976b0c1184f14f4abdadb24ee3802dce",
            "b4009dc8f48f49b29ee7c58b1a5291d8",
            "a9b5962e57e14a1e987a5eadd9133032",
            "82510f31c1fd4370a7dd0a102bdb4c13",
            "cdd605bfa6214b50b5485683a027aa66",
            "013c80a116c549b7a1e326d0d368a01a",
            "ae6d77553a94469889147d7bc486dcaf",
            "e8bcd9819a144c778794af19ec85a28e",
            "11c4ee933f6c4bc9ac68183757aca132",
            "7677ab1a21e24cc3a604d43cde364bb9",
            "3f0d0ef35c8f49ec80a6204ab79679d0",
            "ea4b8f54302f471e9138436e7e088a49",
            "b4d022d24f924a7a995117ff6191ee6d",
            "7a3eab6ccfee41ddacecd0a91d27d2e4",
            "4818b1941efd4e49bcf0579595d0b2a4",
            "742bb9903a0d43ad86cf0c1d53b958b6",
            "c29a4733b01c4edfb46f699f463b2b09",
            "5747e2f71052485483ccebc0e7cb52c3",
            "17ea78d2358141af95b9272c2f676758",
            "264f82d1bc4442198747d3c19afbf067",
            "69e33f4bcdb2495e83c0758527b0867c",
            "6865bde61a6d408d950cf79595ba12f2",
            "cdbe8c22a0c7401f80883cd3de2b6354",
            "95b3166d83c64327885b73922e8c5d24",
            "73e267cc37c9440688e6c5db38e7a7ac",
            "9da5d428aec2400a817609f72d495656",
            "3f5e11c6132f44988a76daa5264d4352",
            "69ecae34cbfb44b787ca7f515ba2c7fb",
            "57aefd8f4f3f44a281e868aeec3d7932",
            "8cfabc0a90c3475a99211da953f40c23",
            "599fd74d351c4db7ac00200487b334b0",
            "986cf186e6304e87832682281c189901",
            "61a252bf14734ee4910233dfbf289157",
            "ddc6330012f643b983955f72f565ff0b",
            "e45e615f44d040b297d387a165b1e07c",
            "6c01d7cffe5c478697bd1e0741d3622c",
            "4245cfb3d5604f3dbbd2cc34e10f4277",
            "4bfc57caa38d49e4add3a05f4bb296cc",
            "0f830c3648324748bff36f93c33228ff",
            "602e1c246d5441c8ada40d66270dffb7",
            "887dd70bb1794cb9854ef8c4c0fb7734",
            "acfab5d7c0e34fc69012aa550d4ebb94",
            "46fcf0163b42418190383a0d02d23e71",
            "bca5ea4f098e46d8a98f5fa4e9c76354",
            "35d910e524934586af9b624338244938",
            "840e3fe35334412d923b0f4b68bef641",
            "36f4200e94fb41f7afc8551f7d6f4628",
            "69d27ce8c3c44937ab225f28262d3a93",
            "1f802e922a054193b22a6f7ff7da25c8",
            "b71d033a35a24706be77c7a04eec2592",
            "d75eaf4ab59341a78bfc62ed55de9bf3",
            "68b96ff31ab14eb7a925f71fba34cacf",
            "40ce4078feb34541a25dacd34f6319c4",
            "a46f41f07b364222bc33c5e507f2963b",
            "aa22ef60c05e496d8f4376ed82203110",
            "7542800b153749d2b119ade0ce239cc3",
            "76bb2a1f78e64adc8e002d2b972e6ade",
            "4dc1dd7d0d3b4f5ebb4cf95e129fe6f0",
            "e93a507cf11c469495e730a6ed3d74f2",
            "3300c2ac3d034da095dcc3f731534cc2",
            "cfbe2235e6034310adbef33eb37c81f6",
            "d6440587d35a4b63990058e2803ceb62",
            "5ac78aaf964b4c1483b0f758b6fc56e4",
            "ffd1d33c77a14c049f5f9c7d7ad61ffb",
            "b5c3edfa60b543bdaea944a273785225",
            "b41ba02e74644979869f23aa38b64a6a",
            "3fa55613b26c452c97ef4ded38a20aad",
            "cfaf50d50db14c618811af65d751685f",
            "89e418d5ecca4874b848507178bd2578",
            "1a15d3626e644233a5541f0ecf98366d",
            "c7bbf7152bf84ae990c675fe952e1eaa",
            "495a680596cd4d1885d887ee132d5413",
            "8d7a8b010bae4502a465a999fba32439",
            "09ccf703dc4e4998a03a558b7be328b6",
            "282ea6a2b9f948f39ae4bc95c1c426b3",
            "b2e21a9dee0b4067a77847886c439f5b",
            "01b496c8c86343dc962e73c180ab4195",
            "5022c97d8e42498bb79b224e60f67d92",
            "80cfe7ad31f24898baefc3c4fa016337",
            "96578d3c922943329695bc7f4d10d0fe",
            "1c2d4c886baa4309ba864b1b96f1fb4c",
            "c8a6b6829e0a48a3a9b32408be2bb04f",
            "c1c06af6d89647a5b28cf4edbd590121",
            "9a90ca5b06794cc5b5d11333cf1164ba",
            "a93ce8f68bec474282ec831a45067786",
            "8eabf07b38e04514a0903e35bd9089cf",
            "d69152a844414bc6b28da247a7a3f80c",
            "2cc19e934b3e4c2d9d6fb8e855eb9112",
            "90aea420f6274352aed115d5efdbd210",
            "e0f34631379b4c3fa1a0feb878f92f09",
            "03c0f8d841984e79b81a55cc085e6b3f",
            "6934354f066444b1b09277b63bb34ddb",
            "98cee9917728449f97a2a52afc684bcc",
            "910e7f8a34fb4471821e4b3fc402156a",
            "f970e82f0d4d4724ac78e62f2daad3f5",
            "0fe8c1c95dda4a97a5a373ff286cb7e1",
            "1ad1aeb9f20941f4b79489c7846089e0",
            "37b95e4b23024039af68dd410f908e10",
            "d80a47f173a1421997a0f29496880e65",
            "e9e8e7694df74fa4ae0200e8378be7a7",
            "4baec401631f4ef8ab73c55b0dad398a",
            "25f44f64421d48dba53fa93d02ce7709",
            "a3b7b4f3f6614975acfc3760b94cec46",
            "895a149e17fe44af89f2109a2371506a",
            "ed4582c8aff24eda9c0f3dabbb14196a",
            "f609a508efd048caafba5ed268124bef",
            "b8424cb0dc2c483a9631a4492d369ac0",
            "41b9c67667df41fba3766359174904d9",
            "2a25ce77f4f048b7b1d2256968534adf",
            "4a2ee3c61cc340648da2971d52ce745c",
            "c3b1916eed5e45e8b951743d49b934ae",
            "345a2ea091b148328c4d6285511ab0bf",
            "b6f8bf5b2db646c5aeb9364785ba0325",
            "d3541e274c454fcf85c6adbf2dbf5998",
            "6b16d98e33bd465f8ab46184d865cd99",
            "0ff2b827d31442df8e66ceef4cbf541e",
            "f08e527d095a47d5b2016bca7380b2f6",
            "56b7c51900cf43e6b4729cc03a158409",
            "87bead021c3c4a04add0c1fbdfda9c52",
            "948a06a1248144398d61d33f36059e96",
            "d5de4a82609e4c6f84d50c8b77fabb05",
            "4a25554d2e2a43088393ff4a2b4383c1",
            "a5bbff315ac441459d8e349cfe32ae75",
            "126e3c3a00fd4cc2b495fca8b922bb99",
            "231b08c64e9540a68e83c9979f4e46b8",
            "63e81ca594aa4b9094502011e73b4457",
            "2c025654972243489b215a9b5cda48fe",
            "26eb64c98265446f8ad9e84ccb40572d",
            "185111ed805d45218f714b297e7adf06",
            "d50d8179a3a64ebbb2bd3f071cfed192",
            "5f05d9c4d66a456786cba48e5b28ccbd",
            "c439354cae854d9cb14b1f727c7351eb",
            "bd9a3bee65364d4a90b5a0124df94d0d",
            "caae9ed1595e4f96b9d6b54582cf1454",
            "5811705cdd97484e9050c7b98519b0e0",
            "91423c589be945cb8d01529c4fe3b8c9",
            "053c7530b2d5420fbbc5ef381f2594dc",
            "ce7401fcb688489fb3c30c383f96e944",
            "c6d3c3d8610a41c396b404f2be22fac4",
            "4c6286f7f36042948e13653c055b34a4",
            "8d0a6bc2b1414e3fbcde3deee92878c3",
            "b85f04a621cc43c1b1fbda2fd9cc366f",
            "71af8d66a036457fb3f919dc7b2b7160",
            "d50b126546fa458890006049739d6d75",
            "1e4960995dd94ea0b5cc8a83a5dfd76e",
            "446b6c8238dd4e0287926df7cb321544",
            "a89b1d8b174f49b3b5c3f05d66db8dda",
            "e30063c663ad4751ba658151b56b8461",
            "5cc2d5ab2a424e05ba27bceda83a6a87",
            "73fe0509aff84c0abd3be74287823414",
            "1c59be2703464a249fb05e8bd5105957",
            "7c0255683fa447aaaec2ed0ba14e0879",
            "de712385ca7a456fb38615c47c061fac",
            "048e36e15d184de6a98000e3deba0784",
            "8b04a37b118f401cafecc15a4b6fb34a",
            "c2a440099b7747c58eec83e20fa17a3f",
            "afefc4a25c884298a869b5232c839c20",
            "85a8aa489b6e4673a380f6ac1ebfe37d",
            "d2702fc5d03d4271943c32f925cbe9c5",
            "a91b10cd309d44808cbd1f675e2f9d6d",
            "563bae9d37cf4d26948adce268923494",
            "322fcc3f19974376a27be3779ad7b463",
            "cdc03b0c1e8d47b4b2174ac3f252cb1f",
            "8783e4500abd4942adfe6a7a475f2a19",
            "e01a43a9d0194dd28f5f6611084ed242",
            "e5624dc30f764276b1488d529fed7711",
            "a401d6a5af704e5180a1accb4dcda155",
            "8a453fa5c6d84099885015b572e6391a",
            "286adf75049f4ff4876142eaf1f964fa",
            "652bb5499a604672b20076343dafd363",
            "d3df5359c39341a9ac0154358979407e",
            "fc8576166e724ba0a7b29f06e685da8e",
            "e34a56a05efd4ec18d24b4746b5f35a1",
            "a7bd9267f15846b4a5e95790f5e305a0",
            "2e4a95df26fb487f9e55bff606c58dd0",
            "b0064ca6ce644c7881f6bc6034391172",
            "d1dd21b063574f39a1a967c422b04ae2",
            "aaaa83889493420b98cba829e2f80b01",
            "751c5c71c7f24b80b80fbaf4957fdee2",
            "bd5df9fc2fe043418676175437117793",
            "c6ae37f045e04aaa9fddac0e585c8a61",
            "9fdbf77777554950bc0b132ee2cdaa67",
            "b391aaf7725d4400b17d57dba1b00f48",
            "261408e6961e44d1a9e9a68c5c9ed31c",
            "8a343d489737493ca9c79d28f319f7ef",
            "9cc95087913944449dac138bf76f74ab",
            "6c2cae8b5f0848efa65e6f94df16ce38",
            "523083aaedf34688b1d3a86a27c9c7f0",
            "362855ad5395479087b565fcdbf6b9eb",
            "c37c838bd42040049d6f6effa6f796ee",
            "87a8cc650f2b4dcfbabd7429ad123c87",
            "73aea0d834df4d8982e1471fe85cf2ec",
            "8754e6b035304048820ccc2bdf291e45",
            "9e262959b4ee47b3a5c033e56cf8dc15",
            "57ef95f18d0c401b8dda4e51296b3eaf",
            "857f33c2dce244a38d8a5f8ddb238ae3",
            "f76e38a716b14f20b4077831af62bada",
            "edf4e92e7f1948a4a9e609a244ce747d",
            "97af8375fdac4cc58bf202dbf7dddc03",
            "539b11c8ca55468187f160fc07c1ba7e",
            "cada922bd8d94277b7b64078d18a7736",
            "29d2e77a64f9407d88beb5962908cacb",
            "7d91256399d043a2999f30d0bd8131b8",
            "42af81e874db4d858339a3daca87cc7c",
            "0069c6e0e9374dd28bf8830bdb5e5555",
            "ab1a6f648f2d423db2a4dd08efd45dfd",
            "a23f54da5eb641668ee9e6ea101bc8f2",
            "04b9b44e8b7f4ab095f3d55f644c9139",
            "ffd9c6c0eee243078ffbec947a8877c8",
            "f44cee1683aa4d9cb0d7f5f8fe08d065",
            "6a2d24ab21994fe8ae10aae65bab1023",
            "7e5b9b33dcd84c54b63078495ee554e6",
            "f81c2e27ddae414e872f1dc08a6c496f",
            "2e4ec5520c6144cea2829cf2980598d8",
            "837e33617ec64158a5fe68b83e024d46",
            "50a42c5bb8b24213ad399199117ad7f5",
            "1bd7b42e109e412f8bbb13c9681d3538",
            "84e65979afaa4476aab9823e0d3aef65",
            "400c2643ac5841d58e5b824516d079f3",
            "05066545695148adbb2d7b445923374f",
            "490cb53a30a14d1e973b19f7694bed9b",
            "f38d4bcd192747fe8f0c4b1c06c872ab",
            "140a1cd4601e432b84da65b7a6af1768",
            "578c3d7b5bf84ba780ec75df65b1dc5f",
            "4bbf85950926458db3a314480f11a142",
            "1dfaa5fd906d4efdae927fe897d5f2f1",
            "5cf6515e6e704305a1f139e7b12dff41",
            "bda44a0fd48c4c2eb1de05038bd510d4",
            "1096c80c2a394151b6fe58f44af6e708",
            "85f8215e708e4a848c171fcef44cdf02",
            "9fbf960d45444ddfb136c4da76d7ef12",
            "e7d15a5cee1a4b199d762abb54d44038",
            "269676b8d9fb4527bc3e2ea2811c42a7",
            "0c231719b49d4dc580cb4ef897009c2f",
            "43d7d1c6817b40d58614a2ba27c684e5",
            "b3bed2042cae4cca9f3b98bfc6a710f7",
            "f4deb3089ddd4405ba9a1996f3e4cf6d",
            "11a57473a262495a9760b8130c066fb2",
            "f6a7d81f4d594ce2afa79035d71960a6",
            "8416524dc2fb44c895e95d8d133da8fa",
            "5d16dfaa0b0145f1abd8cdc6789c3064",
            "0b7ac8fc6a78412caa1da26046f9e9b7",
            "9e33468cc49b469c87c8a695dcd8f8df",
            "151861619ee94d7a83fdcd9815a76dce",
            "3c77b6f1f274474bb9cde3a8360660a9",
            "e9e130fc74c0475984f635f28110ba3e",
            "90ee0fe9595b46ab85a8574f0dcadf9b",
            "31f2e0041a76402cbc9c9a314a72679b",
            "f4118ea082d440819366147829e2a1ea",
            "d0d3c697dec24f98a649bd071f682fac",
            "3fc4f72a03c649258be174e3dc6a18ec",
            "90033061aa0f4614a0a3745b76901fbb",
            "a2d8017006894285a2e11d0ce174e048",
            "1518f1921768408b93fa1fe8579073f2",
            "140d625004ec4de39ca2619c5b1d748b",
            "dd970facae0f4efb8542d1e1e8e772d6",
            "5bd024bd08c34219b94bb81b72ebb193",
            "f370f8ed3be8431bb3d603356fff890c",
            "6efb780e34c54067aa0a3a8c62b6f82e",
            "c1faef2a3da74acdb5bffda79ea22010",
            "02de9f8273de41e2863ee4c5e615146a",
            "d4b893fc630443dcb8d027cf0bec12bb",
            "e9c2207eb6e44265903bf72b52030e78",
            "b41b587980f64c0899f73d6e9fb51fd7",
            "c663aba885eb465dbb612ce9488b9ba9",
            "f8bec287944844ceb69081bdfdc80ba1",
            "71226381e2d84569aa338f18501fdbe8",
            "45b640529d7f47ca9368b64c142191c6",
            "5e127bb6f11e4222b9faab0d771027e0",
            "fcd4a4d196ce40d5abfe29b2ea64daf3",
            "4e3bbd78c2d1432cbf612a9c9705ce7e",
            "bd12bb5b70944485a2a40a95a7425404",
            "bbb34b8cf67547d39b7b57f976b5c80f",
            "8fca34ec77cc44da9d2209f67cd40c60",
            "ddef2c4d87d74e03bbff907ef7e755f9",
            "daee1fce889441d6b844e2ab8ecf8b58",
            "224286ad1dad4dbeb6739b5e26f3113e",
            "51df4b58c497463baddffdec99c7022d",
            "df5803aa5a814775ad378c295d3253bf",
            "5732111673014a81ab3e6f4113db222a",
            "4d2af413dd644b638ee751196bf678aa",
            "1a91731de62845ce80494f396a95cf01",
            "4373e643fd5447279230196cd73d384b",
            "41183e8ab3ca46e09312406ff8003883",
            "d46229751d4144a7a865b66293264c60",
            "da3c89df0cc3444389f71570b4ba9f1d",
            "ca766fcbb88f4758b8dcf22dbc503c07",
            "ee137233d89a49708ff5e2fc6838ff73",
            "5ecc85739ecb46deab0225c35171c7cf",
            "a5a9fa793a734d4c98edcb24473bcc03",
            "ccd336edefc742f7b215e877a6205a29",
            "69ebb87b60c0472faea7a4c0489e115c",
            "3501937bcfa447b2813a04290dbfa8da",
            "ed01700cd7d2413da23def24411231c7",
            "756c7308a59b4fb58aa8f1021b6f399f",
            "14a5bf04bcfa47a79cb0af621107e50c",
            "4c8b436f3a4347abbccc2dc74ac2edd7",
            "f53e21130c414e8ab1c44add5805a21e",
            "d56e351e48ed4f868e1db9a16c94269e",
            "5037fc7fab014791b7cec8453064395b",
            "0052ad27444b4a7e9abc4a3d65a57fbf",
            "471072014a894f94874a8eea03da3946",
            "33eadb3906ee4d79b0310cd33f177c3c",
            "2f06755b028a496196c1be56d5a65dda",
            "2e9670c292ad4033acb06975c295d66c",
            "985ca53037f24aad864bec5d8aa2c918",
            "5802d12668574602b21a9326bc76ac5c",
            "4f202e1463434d01be316b40b3038678",
            "1c23385c25644cee93289c01ff3f810a",
            "4eae60965a964ec981657d1c92adce02",
            "ce9e7fe79b224cdab6a3b438cf312af2",
            "442366e789e04a5eb43b50f8fe357808",
            "6592970604cc461681c3d67c0b69d96f",
            "76d8e0872896400d890e89c0ed3ec2d0",
            "4c868c05d8894910b57bdb272ba30f7b",
            "54670d2a0cea436383227b98cedbfe06",
            "d70d279813784badb9aec338a67c085e",
            "01cd94911fff46e6bd4f301bc270bdd0",
            "4d65279ba8234e5a882dd70abfb74850",
            "5cc836b9711e4d96b7a2375aa43fce90",
            "0ece1c6c7338457f967b6223d66d76e7",
            "da9598f6c4d14634825a6a3a45e4f831",
            "1c67a8224f9d404e8d7e4dc32707b63a",
            "b412199e761e4eb9a68ef0e93b483fac",
            "f3db08074df349c1a5eb40280ab3cf7b",
            "fcbc585264ee4425904baeb0f4972fd1",
            "e4fd6271b6544261ac6f78fb1b72688c",
            "6de47bad56cc4a008a0f835c1c72df0e",
            "522a3751f08f437d909ef6bc3e39e724",
            "422b76069b694430aa252c859aabef46",
            "0e9e50776214419ea79ac7aa7b7bd7bd",
            "1d975c2ebd05477c895e6802ecd95e24",
            "abfc49740f634c7fbbc657c3d7b91686",
            "f3ea0ac7882e43c1b72379e47ae09049",
            "76e1244eca7c4997abc429fc3ecc2408",
            "c26f49b92f5e49449200fa34eeee930d",
            "c1afc817b7b44860b5c3807873bfa55c",
            "3a2f0b3369ea4a329461add010ac8b1f",
            "052df03955a94bbbb6cf54de69ba0aa6",
            "a8ede901ab974d1e9c7ae2cb0c6ad57b",
            "bf5d9066e0d14d05a4b4d2380b5e1a4d",
            "e5bb9bcb3042491e8a483771b91dc030",
            "75210506413a4a77bfd8c529f804fb08",
            "e1af136c2b8a4e2892d15f4cc465ed04",
            "ff47b9e97a324758a88e4ec3988a83ce",
            "73dbbacdc8ad4f06828d971f17b28dfd",
            "c3ac81401fe84fd0b454daa32da33b87",
            "4de909faa5c0492eb5e650a7dd7fda55",
            "018bb062e7a3484aa384e6d1f64fbf2e",
            "0cd15564e6b44a3db5b4956956926269",
            "d208c3c2dc454d55bd0e426b00e0b3dd",
            "87590f33a300490cb8a28150bf3a114d",
            "0f7d8f04eb884b4b88e75faccd312982",
            "b516ea0938d042e2a6dc03b2e5ce2d18",
            "21092c023e774fcc9784a06b3576f676",
            "3bce7ed06dff449fb72e0a87f59eca81",
            "4c1938510b6b4a9d903175ecfe8b47cd",
            "4801b4c4bca1485398710229471f726b",
            "a2c8980a31b5402c9284c4010ae83ab6",
            "a96f98531c2142caa1d3d307f69acb5e",
            "97845bf294fc40299b138d129caf877d",
            "89f8e66a771c448686b6a55b15ab94d2",
            "ab3ae84691664fbe91f7f08d6f40801d",
            "46308e18eea9415bb14b1845b75bd4bf",
            "96ea9168d6bc48ada010a40f17a4b6a8",
            "8eec8538d58b4016b2832792fbbeee0e",
            "1c188f899c8643c194656671bded6473",
            "f0ccf716d18c4b1c84aebc48afaebac3",
            "c2ed6b8232bb4bd88b4aea0bf6d22cb2",
            "c90da7dccdb3436c9fee6d80d8cdcf30",
            "fc842a338771403095d935c68c43c171",
            "c59a7dd5aa8244deb8675694dad909aa",
            "7d34b80a367a43ebbc7f61eecdce3159",
            "2bf5bd52fe544a8bbf357b3dfbbb65d6",
            "2b27cf1e04c949288bcbd5d4ccf8d83c",
            "aa93e7842fdf457aba8a154d354c44b0",
            "4d351efd70ab4f6abb9e9b33fee7a673",
            "ed444bd347a54d9c81b3c6d71c46d87d",
            "fc8d6e864bf34455b9e560ef7f240fc4",
            "f502314b712a4e66affe28a171c015a1",
            "ea5d6fa333ca48b1864aef3c567df2e9",
            "e2ba0aa5c3c8467f93333a72af799d76",
            "ea1ec24505a246e2b4f42bfe8eb4eb00",
            "04d5d5a316384f3c98784e55c68cba2f",
            "6ccf2ede3fb74e4cb4cfb0f5ad9eaa1f",
            "e8745cb5a8234957a58d8e60b1492697",
            "51bb278da5814b848ca8ca2ca1461023",
            "6e57b131f8a14fc792aec8eb82a10b90",
            "58f1fd4ed9994b1caf6c5cb9a3a693ce",
            "3febe6e40ea349ca82a729d8776dd6f2",
            "a44de8fb93f548369fb9101537d3de1b",
            "426a3789ca8b497db399624b88933ed1",
            "3b3c39f9b26e46ee8d8232cdd6e98c9a",
            "2d557f491f634fe18fd2d8c776c97358",
            "5826f53547274ee3a1ef8f45efd1b74a",
            "12bb94e74060407ebbedcbb0d18438f4",
            "f0f5927da3394e5eb4eedef40bbf4c58",
            "13ee355fcdf140248ae0d15329158ecd",
            "dc10211274b54beb9ef5eda4116375e4",
            "4c02f69a1dde4393add57036b26c79c2",
            "2a12ae518c094a65a47e66ffcafb892e",
            "dbe3ac8a7308433e8a8145c6141eebd4",
            "12bcb7b0e2fc4467bb35e2b15b3d7ca5",
            "e7214af45ed6446f8907e19fd8b815e6",
            "aad8bc06c89c43bd838e69c182f01bbd",
            "a4a45399f43749358e1fe2766c32726f",
            "5b43fc57de8f44729eb6c665fda91393",
            "7c6861d8fee04f858546a1b1c203b90b",
            "39d94b47ab62418e86a5b1c15c1af445",
            "0e462d0ae8134589ace140fe2b1dadd8",
            "4858d99fc1764b4aa6229d962e460343",
            "2e34b99edeef4cefbfcf0354a87c900f",
            "e465523f59f444d2916019693c597007",
            "95b8ed079cfa48e096e2389403c0eaa2",
            "484f63bb56344710a6de493d43bf8a41",
            "4d7b4f8fa8a24a3a8c3af1ce93a6f8a2",
            "b4562bb0c855481a80237bc3f500a339",
            "9732387b405f4aa683f296346581a678",
            "60c8f89801354abd8a693641584e5698",
            "557aa883241a439db9f7e3461b3d4f54",
            "7787e22671d748db801cd145f9a80759",
            "05df798f60c743a5bf3e0a0e508c9d30",
            "9c9257a0664b4fad929856975b4ade1b",
            "73d7948ca28b4f57b4c566c182aed2ef",
            "7f23ca3b926a4ea4a184f3bf14f82b31",
            "412e90115a944f9d8e2515331304788f",
            "d53aa8734c274adc89abe20e0fe7358a",
            "38e8b3bd97914a449631a1429cda9a93",
            "c31a0219d7e345719630298e9f2ab414",
            "ec08574c799b41d8aa0fdecae192a1cd",
            "1103ee1d489b4d1f8f6c681d5d5532b3",
            "79ac1175e3c4429ca7c4185816514e42",
            "0d5088f6a088417e86be1b6ceb55fec6",
            "3ca201ed0f184ada95f9b1f05a90a641",
            "5e8ac9dc3dbf4800a5e70c1548656379",
            "50dbad770a3e4a72b24b9c7ff2c92587",
            "6aa6c89d827f4e66b72b53ffc1b8f5b0",
            "eb7402324e8045af94112079e16014ee",
            "cfe01ec6e34e470f96842f915c41a6fa",
            "cf674b870c5742399f1b637b5c997fff",
            "57cad25cd93b41b7909808a3c7463fb5",
            "7b2c278a04bb46b693f2845b0bd59c62",
            "016645716f324fb5bc18c318b0d837d1",
            "696e608546184648976be5b9fa8a8c54",
            "1701f5464bbc4dc3aee158be6f89a4c9",
            "8a5d1d03e64742e2aabcd8f26383dbb2",
            "c42ca6ba341e41c6942d7799e95fb651",
            "fa25cde4aa444d9cb7307f3e6b657de0",
            "3804beace20a4ee2a415ca8bdcd61f97",
            "8596be60ea584ae4b2662878bda9ef38",
            "4f0b20232e5241ad8b159a0f2fe53a75",
            "6f94cb72811d4a8b9b93f57484cb4d39",
            "1921562c68564fa9b036e63306647adb",
            "a752df06867c4b2f9996d715aa1a4631",
            "e0bfce9314a94ae591bf1fb1b05c984b",
            "160d4af469854afa840ac88a33401ed5",
            "13de4fa722ec4a6ca7f2d75e68886105",
            "ad48fcfaacb24d16b360ea47a8510d28",
            "3c2dead2aff34a72bf2959448a8d4961",
            "fe5ba9f2dfb14db19a9048a25776ae6a",
            "ea6f2e32e98249219ce0de8b8e21dd8f",
            "d074820b68274d87b4352d39da17570a",
            "1c2bc0d363a1437bb8b0addf1b4d63ed",
            "d00045df403d4f67a4cdcd2460ee419a",
            "46bac33ef9cc4864b664cce5bf72d3e8",
            "3b05861005e9498a8b229ee732339dd8",
            "836a596917fa4039b6c4194179dea09c",
            "5ca640526f9348a580f182dd70212b8d",
            "9cad58c6b19046c7a7187a6a1590845c",
            "bbc99003d45245dabe216997b0a75ddb",
            "bb5f5dd3ad63428486b5e6ebd2ea40b5",
            "1cbae8c03e0d4d5b9c4b0f6f7d3c86f4",
            "e99fc1ca33d74dc8ae4b90bba4f65a48",
            "46d3ea1481454a9eb7791c3faa0a5c4b",
            "905aa7a0945f457590adc34ed0a4b364",
            "df4157b72d694fb5aa78fc56638de3cd",
            "7bc03366059347d3aa55e645b443c77c",
            "17b997a6a2ef403eaffd2f54d7eccd58",
            "0de128704da44de1aab63ad3d4548860",
            "4ee0cdf14aeb4b28967f61db86de2526",
            "2e69b787d5524dc29ae4a74f02af5113",
            "a378868886ca46d087d3b90b00f2dde9",
            "26462d2bac3341fd9aeffbe7fe938685",
            "272a015ebc3c49f49082ebf9efb1e7cd",
            "161631506016417eaaf200df6574285e",
            "3a8410e996c6406fb9cb350f49f81a1f",
            "e4a36a25a18b47b2b0778bc4e3a2958a",
            "25d1c756e7ca4334b2d72f2da9a308d8",
            "521ad1d42a42442e985eb121db1816a9",
            "2e00f1925a21447bbea360c3d1bbc896",
            "2c5b0e3958fc4f07a903d369e9f526fe",
            "a3cb8b5d23304f5cb5b95d280277f5a5",
            "55a8a09bb675496f946444fd92879e23",
            "81ae3501f7974ac0b90baae0a744bd4b",
            "356ea04fceab458da493855d166523da",
            "2ea637c6d3ad4fa399eceffb993104ca",
            "83c8b08df54041b493bcc7fc366b2edb",
            "1252094e510e40eb9870a570ed0d47d7",
            "598bb575f7b8415dbf5e4c700f4a1870",
            "d23bdba5fc70472dbaed82d12eb59010",
            "1083e27dc7934965a1ab472757744f07",
            "1210621453834a00b36df4473dac102e",
            "4131fd91697947d59eae6dc4b9742bf9",
            "689316fb9c3343b3a9b869995153401d",
            "eb5bb418496448e89183245b273c87f2",
            "4acc19f829b146769ae9edf5adca16d6",
            "37671217aae645b7953597677bbaeb62",
            "7821b76b484e4bd482b4271da2dcec72",
            "3a7241b5b2834c4483827492ba3f8617",
            "bdefcd23fb7b4b14a061f9db4b7f71a4",
            "c127c1ed13214f41b4238ae153377325",
            "e050786ebbb5468c8703f266f4b35628",
            "a22c8105a6fd46288f8883240f647428",
            "cf234005681940009c1dbf49d736644f",
            "721d32a069224960a4e13ebc1b01577a",
            "3f13acf3a33341a3bd109cd66a48455a",
            "93620e8c77a743c09fc0278f040cad8c",
            "b495c6afbbe545d3afb441c0d8340597",
            "1aedfe3c136442d5bc902b01642d4569",
            "d40c77cb05aa4920a05822b04aa0181e",
            "69bc693bf6644b8bbdf1c4033c7ef05c",
            "1d1f734023114be4bb22f5be1c9f92b4",
            "c60b9cddfda846d3b97a3f0e237bd3a2",
            "88022e65911b4b0b981d78a50615b758",
            "7528eed3bf5b4820ad8a1f4940a41893",
            "ccba3d9ad9d143ce833726d13ee08432",
            "69f6dbd973b7494e8634b358be5e9704",
            "f68b24c00cee4019ab785874c2ce3b0b",
            "80a8a89e832c49478d24d74a41d17f29",
            "7588cd7100124b21a87ff0a2a79d0e82",
            "0b4bb126e23b48a194fe5ec182526220",
            "b4c7d54866f648918f5f090dd591f26e",
            "0ef331a0090046a8ae4c2cdf0aff9e15",
            "d1a182d0280947869cbb9edb5db362f4",
            "95c313347f2746be9c57c8bbb9fd2dcd",
            "340f004564114e2095c6f58de2b4e73a",
            "57c62c640ab14d509d3274e59dd8c200",
            "86b030efdbb243cbada1d074272c9040",
            "f4641b129c8e414aa18ddbacde683d00",
            "c1234523220c4ef6a46fb2106b99ed60",
            "44da0c2bbd42486d92e03063fc495827",
            "f2338c04439f4e369bd1a3472587c8eb",
            "3d92678e1c66490786043d63d95e237b",
            "e29cfb25b48949108fbde16dd05bb093",
            "7e7103eaa0434d489e14a7ed024fafdf",
            "5d932efce2ae4cf8a93eef09c1b3e87d",
            "ef2bb6d392784330bafe2434b59ff7a7",
            "0c676d1aad3e40638ee55ce98f13e992",
            "77b51f5ce2ec423ab4990ddc5e675b77",
            "ca24bdf2702349bc84036b2557811d79",
            "18d0e1c0c7e041abab730e2c0aedb8b9",
            "27a990b7478846ffb0c123e9628a4b03",
            "0341027a9dc440c4809d4a83ffcdaa3c",
            "b498eb810d4242e59329cace8b6aa7d3",
            "c8585d72c0e44057bd4910ec9669396b",
            "2d085ed589e74991af207aaa1e96b664",
            "aff9723b95cd422cb3a5a9b49e6ca1c1",
            "4499e9ac490c4901a46e271463683ab7",
            "74337e4a8e2d432da6c93b5589bebcaa",
            "b3627a458c1a462fb28ff41fdaadccda",
            "324d6424071444feb2d209543f9cc0d7",
            "28862e9968604b59afc3a6484660abef",
            "b95ce39f48a04abaa04c8d0604ba0fb9"
          ]
        },
        "id": "vG2Gy_49HpZG",
        "outputId": "a3758652-27ea-4979-d268-07051d94835d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "965e7943bc3a4f23b026ab7aa8f64c70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de469265f88b49969cadabf54a5de347",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Training Loss: 7.4331, Validation Loss: 2.9317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: FID: 10.4342\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_1 with FID: 10.4342\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ef5a35a7e48450283e9f7a722d262cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a504ae481bbb457895f8fcb2cd7b0cab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Training Loss: 2.3290, Validation Loss: 1.1077\n",
            "Epoch 2: FID: 10.5488\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7b79d67b605469d85e5123811f6b4ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0361f7dafa2f4783a473ea76d732d647",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Training Loss: 1.1128, Validation Loss: 0.7875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: FID: 10.1320\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_3 with FID: 10.1320\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a011297b0f64403a89d0010ac249186e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4efe2d121284b13b30c2bbb736a64a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: Training Loss: 0.8656, Validation Loss: 0.7184\n",
            "Epoch 4: FID: 10.2314\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "501a22b845c947299ff1a46768e20fef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "719d8856f1da487e9de1b9ab93436e0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: Training Loss: 0.7878, Validation Loss: 0.6890\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: FID: 9.5808\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_5 with FID: 9.5808\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8abf39c052364650b7c1ec36cdd8240d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 6 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "058eadb794aa4c76b4d31584ae4efbb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 6 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: Training Loss: 0.7464, Validation Loss: 0.6718\n",
            "Epoch 6: FID: 10.0879\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82fbd7363cdd4f6687f6d4213a803d7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 7 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f709a2009bb48a4a65c0505db0ce0c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 7 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: Training Loss: 0.7166, Validation Loss: 0.6602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: FID: 9.2811\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_7 with FID: 9.2811\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a2197442bbd4afd82a8ca7a62f7355a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 8 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "991a0eeaa6ae49c781037f0f4c9c24ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 8 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: Training Loss: 0.6988, Validation Loss: 0.6510\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: FID: 9.2802\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_8 with FID: 9.2802\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "025615140bea4f4d8feec596e3c0264f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 9 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f016f06e9859466fb7fbebf3ddd96bc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 9 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: Training Loss: 0.6815, Validation Loss: 0.6442\n",
            "Epoch 9: FID: 9.4931\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a26d31972e5042f5a3846a5dc9d04fda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 10 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df786630c7f74138858c81d752c90b6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 10 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: Training Loss: 0.6652, Validation Loss: 0.6385\n",
            "Epoch 10: FID: 9.6032\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f80f06b949614880be5a65f22c378812",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 11 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4ac0fe218e8413d8c4eaceebdfba855",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 11 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Training Loss: 0.6529, Validation Loss: 0.6341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: FID: 8.5226\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_11 with FID: 8.5226\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1aabeab51d8a4f55b4deba4ffeb4df8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 12 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7b4dc2f50b04aacb31da04def0f89a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 12 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Training Loss: 0.6395, Validation Loss: 0.6306\n",
            "Epoch 12: FID: 8.7680\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d03e8f2a35a9423abb7e817bcc7da3ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 13 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ee7447b85664724ab3c9d8952683f36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 13 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Training Loss: 0.6278, Validation Loss: 0.6272\n",
            "Epoch 13: FID: 8.9326\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74445178d8a54e9ba7f65963a93fee38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 14 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e48ac6076a1b45539b0888bf4967e945",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 14 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Training Loss: 0.6182, Validation Loss: 0.6250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: FID: 8.4777\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_14 with FID: 8.4777\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29bb2b9e94bd4e3183904c7b02c0b28d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 15 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "016a10f0c75c487c84e8f54fd551f388",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 15 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: Training Loss: 0.6087, Validation Loss: 0.6231\n",
            "Epoch 15: FID: 9.3359\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d4e12ce5a57433aaee598ad2b8091fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 16 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a2064b4dc94429eab360af66cdba4c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 16 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Training Loss: 0.5983, Validation Loss: 0.6205\n",
            "Epoch 16: FID: 8.9178\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b8f25b896254d10895d0b4726e397cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 17 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee3deb5c7a7342f584479270233d9977",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 17 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Training Loss: 0.5881, Validation Loss: 0.6195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: FID: 8.3980\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_17 with FID: 8.3980\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9dd45bfd120c418589c22067bd8e9075",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 18 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92362be6847540408985c4cf0b8ea1e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 18 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: Training Loss: 0.5800, Validation Loss: 0.6183\n",
            "Epoch 18: FID: 8.6754\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3edb2e9c2d8e47368cc9e5b39eb4df14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 19 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e122274536c64fe78a9b6b6554d5e9fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 19 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: Training Loss: 0.5718, Validation Loss: 0.6180\n",
            "Epoch 19: FID: 8.8727\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05dd47d568de43d5af666bad6eac3a0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 20 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6723be0ef57a4e2f93a1dc1e504b7bb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 20 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: Training Loss: 0.5638, Validation Loss: 0.6168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: FID: 8.2343\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_20 with FID: 8.2343\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae03cbfcf7424daba91a14c077e30ff2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 21 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f13472adc6e146428282d841b593da1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 21 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21: Training Loss: 0.5561, Validation Loss: 0.6168\n",
            "Epoch 21: FID: 8.5111\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23975e9aaa0448499000845d2db31a58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 22 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e80c664d6f947eeb8c7658c81d1dc4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 22 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22: Training Loss: 0.5482, Validation Loss: 0.6171\n",
            "Epoch 22: FID: 8.4227\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a040ca9cee8418489771bfa79a4025b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 23 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78ab978f52fe4e97a32b1131d04361ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 23 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23: Training Loss: 0.5394, Validation Loss: 0.6167\n",
            "Epoch 23: FID: 8.5965\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6608497474fa43629e47b2d10b0df2fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 24 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dab0b6f33b1b40f685213ead60dac74b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 24 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24: Training Loss: 0.5318, Validation Loss: 0.6170\n",
            "Epoch 24: FID: 8.3119\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "004e1c5462cd4a0e8eaf70d01b69a22a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 25 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8a6f12702a84af198749fbfbc042c0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 25 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25: Training Loss: 0.5247, Validation Loss: 0.6174\n",
            "Epoch 25: FID: 8.6382\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3a060aa4c8945f2ab1ba219cd80d9e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 26 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4f2804286ce45449915303b81e1197b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 26 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26: Training Loss: 0.5177, Validation Loss: 0.6177\n",
            "Epoch 26: FID: 8.4583\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38963f375d6b4a6f8da05ee6e64b9455",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 27 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5417c2d44485485cbd895dc2af9d7eee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 27 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27: Training Loss: 0.5106, Validation Loss: 0.6175\n",
            "Epoch 27: FID: 8.7299\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d4f7f7614a24b66b2d9d31815dd5823",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 28 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d0273d88be04c37ad8bdd38a0ea473d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 28 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28: Training Loss: 0.4980, Validation Loss: 0.6200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28: FID: 8.0964\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_28 with FID: 8.0964\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ad8cf836e374bdcb3de3674c6fc42b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 29 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24196c5d3659424182077dccb40964f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 29 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29: Training Loss: 0.4888, Validation Loss: 0.6207\n",
            "Epoch 29: FID: 8.5164\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d02b021e61c4728a499af01e7b23c82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 30 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11003d10a99e4f528d46f8693056a0c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 30 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30: Training Loss: 0.4884, Validation Loss: 0.6205\n",
            "Epoch 30: FID: 8.0992\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4eecb02c69fc4dd09d024fc5d81ffe69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 31 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26f1f2b757b54db5bc38a423dee5a355",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 31 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31: Training Loss: 0.4811, Validation Loss: 0.6222\n",
            "Epoch 31: FID: 8.6823\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b66258dcd2784cbea45ccc69a7955239",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 32 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07662fd40f60447ea807a09d60a7d031",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 32 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32: Training Loss: 0.4753, Validation Loss: 0.6228\n",
            "Epoch 32: FID: 8.1223\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5f0ba1d51794bfc9269c0212dc5763d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 33 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f76d529687d14b31a951a5ce9f0c1542",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 33 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33: Training Loss: 0.4676, Validation Loss: 0.6246\n",
            "Epoch 33: FID: 8.6886\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "198c34506fa0496f89a2c4c032c1b1b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 34 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b80363e1118346989420247a0cefa087",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 34 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34: Training Loss: 0.4513, Validation Loss: 0.6288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34: FID: 8.0219\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_34 with FID: 8.0219\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "063aabd7ae234734a1ca075d3b426320",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 35 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4898dd41ed3e413f9dc724ba0eb3d7ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 35 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35: Training Loss: 0.4545, Validation Loss: 0.6274\n",
            "Epoch 35: FID: 8.4446\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "926316e01c2743108299c079cca3f95a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 36 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "825c149d91ea492aa6440e7a83107a15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 36 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36: Training Loss: 0.4480, Validation Loss: 0.6290\n",
            "Epoch 36: FID: 8.5256\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f6816a63e0b40fcaed966146baff3d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 37 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac2c1d14d8d14e3da4ede7323ecf1a70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 37 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37: Training Loss: 0.4408, Validation Loss: 0.6322\n",
            "Epoch 37: FID: 8.2184\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01befd30a6a74003927ba7623e368f99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 38 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cb05ae76b5f4aa08146ca05a3bb6128",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 38 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38: Training Loss: 0.4188, Validation Loss: 0.6365\n",
            "Epoch 38: FID: 8.2530\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9dff215cf7f4f969ee669a94038ec05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 39 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6161825aaa4c4ef9bebe0c84d44ced01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 39 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39: Training Loss: 0.4280, Validation Loss: 0.6351\n",
            "Epoch 39: FID: 8.3680\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f08428d52fd4a6080e5b10cb4ec88ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 40 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8718855ee0344bee9e50211903defda4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 40 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40: Training Loss: 0.4215, Validation Loss: 0.6362\n",
            "Epoch 40: FID: 8.0599\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e45c410c2cf44f7948bde268bc0ded0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 41 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae17ba255038431bbb27eb902cf90d61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 41 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41: Training Loss: 0.4155, Validation Loss: 0.6396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41: FID: 7.9751\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_41 with FID: 7.9751\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5440a7e532ca476c99f8e163d6049618",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 42 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c4010a5617e4f2a9cc6f5bc6345ecbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 42 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42: Training Loss: 0.4090, Validation Loss: 0.6402\n",
            "Epoch 42: FID: 8.4251\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be390185f22c4b469361c7dbdb419136",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 43 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cfa5c04cf1342aba42e79018ab1ca3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 43 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43: Training Loss: 0.4029, Validation Loss: 0.6422\n",
            "Epoch 43: FID: 8.4078\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c443ca8405e342c096be651c73077007",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 44 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7386c51c579a4631b0e6bc6ee863ed8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 44 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44: Training Loss: 0.3955, Validation Loss: 0.6449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44: FID: 7.7548\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_44 with FID: 7.7548\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "529500814f4e4a97bf6ca2429f9aa1fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 45 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9b5962e57e14a1e987a5eadd9133032",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 45 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45: Training Loss: 0.3856, Validation Loss: 0.6492\n",
            "Epoch 45: FID: 8.1207\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a3eab6ccfee41ddacecd0a91d27d2e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 46 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73e267cc37c9440688e6c5db38e7a7ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 46 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46: Training Loss: 0.3854, Validation Loss: 0.6479\n",
            "Epoch 46: FID: 7.8698\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c01d7cffe5c478697bd1e0741d3622c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 47 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36f4200e94fb41f7afc8551f7d6f4628",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 47 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47: Training Loss: 0.3791, Validation Loss: 0.6510\n",
            "Epoch 47: FID: 8.2691\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dc1dd7d0d3b4f5ebb4cf95e129fe6f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 48 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89e418d5ecca4874b848507178bd2578",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 48 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48: Training Loss: 0.3724, Validation Loss: 0.6530\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48: FID: 7.7433\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_48 with FID: 7.7433\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96578d3c922943329695bc7f4d10d0fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 49 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03c0f8d841984e79b81a55cc085e6b3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 49 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49: Training Loss: 0.3655, Validation Loss: 0.6567\n",
            "Epoch 49: FID: 8.2796\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25f44f64421d48dba53fa93d02ce7709",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 50 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6f8bf5b2db646c5aeb9364785ba0325",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 50 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50: Training Loss: 0.3597, Validation Loss: 0.6581\n",
            "Epoch 50: FID: 8.0452\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "126e3c3a00fd4cc2b495fca8b922bb99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 51 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5811705cdd97484e9050c7b98519b0e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 51 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51: Training Loss: 0.3359, Validation Loss: 0.6639\n",
            "Epoch 51: FID: 8.1873\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "446b6c8238dd4e0287926df7cb321544",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 52 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afefc4a25c884298a869b5232c839c20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 52 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52: Training Loss: 0.3485, Validation Loss: 0.6624\n",
            "Epoch 52: FID: 8.1457\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a453fa5c6d84099885015b572e6391a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 53 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "751c5c71c7f24b80b80fbaf4957fdee2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 53 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53: Training Loss: 0.3424, Validation Loss: 0.6646\n",
            "Epoch 53: FID: 7.8863\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c37c838bd42040049d6f6effa6f796ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 54 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cada922bd8d94277b7b64078d18a7736",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 54 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54: Training Loss: 0.3373, Validation Loss: 0.6675\n",
            "Epoch 54: FID: 8.3119\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e5b9b33dcd84c54b63078495ee554e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 55 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "140a1cd4601e432b84da65b7a6af1768",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 55 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55: Training Loss: 0.3302, Validation Loss: 0.6699\n",
            "Epoch 55: FID: 8.3147\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c231719b49d4dc580cb4ef897009c2f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 56 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c77b6f1f274474bb9cde3a8360660a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 56 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56: Training Loss: 0.3115, Validation Loss: 0.6740\n",
            "Epoch 56: FID: 8.2906\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd970facae0f4efb8542d1e1e8e772d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 57 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71226381e2d84569aa338f18501fdbe8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 57 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57: Training Loss: 0.3201, Validation Loss: 0.6741\n",
            "Epoch 57: FID: 7.7918\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51df4b58c497463baddffdec99c7022d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 58 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ecc85739ecb46deab0225c35171c7cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 58 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58: Training Loss: 0.3056, Validation Loss: 0.6778\n",
            "Epoch 58: FID: 7.7864\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5037fc7fab014791b7cec8453064395b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 59 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce9e7fe79b224cdab6a3b438cf312af2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 59 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59: Training Loss: 0.3098, Validation Loss: 0.6788\n",
            "Epoch 59: FID: 7.7744\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da9598f6c4d14634825a6a3a45e4f831",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 60 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abfc49740f634c7fbbc657c3d7b91686",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 60 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 60: Training Loss: 0.3041, Validation Loss: 0.6819\n",
            "Epoch 60: FID: 7.9660\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1af136c2b8a4e2892d15f4cc465ed04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 61 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21092c023e774fcc9784a06b3576f676",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 61 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 61: Training Loss: 0.2997, Validation Loss: 0.6820\n",
            "Epoch 61: FID: 8.3055\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8eec8538d58b4016b2832792fbbeee0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 62 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d351efd70ab4f6abb9e9b33fee7a673",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 62 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 62: Training Loss: 0.2942, Validation Loss: 0.6853\n",
            "Epoch 62: FID: 8.3124\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e57b131f8a14fc792aec8eb82a10b90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 63 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc10211274b54beb9ef5eda4116375e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 63 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 63: Training Loss: 0.2894, Validation Loss: 0.6888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 63: FID: 7.6406\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_63 with FID: 7.6406\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e462d0ae8134589ace140fe2b1dadd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 64 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7787e22671d748db801cd145f9a80759",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 64 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 64: Training Loss: 0.2836, Validation Loss: 0.6915\n",
            "Epoch 64: FID: 7.9347\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79ac1175e3c4429ca7c4185816514e42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 65 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "016645716f324fb5bc18c318b0d837d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 65 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 65: Training Loss: 0.2526, Validation Loss: 0.6978\n",
            "Epoch 65: FID: 7.8142\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a752df06867c4b2f9996d715aa1a4631",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 66 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46bac33ef9cc4864b664cce5bf72d3e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 66 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 66: Training Loss: 0.2751, Validation Loss: 0.6954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 66: FID: 7.5300\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_66 with FID: 7.5300\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df4157b72d694fb5aa78fc56638de3cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 67 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4a36a25a18b47b2b0778bc4e3a2958a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 67 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 67: Training Loss: 0.2692, Validation Loss: 0.6977\n",
            "Epoch 67: FID: 8.3005\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1252094e510e40eb9870a570ed0d47d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 68 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a7241b5b2834c4483827492ba3f8617",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 68 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 68: Training Loss: 0.2496, Validation Loss: 0.7023\n",
            "Epoch 68: FID: 7.8911\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d40c77cb05aa4920a05822b04aa0181e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 69 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b4bb126e23b48a194fe5ec182526220",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 69 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 69: Training Loss: 0.2556, Validation Loss: 0.7023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 69: FID: 7.4286\n",
            "Model saved to /content/drive/My Drive/model_81_bart_class1_epoch_69 with FID: 7.4286\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2338c04439f4e369bd1a3472587c8eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 70 Training:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0341027a9dc440c4809d4a83ffcdaa3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 70 Validation:   0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 70: Training Loss: 0.2562, Validation Loss: 0.7038\n",
            "Epoch 70: FID: 8.2207\n"
          ]
        }
      ],
      "source": [
        "## modified on April 1st\n",
        "from transformers import AdamW\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import os\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "num_epochs = 70\n",
        "model.train()\n",
        "\n",
        "# Initialize a folder path for saving models\n",
        "folder_path = \"/content/drive/My Drive\"\n",
        "\n",
        "best_fid = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    total_val_loss = 0\n",
        "\n",
        "    # Training\n",
        "    model.train()\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch+1} Training'):\n",
        "        optimizer.zero_grad()\n",
        "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=f'Epoch {epoch+1} Validation'):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    print(f'Epoch {epoch+1}: Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "    # Generate text and calculate FID\n",
        "    df_text = generate_text(top_p=0.95, top_k=45, temperature=4.7, num_beams=4, num_texts=200, repetition_penalty=1.7)\n",
        "    generated_texts = df_text['text'].tolist()\n",
        "    generated_embeddings = get_embeddings(generated_texts)\n",
        "    mu_generated, sigma_generated = calculate_mean_covariance(generated_embeddings)\n",
        "    fid = calculate_frechet_distance(mu_orig, sigma_orig, mu_generated, sigma_generated)\n",
        "    print(f'Epoch {epoch+1}: FID: {fid:.4f}')\n",
        "\n",
        "    # Save the model if the current FID is lower than the best FID\n",
        "    if fid < best_fid:\n",
        "        best_fid = fid\n",
        "        save_path = os.path.join(folder_path, f'model_81_bart_class1_epoch_{epoch + 1}')\n",
        "        model.save_pretrained(save_path)\n",
        "        tokenizer.save_pretrained(save_path)\n",
        "        print(f'Model saved to {save_path} with FID: {fid:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV4pq25bcS_Y"
      },
      "source": [
        "## test0 81"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ul04SQ4-ca2n"
      },
      "outputs": [],
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "tokenizer = BartTokenizer.from_pretrained(\"/content/drive/MyDrive/model_81_bart_class1_epoch_69\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/model_81_bart_class1_epoch_69\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qvpy6hudca2n",
        "outputId": "5282bda3-fb26-4baa-d56a-5aec1be48d38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(50265, 768, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.eval()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJrNPYPica2n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def generate_text_with_beams(prompt, num_texts=5, temperature=1.0, top_k=50, top_p=0.95, min_length=50, max_length=320, num_beams=5, no_repeat_ngram_size=2, early_stopping=True, seed=42, repetition_penalty=1.5):\n",
        "    if seed is not None:\n",
        "        set_seeds(seed)\n",
        "    model.eval()\n",
        "    generated_texts = []\n",
        "    for _ in range(num_texts):\n",
        "        # Encode the prompt to generate input_ids and attention_mask\n",
        "        encoding = tokenizer(prompt, return_tensors='pt', padding='max_length', max_length=max_length, truncation=True)\n",
        "        input_ids = encoding['input_ids'].to(model.device)\n",
        "        attention_mask = encoding['attention_mask'].to(model.device)\n",
        "\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,  # Include attention mask in generation\n",
        "            min_length=min_length,\n",
        "            max_length=max_length,\n",
        "            num_beams=num_beams,\n",
        "            num_return_sequences=1,  # Generate one sequence at a time to ensure diversity\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "            repetition_penalty=repetition_penalty,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            early_stopping=early_stopping\n",
        "        )\n",
        "\n",
        "        text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        generated_texts.append(text)\n",
        "\n",
        "    return generated_texts\n",
        "\n",
        "def generate_text(top_p, top_k, temperature, num_beams=5, num_texts=20, seed=42, repetition_penalty=1.2):\n",
        "    prompts = [ \"Write a Science/Technology News\"]\n",
        "    all_prompts = []\n",
        "    all_texts = []\n",
        "\n",
        "    for prompt in prompts:\n",
        "        generated_texts_for_prompt = []\n",
        "        num_iterations = num_texts // num_beams\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "            set_seeds(seed + i)\n",
        "            generated_texts = generate_text_with_beams(\n",
        "                prompt=prompt,\n",
        "                num_texts=num_beams,\n",
        "                temperature=temperature,\n",
        "                top_k=top_k,\n",
        "                top_p=top_p,\n",
        "                min_length=50,\n",
        "                max_length=200,  # Adjust max_length as needed\n",
        "                num_beams=num_beams,\n",
        "                no_repeat_ngram_size=2,\n",
        "                early_stopping=True,  # Enable early stopping\n",
        "                seed=seed + i,  # Adjust seed for each batch to maintain diversity while being reproducible\n",
        "                repetition_penalty=repetition_penalty  # Adding repetition penalty\n",
        "            )\n",
        "            generated_texts_for_prompt.extend(generated_texts)\n",
        "\n",
        "        # Ensure uniqueness and limit to the desired number of texts\n",
        "        unique_texts = list(set(generated_texts_for_prompt))[:num_texts]\n",
        "        all_prompts.extend([prompt] * len(unique_texts))\n",
        "        all_texts.extend(unique_texts)\n",
        "\n",
        "    return pd.DataFrame({'prompt': all_prompts, 'text': all_texts})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQzgyLl3ca2n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=320):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.targets = dataframe.label\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjz5bkBCca2o"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/planB/bert/BERT_baseline_723_2')\n",
        "bert_model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/planB/bert/BERT_baseline_723_2', num_labels=2)\n",
        "bert_model.to(device)\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "            logits = outputs.logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "            predictions.extend(np.argmax(logits, axis=1).flatten())\n",
        "            true_labels.extend(label_ids.flatten())\n",
        "\n",
        "    avg_accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    # Calculate accuracy for each class\n",
        "    class_accuracies = defaultdict(list)\n",
        "    for true, pred in zip(true_labels, predictions):\n",
        "        class_accuracies[true].append(pred == true)\n",
        "\n",
        "    class_accuracy_results = {label: np.mean(acc) for label, acc in class_accuracies.items()}\n",
        "\n",
        "    return avg_accuracy, class_accuracy_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvlJ9rUTca2o",
        "outputId": "5c75923b-ba23-4234-df43-beddde556ec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.10.1 sacrebleu-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sacrebleu\n",
        "\n",
        "def calculate_self_bleu(texts):\n",
        "    scores = []\n",
        "    for i, target in enumerate(texts):\n",
        "        references = texts[:i] + texts[i+1:]\n",
        "        bleu_score = sacrebleu.corpus_bleu([target], [references]).score\n",
        "        scores.append(bleu_score)\n",
        "    return np.mean(scores)\n",
        "\n",
        "def calculate_self_bleu_per_class(df):\n",
        "    class_bleu_scores = {}\n",
        "    for label, group in df.groupby('label'):\n",
        "        texts = group['text'].tolist()\n",
        "        self_bleu_score = calculate_self_bleu(texts)\n",
        "        class_bleu_scores[label] = self_bleu_score\n",
        "    return class_bleu_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5KbZAWCca2o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import jaccard_score\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate Jaccard Similarity between two texts\n",
        "def jaccard_similarity(text1, text2):\n",
        "    set1 = set(text1.split())\n",
        "    set2 = set(text2.split())\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union) if len(union) > 0 else 0\n",
        "\n",
        "# Function to calculate mean Jaccard similarity within each class\n",
        "def calculate_self_jaccard_similarity(df):\n",
        "    results = {}\n",
        "    for label, group in df.groupby('label'):\n",
        "        jaccard_similarities = [jaccard_similarity(text1, text2) for text1, text2 in combinations(group['text'], 2)]\n",
        "        results[label] = np.mean(jaccard_similarities) if jaccard_similarities else 0\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwkLvMgyca2o"
      },
      "outputs": [],
      "source": [
        "label_map2 = {\"Write a Business News\":0, \"Write a Science/Technology News\":1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "3c53029f3b354b568d605b29ac5c3aca",
            "96ee856fa2e448d29a8ab3fefaaed4b7",
            "1255c554eda7464f852378b192644772",
            "e1036f676265463a8fae23839abedca7",
            "f5542d57977a47e18834d0b1bf964e1e",
            "7ffaabd1063940ee8f95b0ac53e9c4fd",
            "ee5090ca04eb46bc97c436482b5e869b",
            "c3aa42cdc8d741a79ea4b3b64cabfdb6",
            "3310dc5c401b470e969f2d9d4ea0fcd4",
            "661b52516ff94fdcbc006f0fc182c5c6",
            "66ebdb853c47420fa6f7c1764a7818c3",
            "e7f3a73bc5314f9b80820e16c67f8c74",
            "119002f56adf457185909c6e6a7d64ed",
            "09a7a5f0e98c4449bc702c092caaad8e",
            "6c005c3e113646b0ab9b9be743250a74",
            "72acf7a30dcd46c493810dca3fe9a844",
            "7432c2935c6844c587a9f24da4324355",
            "0ccecb2f4a1e4597931ca7f83b76003d",
            "c2941346dd004684bde799c7691d037d",
            "4afcf51e476e4e88bb23131dd733eea3",
            "e40cf8feb18d4eafa593281a44d9e4a7",
            "c18bcd2ff6b64274bf19fe765c6f3ddf",
            "4e2ce67f2f9248789afc9e2d5e04a8a6",
            "670cbb15c5ae4f91b98ae6c3a4226643",
            "c2758dd2fe1e4889852174ec12ef0b2c",
            "e6c1146098ca4c5e92d3bfa2718d84da",
            "8c04c6d320ca41938ba8a4e2c21c3287",
            "ba1162a973d2444292027f6a26820b6b",
            "e51068f247b8468cad96b0b2aa19a4d5",
            "67cc42f6bab44b8f8a4ced0f583bc0ef",
            "052dfc4577fc4e578556559a24520204",
            "627610cf85d546cd8b0e910a10cf7d5e",
            "09d9b939f7f34bc190389388af561b92",
            "e3edc433917649c692804d0e73b19f8c",
            "d1eedac90add4752a9f06affacec5e34",
            "6a4410eb881c4be4a227b00bfc338ee0",
            "d7b7370a37874811942850a64153a466",
            "ba16c47bd3d04b9a830535bcb3cd5afa",
            "9ba2eefd05b6436c811437418f4af7ff",
            "6437bba2ba024b5c80439377c4f67dc6",
            "1fd5f6d235cb424381d4a316596313f7",
            "031294438cd347e3b02c892f2705ed81",
            "2e3549d4053b46f59ef918f13b21a1bd",
            "220bf3a6871f43ff996d9a7e7f8b0468",
            "830e6e83bea44ee9a5c0ff4b6243872b",
            "8438f3ac537f455cbd661b0266110533",
            "8fd8444bcd4b4513a5c5690d19b5d944",
            "1e1b6175e82c4f6f83090fdc74127789",
            "ee6d880906144a09a3f094e1bb3f819a",
            "53dd1d22776d4bffb8c97430f76ebc43",
            "eb8e05054b4a40b69d0cb3f0339f0336",
            "7e6fb2233c0c47508b0a33edf7aceaaf",
            "30b31f76027e4268bcda2d27b6ccbb62",
            "7abb24b4175643b0874bbbe57c67f56c",
            "99853355de7548f3a07b5436c409eabb"
          ]
        },
        "collapsed": true,
        "id": "3faVnE1Dca2o",
        "outputId": "5acb9fa1-d2d3-4c21-fc7e-5fa58193b2f8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c53029f3b354b568d605b29ac5c3aca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7f3a73bc5314f9b80820e16c67f8c74",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e2ce67f2f9248789afc9e2d5e04a8a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3edc433917649c692804d0e73b19f8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "830e6e83bea44ee9a5c0ff4b6243872b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from scipy.linalg import sqrtm\n",
        "import pandas as pd\n",
        "\n",
        "# Load BERT model and tokenizer\n",
        "bert_tokenizer_base = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model_base = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model_base.to(device)\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        inputs = bert_tokenizer_base(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=320)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = bert_model_base(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "        all_embeddings.append(embeddings.cpu().numpy())\n",
        "        torch.cuda.empty_cache()  # Clear unused memory\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Function to calculate mean and covariance\n",
        "def calculate_mean_covariance(embeddings):\n",
        "    mu = np.mean(embeddings, axis=0)\n",
        "    sigma = np.cov(embeddings, rowvar=False)\n",
        "    return mu, sigma\n",
        "\n",
        "# Function to compute Fréchet Distance\n",
        "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2):\n",
        "    diff = mu1 - mu2\n",
        "    covmean, _ = sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "    return np.sum(diff**2) + np.trace(sigma1 + sigma2 - 2*covmean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeOqSuAAca2p"
      },
      "outputs": [],
      "source": [
        "df_original0 = df_train[df_train['label']==0].sample(n=500, random_state=13)\n",
        "original_texts0 = df_original0['text'].tolist()\n",
        "original_embeddings0 = get_embeddings(original_texts0)\n",
        "df_original1 = df_train[df_train['label']==1].sample(n=500, random_state=13)\n",
        "original_texts1 = df_original1['text'].tolist()\n",
        "original_embeddings1 = get_embeddings(original_texts1)\n",
        "mu_orig0, sigma_orig0 = calculate_mean_covariance(original_embeddings0)\n",
        "mu_orig1, sigma_orig1 = calculate_mean_covariance(original_embeddings1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNFdzUmuca2q",
        "outputId": "2e02d247-6b42-4d96-aef1-3d759543d045"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k: 40\n",
            "bert accuracy: (0.982, {1: 0.982})\n",
            "Jaccard similarities: {1: 0.06905424068533292}\n",
            "Self-BLEU: {1: 1.2618093839496831}\n",
            "4.528457425966696\n",
            "k: 45\n",
            "bert accuracy: (0.974, {1: 0.974})\n",
            "Jaccard similarities: {1: 0.06741114920370249}\n",
            "Self-BLEU: {1: 0.9825441296337595}\n",
            "4.145145268015739\n",
            "k: 50\n",
            "bert accuracy: (0.98, {1: 0.98})\n",
            "Jaccard similarities: {1: 0.06604278261311229}\n",
            "Self-BLEU: {1: 1.308652768326823}\n",
            "4.034950990947852\n"
          ]
        }
      ],
      "source": [
        "for k in [40,45,50]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=k, temperature=3.7, num_beams=4 , num_texts=500, repetition_penalty=1.7,seed=724)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  df_generate1 = df_text[df_text['label']==1]\n",
        "  generated_texts1 = df_generate1['text'].tolist()\n",
        "  generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "  mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "\n",
        "  fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "  print(f\"k: {k}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwuWPfrIca2q",
        "outputId": "25bdfc57-a6ec-484d-d5fe-3a300a10981b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k: 40\n",
            "bert accuracy: (0.974, {1: 0.974})\n",
            "Jaccard similarities: {1: 0.06677845700880919}\n",
            "Self-BLEU: {1: 1.2460879307284523}\n",
            "4.21607277198295\n",
            "k: 45\n",
            "bert accuracy: (0.968, {1: 0.968})\n",
            "Jaccard similarities: {1: 0.06515656792848495}\n",
            "Self-BLEU: {1: 1.1321612598196298}\n",
            "3.9086340515161266\n",
            "k: 50\n",
            "bert accuracy: (0.978, {1: 0.978})\n",
            "Jaccard similarities: {1: 0.06547116336171306}\n",
            "Self-BLEU: {1: 1.2254141397931715}\n",
            "4.01924765363944\n"
          ]
        }
      ],
      "source": [
        "for k in [40,45,50]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=k, temperature=4.1, num_beams=4 , num_texts=500, repetition_penalty=1.7,seed=724)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  df_generate1 = df_text[df_text['label']==1]\n",
        "  generated_texts1 = df_generate1['text'].tolist()\n",
        "  generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "  mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "\n",
        "  fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "  print(f\"k: {k}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  print(fid1)\n",
        "  ## this one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmqAv8tsca2q",
        "outputId": "c5012d82-362e-4e8e-8fc3-3bd362d5a281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k: 40\n",
            "bert accuracy: (0.976, {1: 0.976})\n",
            "Jaccard similarities: {1: 0.06777460675994189}\n",
            "Self-BLEU: {1: 1.0347257314152107}\n",
            "4.201559787984857\n",
            "k: 45\n",
            "bert accuracy: (0.978, {1: 0.978})\n",
            "Jaccard similarities: {1: 0.06382296294021828}\n",
            "Self-BLEU: {1: 1.261064577820559}\n",
            "4.049706154106106\n",
            "k: 50\n",
            "bert accuracy: (0.974, {1: 0.974})\n",
            "Jaccard similarities: {1: 0.06479205966420125}\n",
            "Self-BLEU: {1: 1.2295038612432556}\n",
            "4.206918834495475\n"
          ]
        }
      ],
      "source": [
        "for k in [40,45,50]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=k, temperature=4.3, num_beams=4 , num_texts=500, repetition_penalty=1.7,seed=724)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  df_generate1 = df_text[df_text['label']==1]\n",
        "  generated_texts1 = df_generate1['text'].tolist()\n",
        "  generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "  mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "\n",
        "  fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "  print(f\"k: {k}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  print(fid1)\n",
        "  ## this one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCigrv_l8Wt8",
        "outputId": "fb5d1ce5-3188-469d-f0b4-b07a43e8133d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k: 40\n",
            "bert accuracy: (0.984, {1: 0.984})\n",
            "Jaccard similarities: {1: 0.06719142625516006}\n",
            "Self-BLEU: {1: 1.1579028711069008}\n",
            "4.1012299231212905\n",
            "k: 45\n",
            "bert accuracy: (0.976, {1: 0.976})\n",
            "Jaccard similarities: {1: 0.06499143098294805}\n",
            "Self-BLEU: {1: 1.2068144332877917}\n",
            "4.110958950527063\n",
            "k: 50\n",
            "bert accuracy: (0.972, {1: 0.972})\n",
            "Jaccard similarities: {1: 0.06407770616980914}\n",
            "Self-BLEU: {1: 1.0333657873675492}\n",
            "3.9573774498765015\n"
          ]
        }
      ],
      "source": [
        "for k in [40,45,50]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=k, temperature=4.5, num_beams=4 , num_texts=500, repetition_penalty=1.7,seed=724)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  df_generate1 = df_text[df_text['label']==1]\n",
        "  generated_texts1 = df_generate1['text'].tolist()\n",
        "  generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "  mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "\n",
        "  fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "  print(f\"k: {k}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  print(fid1)\n",
        "  ## this one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CogmqMh-DHLa",
        "outputId": "b15e04f8-0341-4635-f036-55d3338d755b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k: 40\n",
            "bert accuracy: (0.978, {1: 0.978})\n",
            "Jaccard similarities: {1: 0.06515876035785811}\n",
            "Self-BLEU: {1: 1.2911546392295}\n",
            "3.969484354105888\n",
            "k: 45\n",
            "bert accuracy: (0.98, {1: 0.98})\n",
            "Jaccard similarities: {1: 0.06464754739484214}\n",
            "Self-BLEU: {1: 0.7376890022550678}\n",
            "4.116566339151534\n",
            "k: 50\n",
            "bert accuracy: (0.98, {1: 0.98})\n",
            "Jaccard similarities: {1: 0.06341837996034376}\n",
            "Self-BLEU: {1: 1.1254275573551853}\n",
            "4.160562725089627\n"
          ]
        }
      ],
      "source": [
        "for k in [40,45,50]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=k, temperature=4.7, num_beams=4 , num_texts=500, repetition_penalty=1.7,seed=724)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  df_generate1 = df_text[df_text['label']==1]\n",
        "  generated_texts1 = df_generate1['text'].tolist()\n",
        "  generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "  mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "\n",
        "  fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "  print(f\"k: {k}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  print(fid1)\n",
        "  ## this one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm3-4Msq9g4c",
        "outputId": "690e4f48-6325-4dba-dc14-9a8e65b4a560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k: 1.3\n",
            "bert accuracy: (0.978, {1: 0.978})\n",
            "Jaccard similarities: {1: 0.06436817814190998}\n",
            "Self-BLEU: {1: 1.0335621377771533}\n",
            "3.983130285124938\n",
            "k: 1.9\n",
            "bert accuracy: (0.966, {1: 0.966})\n",
            "Jaccard similarities: {1: 0.06494181827478426}\n",
            "Self-BLEU: {1: 1.1049266894539127}\n",
            "4.005199031451172\n",
            "k: 2.1\n",
            "bert accuracy: (0.974, {1: 0.974})\n",
            "Jaccard similarities: {1: 0.06686724003482773}\n",
            "Self-BLEU: {1: 1.6334852401078797}\n",
            "3.993143772751442\n"
          ]
        }
      ],
      "source": [
        "## not yet\n",
        "for rp in [1.3,1.9,2.1]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=40, temperature=4.7, num_beams=4 , num_texts=500, repetition_penalty=rp,seed=724)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  df_generate1 = df_text[df_text['label']==1]\n",
        "  generated_texts1 = df_generate1['text'].tolist()\n",
        "  generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "  mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "\n",
        "  fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "  print(f\"k: {rp}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGceIG6v8NcX",
        "outputId": "b43e9c97-3f71-48f1-adf8-5f916d28bfcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k: 1.3\n",
            "bert accuracy: (0.982, {1: 0.982})\n",
            "Jaccard similarities: {1: 0.06291394323922364}\n",
            "Self-BLEU: {1: 0.6403436380488399}\n",
            "4.094368004159426\n",
            "k: 1.9\n",
            "bert accuracy: (0.978, {1: 0.978})\n",
            "Jaccard similarities: {1: 0.06342829113441058}\n",
            "Self-BLEU: {1: 1.1589391626418732}\n",
            "4.022096147514948\n",
            "k: 2.1\n",
            "bert accuracy: (0.98, {1: 0.98})\n",
            "Jaccard similarities: {1: 0.0653966658348115}\n",
            "Self-BLEU: {1: 1.1532964799971186}\n",
            "4.169384433440859\n"
          ]
        }
      ],
      "source": [
        "## not yet\n",
        "for rp in [1.3,1.9,2.1]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=50, temperature=4.5, num_beams=4 , num_texts=500, repetition_penalty=rp,seed=724)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  df_generate1 = df_text[df_text['label']==1]\n",
        "  generated_texts1 = df_generate1['text'].tolist()\n",
        "  generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "  mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "\n",
        "  fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "  print(f\"k: {rp}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH_nvi-Dca2q"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=4.1, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=81)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_81_0.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zj_1roXm99Ss"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=50, temperature=4.1, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=81)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_81_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKo8ZaLbca2q"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=4.3, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=81)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_81_2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDHV1sHCZNrD"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=4.3, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=87)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_81_22.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O6govQTap7Zq"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=40, temperature=4.7, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=84)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_81_3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "sKODUKvlEZFv",
        "outputId": "52c3e94f-839a-4f24-cc03-ce5106e92da0"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-62b86b40aaae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m87\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prompt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/planB/df_generated_bart_class1_81_33.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6b4ec568dab8>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(top_p, top_k, temperature, num_beams, num_texts, seed, repetition_penalty)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mset_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             generated_texts = generate_text_with_beams(\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mnum_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6b4ec568dab8>\u001b[0m in \u001b[0;36mgenerate_text_with_beams\u001b[0;34m(prompt, num_texts, temperature, top_k, top_p, min_length, max_length, num_beams, no_repeat_ngram_size, early_stopping, seed, repetition_penalty)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         outputs = model.generate(\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Include attention mask in generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   1954\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2930\u001b[0m             )  # (batch_size * num_beams, vocab_size)\n\u001b[1;32m   2931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2932\u001b[0;31m             \u001b[0mnext_token_scores_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2933\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2934\u001b[0m                 \u001b[0mnext_token_scores_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_warper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_scores_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores)\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0mcur_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0mscores_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m         \u001b[0mbanned_batch_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calc_banned_ngram_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batch_hypotheses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbanned_tokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbanned_batch_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mscores_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbanned_tokens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m_calc_banned_ngram_tokens\u001b[0;34m(ngram_size, prev_input_ids, num_hypos, cur_len)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hypos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0mgenerated_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hypos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m     banned_tokens = [\n\u001b[0m\u001b[1;32m    910\u001b[0m         \u001b[0m_get_generated_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_ngrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhypo_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_input_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhypo_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhypo_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hypos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0mgenerated_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hypos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     banned_tokens = [\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0m_get_generated_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_ngrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhypo_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_input_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhypo_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhypo_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hypos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m_get_generated_ngrams\u001b[0;34m(banned_ngrams, prev_input_ids, ngram_size, cur_len)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_get_generated_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbanned_ngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m     \"\"\"\n\u001b[1;32m    880\u001b[0m     \u001b[0mDetermines\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbanned\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mhypothesis\u001b[0m \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m \u001b[0mpreviously\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=40, temperature=4.7, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=87)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_81_33.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dLP419EEetK"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=40, temperature=4.7, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=87)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_81_32.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cs2j1pFfqG6a"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=50, temperature=4.5, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=84)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_81_4.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buQ1bQJkCuHe",
        "outputId": "d53acbb3-2cbe-40aa-cb91-4cdbf71b243c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.978, {1: 0.978})\n"
          ]
        }
      ],
      "source": [
        "print(bert_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl3JDOqvca2q"
      },
      "outputs": [],
      "source": [
        "df_original0 = df_train[df_train['label']==0]\n",
        "original_texts0 = df_original0['text'].tolist()\n",
        "original_embeddings0 = get_embeddings(original_texts0)\n",
        "df_original1 = df_train[df_train['label']==1]\n",
        "original_texts1 = df_original1['text'].tolist()\n",
        "original_embeddings1 = get_embeddings(original_texts1)\n",
        "mu_orig0, sigma_orig0 = calculate_mean_covariance(original_embeddings0)\n",
        "mu_orig1, sigma_orig1 = calculate_mean_covariance(original_embeddings1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KDhYccm1EBEI",
        "outputId": "0d130037-ca93-40d3-d8ac-8ccfef36940f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_text\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Write a Science/Technology News\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"Vonage signs deal on XML docs Vonage announced a framework agreement with OpenText Technology Inc. to document documents produced by Opentext Media Inc.-based legal firm, Rackspace International LtMmH.lt/MwPAY, for collaborative applications that can be downloaded across multiple Internet sites covering domains from Mozilla to Apache, plus \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_text"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-16fa325c-cfca-42f4-864f-91033cdf6f23\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Sasser, Gates Back Capsule With New Microsoft ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>NEC to Buy German PC vendor Intel Corporation ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Google to launch content management software G...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Microsoft Releases Anti-Spam Product for Augus...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>NASA Flights New Space Ship to Test Phones Oct...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Apple disables iPod juice juice, juice bars Ap...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Swatch Eyes Blindfold Market - Software giant ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Venture Partners Expands DMO Strain Technologi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Nvidia 39s Shandong G5 processor combines Inte...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>AOL moves forward with anti-Spam technology co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16fa325c-cfca-42f4-864f-91033cdf6f23')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16fa325c-cfca-42f4-864f-91033cdf6f23 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16fa325c-cfca-42f4-864f-91033cdf6f23');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-238255a9-9ec0-4176-9ccb-4330e6eb160f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-238255a9-9ec0-4176-9ccb-4330e6eb160f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-238255a9-9ec0-4176-9ccb-4330e6eb160f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9c864a52-081c-4945-b24f-2170faa2e0a2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_text')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9c864a52-081c-4945-b24f-2170faa2e0a2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_text');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                               prompt  \\\n",
              "0     Write a Science/Technology News   \n",
              "1     Write a Science/Technology News   \n",
              "2     Write a Science/Technology News   \n",
              "3     Write a Science/Technology News   \n",
              "4     Write a Science/Technology News   \n",
              "...                               ...   \n",
              "9995  Write a Science/Technology News   \n",
              "9996  Write a Science/Technology News   \n",
              "9997  Write a Science/Technology News   \n",
              "9998  Write a Science/Technology News   \n",
              "9999  Write a Science/Technology News   \n",
              "\n",
              "                                                   text  label  \n",
              "0     Sasser, Gates Back Capsule With New Microsoft ...      1  \n",
              "1     NEC to Buy German PC vendor Intel Corporation ...      1  \n",
              "2     Google to launch content management software G...      1  \n",
              "3     Microsoft Releases Anti-Spam Product for Augus...      1  \n",
              "4     NASA Flights New Space Ship to Test Phones Oct...      1  \n",
              "...                                                 ...    ...  \n",
              "9995  Apple disables iPod juice juice, juice bars Ap...      1  \n",
              "9996  Swatch Eyes Blindfold Market - Software giant ...      1  \n",
              "9997  Venture Partners Expands DMO Strain Technologi...      1  \n",
              "9998  Nvidia 39s Shandong G5 processor combines Inte...      1  \n",
              "9999  AOL moves forward with anti-Spam technology co...      1  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX2eM6aj_IYx",
        "outputId": "880ec500-fb97-42d4-d725-b124300738c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.054204883370948\n"
          ]
        }
      ],
      "source": [
        "df_text = pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_81_22.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0wdTpHNca2r",
        "outputId": "40b5c9ee-8916-44cb-b346-35e993a3ba4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.9779, {1: 0.9779})\n",
            "{1: 0.07319351211725297}\n"
          ]
        }
      ],
      "source": [
        "df_text1=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_1.csv\")\n",
        "dataset = TextDataset(dataframe=df_text1, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text1)\n",
        "print(bert_acc)\n",
        "print(js)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncmjr1Ffca2r",
        "outputId": "eb7b5d47-1d37-42f1-b0c4-1cc042c30684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.9779, {1: 0.9779})\n",
            "{1: 0.07091136734796893}\n"
          ]
        }
      ],
      "source": [
        "df_text2=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_2.csv\")\n",
        "dataset = TextDataset(dataframe=df_text1, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text2)\n",
        "print(bert_acc)\n",
        "print(js)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2sozSx_ca2r",
        "outputId": "66127cbb-7337-4f7a-84ae-5bf645ff70ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.8417605206148489\n"
          ]
        }
      ],
      "source": [
        "df_original1 = df_train[df_train['label']==1][0:1000]\n",
        "original_texts1 = df_original1['text'].tolist()\n",
        "original_embeddings1 = get_embeddings(original_texts1)\n",
        "mu_orig1, sigma_orig1 = calculate_mean_covariance(original_embeddings1)\n",
        "df_generate1 = df_train[df_train['label']==1][1000:2000]\n",
        "generated_texts1 = df_generate1['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La-VE63Nca2r",
        "outputId": "5a460abb-e3be-4024-da6e-2d7a8a781b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.183885243008145\n"
          ]
        }
      ],
      "source": [
        "df_original1 = df_train[df_train['label']==1][0:1000]\n",
        "original_texts1 = df_original1['text'].tolist()\n",
        "original_embeddings1 = get_embeddings(original_texts1)\n",
        "mu_orig1, sigma_orig1 = calculate_mean_covariance(original_embeddings1)\n",
        "df_generate1 = df_train[df_train['label']==0][1000:2000]\n",
        "generated_texts1 = df_generate1['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWMj67-vca2r",
        "outputId": "85f75a2d-a8d4-4126-dc0e-85d0d39eff73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.21268893045666\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_0.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4bOeeA4ca2s",
        "outputId": "125f6042-df1d-459c-f8ee-e6211507c624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.0926786144048206\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_1.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUGOaIQmca2s",
        "outputId": "51d0e0d3-07b3-4c21-8745-4a9b462e3791"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.782454053963\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_2.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MGkTSRFdca2s",
        "outputId": "b438d18f-52bf-4d78-b067-6bb691e10c83"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_text\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2886,\n        \"min\": 0,\n        \"max\": 9999,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          6252,\n          4684,\n          1731\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Write a Science/Technology News\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"SAP to support Oracle in court In a move designed to create an argument that Oracle Inc. and other groups are violating an antitrust law, SAP announced yesterday that it has joined the Electronic Data Systems Association 39s fight to block Oracle from selling its controversial Net-portable storage appliance SEAP Internet Explorer. SAP claimed to be the first global vendor to sue Oracle for copyright violations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_text"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-82e01a1e-45c3-4c2f-b630-a476300b80fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>prompt</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Oracle, SBC reach Deal to Buy Oracle Business ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Yahoo Offers Online Music Search, PayPal Reute...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Toshiba to unveil notebook memory unit Toshiba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Nvidia Introduces Powerful 3G G5 GPU Nvidia Co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>AOL Offers Web-Swap Service Microsoft has intr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9995</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>NASA 39s Titan Probe lands on Mars NASA offici...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9996</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Microsoft updates Windows XP update Microsoft ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9997</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Intel Adds Wireless Chips Intel announced that...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9998</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Nvidia To Build New GeForce X800 GPU Nvidia to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>9999</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Cops Bust 28 Cybercrimes AP AP - A police offi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82e01a1e-45c3-4c2f-b630-a476300b80fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82e01a1e-45c3-4c2f-b630-a476300b80fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82e01a1e-45c3-4c2f-b630-a476300b80fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3db1ac45-42cb-4332-9fde-288bd6dd647f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3db1ac45-42cb-4332-9fde-288bd6dd647f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3db1ac45-42cb-4332-9fde-288bd6dd647f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_27cfea11-0678-40d7-9868-49e3c5274063\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_text')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_27cfea11-0678-40d7-9868-49e3c5274063 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_text');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      Unnamed: 0                           prompt  \\\n",
              "0              0  Write a Science/Technology News   \n",
              "1              1  Write a Science/Technology News   \n",
              "2              2  Write a Science/Technology News   \n",
              "3              3  Write a Science/Technology News   \n",
              "4              4  Write a Science/Technology News   \n",
              "...          ...                              ...   \n",
              "9995        9995  Write a Science/Technology News   \n",
              "9996        9996  Write a Science/Technology News   \n",
              "9997        9997  Write a Science/Technology News   \n",
              "9998        9998  Write a Science/Technology News   \n",
              "9999        9999  Write a Science/Technology News   \n",
              "\n",
              "                                                   text  label  \n",
              "0     Oracle, SBC reach Deal to Buy Oracle Business ...      1  \n",
              "1     Yahoo Offers Online Music Search, PayPal Reute...      1  \n",
              "2     Toshiba to unveil notebook memory unit Toshiba...      1  \n",
              "3     Nvidia Introduces Powerful 3G G5 GPU Nvidia Co...      1  \n",
              "4     AOL Offers Web-Swap Service Microsoft has intr...      1  \n",
              "...                                                 ...    ...  \n",
              "9995  NASA 39s Titan Probe lands on Mars NASA offici...      1  \n",
              "9996  Microsoft updates Windows XP update Microsoft ...      1  \n",
              "9997  Intel Adds Wireless Chips Intel announced that...      1  \n",
              "9998  Nvidia To Build New GeForce X800 GPU Nvidia to...      1  \n",
              "9999  Cops Bust 28 Cybercrimes AP AP - A police offi...      1  \n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RFcEBQAIca2s"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=3.3, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=729)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2y5b-mASca2s"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=3.7, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=729)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GxTc6YqSca2t"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=4.1, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=729)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5o2SjFeLQmB"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=4.1, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=87)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_33.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaUmaRKrvWP3",
        "outputId": "8d731ae0-57b1-412c-e8d5-6a9728b9fb6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.9788, {1: 0.9788})\n"
          ]
        }
      ],
      "source": [
        "dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "#js = calculate_self_jaccard_similarity(df_text)\n",
        "print(bert_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzzDyd1Gwd3r",
        "outputId": "e461ccfb-4a70-4e1c-d4bb-cde03393adc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0490165905529873\n"
          ]
        }
      ],
      "source": [
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sH98BuKWca2t"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=4.7, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=729)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_4.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItSLpL1Hca2t"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=50, temperature=4.7, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=729)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_5.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkScfu4mca2t"
      },
      "outputs": [],
      "source": [
        "df_original0 = df_train[df_train['label']==0]\n",
        "original_texts0 = df_original0['text'].tolist()\n",
        "original_embeddings0 = get_embeddings(original_texts0)\n",
        "mu_orig0, sigma_orig0 = calculate_mean_covariance(original_embeddings0)\n",
        "df_original1 = df_train[df_train['label']==1]\n",
        "original_texts1 = df_original1['text'].tolist()\n",
        "original_embeddings1 = get_embeddings(original_texts1)\n",
        "mu_orig1, sigma_orig1 = calculate_mean_covariance(original_embeddings1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgEo9dxGca2t",
        "outputId": "0d792f8a-5a2f-43a3-cb69-8bdece34ae26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3264456599742505\n",
            "(0.9734, {1: 0.9734})\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_5.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)\n",
        "dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "\n",
        "print(bert_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGXPJ1LZca2t",
        "outputId": "d9a1d363-1984-4e26-dcd7-4cf9a23b55f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2600258330227123\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_3.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI-uo5gKca2u",
        "outputId": "5febefd3-d675-4a62-d747-fd129bf5ef90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.818059932058354\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_4.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Mvt0RQFgca2u",
        "outputId": "1d254333-c578-4511-86a2-c04099ce4c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.9761, {1: 0.9761})\n",
            "{1: 0.07091136734796893}\n"
          ]
        }
      ],
      "source": [
        "df_text2=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_2.csv\")\n",
        "dataset = TextDataset(dataframe=df_text2, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text2)\n",
        "print(bert_acc)\n",
        "print(js)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "collapsed": true,
        "id": "qdhkFlZnca2u",
        "outputId": "f6578d29-10a3-4f27-aad9-5386d8ed42d7"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1b4c4ee9c0e7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbert_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_self_jaccard_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_text3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-d8b090a4b1ff>\u001b[0m in \u001b[0;36mcalculate_self_jaccard_similarity\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mjaccard_similarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjaccard_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaccard_similarities\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjaccard_similarities\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-d8b090a4b1ff>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mjaccard_similarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjaccard_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaccard_similarities\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjaccard_similarities\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-d8b090a4b1ff>\u001b[0m in \u001b[0;36mjaccard_similarity\u001b[0;34m(text1, text2)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mset2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0munion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "df_text3=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_3.csv\")\n",
        "dataset = TextDataset(dataframe=df_text3, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text3)\n",
        "print(bert_acc)\n",
        "print(js)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PNMZGPTca2u",
        "outputId": "93a45b48-d9df-4f84-9a95-d36ebd1d2d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.9729, {1: 0.9729})\n"
          ]
        }
      ],
      "source": [
        "print(bert_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWpwxptPca2u",
        "outputId": "9072a3c6-20ae-4ed6-82f2-2d9063542616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.9213, {0: 0.9213})\n"
          ]
        }
      ],
      "source": [
        "df_text3=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class0_2.csv\")\n",
        "dataset = TextDataset(dataframe=df_text3, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "# js = calculate_self_jaccard_similarity(df_text3)\n",
        "print(bert_acc)\n",
        "# print(js)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSXWFPMQca2u",
        "outputId": "05b38f14-63f6-4391-c0a0-d921ce55b5ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.5251623554021747\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class0_2.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig0, sigma_orig0, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm_a3dq9Vx9r"
      },
      "source": [
        "## load model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x3yiIbwVx9r"
      },
      "outputs": [],
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "tokenizer = BartTokenizer.from_pretrained(\"/content/drive/MyDrive/model_723_bart_class1_epoch_29\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/model_723_bart_class1_epoch_29\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6TEPv2lVx9s",
        "outputId": "ad3d4b59-837f-4117-9afd-4916a66c9876"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(50265, 768, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.eval()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44MMWSoPVx9t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def generate_text_with_beams(prompt, num_texts=5, temperature=1.0, top_k=50, top_p=0.95, min_length=50, max_length=320, num_beams=5, no_repeat_ngram_size=2, early_stopping=True, seed=42, repetition_penalty=1.5):\n",
        "    if seed is not None:\n",
        "        set_seeds(seed)\n",
        "    model.eval()\n",
        "    generated_texts = []\n",
        "    for _ in range(num_texts):\n",
        "        # Encode the prompt to generate input_ids and attention_mask\n",
        "        encoding = tokenizer(prompt, return_tensors='pt', padding='max_length', max_length=max_length, truncation=True)\n",
        "        input_ids = encoding['input_ids'].to(model.device)\n",
        "        attention_mask = encoding['attention_mask'].to(model.device)\n",
        "\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,  # Include attention mask in generation\n",
        "            min_length=min_length,\n",
        "            max_length=max_length,\n",
        "            num_beams=num_beams,\n",
        "            num_return_sequences=1,  # Generate one sequence at a time to ensure diversity\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "            repetition_penalty=repetition_penalty,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            early_stopping=early_stopping\n",
        "        )\n",
        "\n",
        "        text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        generated_texts.append(text)\n",
        "\n",
        "    return generated_texts\n",
        "\n",
        "def generate_text(top_p, top_k, temperature, num_beams=5, num_texts=20, seed=42, repetition_penalty=1.2):\n",
        "    prompts = [ \"Write a Science/Technology News\"]\n",
        "    all_prompts = []\n",
        "    all_texts = []\n",
        "\n",
        "    for prompt in prompts:\n",
        "        generated_texts_for_prompt = []\n",
        "        num_iterations = num_texts // num_beams\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "            set_seeds(seed + i)\n",
        "            generated_texts = generate_text_with_beams(\n",
        "                prompt=prompt,\n",
        "                num_texts=num_beams,\n",
        "                temperature=temperature,\n",
        "                top_k=top_k,\n",
        "                top_p=top_p,\n",
        "                min_length=50,\n",
        "                max_length=200,  # Adjust max_length as needed\n",
        "                num_beams=num_beams,\n",
        "                no_repeat_ngram_size=2,\n",
        "                early_stopping=True,  # Enable early stopping\n",
        "                seed=seed + i,  # Adjust seed for each batch to maintain diversity while being reproducible\n",
        "                repetition_penalty=repetition_penalty  # Adding repetition penalty\n",
        "            )\n",
        "            generated_texts_for_prompt.extend(generated_texts)\n",
        "\n",
        "        # Ensure uniqueness and limit to the desired number of texts\n",
        "        unique_texts = list(set(generated_texts_for_prompt))[:num_texts]\n",
        "        all_prompts.extend([prompt] * len(unique_texts))\n",
        "        all_texts.extend(unique_texts)\n",
        "\n",
        "    return pd.DataFrame({'prompt': all_prompts, 'text': all_texts})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWfstHMKVGJ1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=320):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.targets = dataframe.label\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT4sXzjAUvmd"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/planB/bert/BERT_baseline_723_2')\n",
        "bert_model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/planB/bert/BERT_baseline_723_2', num_labels=2)\n",
        "bert_model.to(device)\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "            logits = outputs.logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "            predictions.extend(np.argmax(logits, axis=1).flatten())\n",
        "            true_labels.extend(label_ids.flatten())\n",
        "\n",
        "    avg_accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    # Calculate accuracy for each class\n",
        "    class_accuracies = defaultdict(list)\n",
        "    for true, pred in zip(true_labels, predictions):\n",
        "        class_accuracies[true].append(pred == true)\n",
        "\n",
        "    class_accuracy_results = {label: np.mean(acc) for label, acc in class_accuracies.items()}\n",
        "\n",
        "    return avg_accuracy, class_accuracy_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6tKRWtyVXTt",
        "outputId": "4bb37c27-e9cb-447e-cb2b-38b7148ee161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.10.1 sacrebleu-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sacrebleu\n",
        "\n",
        "def calculate_self_bleu(texts):\n",
        "    scores = []\n",
        "    for i, target in enumerate(texts):\n",
        "        references = texts[:i] + texts[i+1:]\n",
        "        bleu_score = sacrebleu.corpus_bleu([target], [references]).score\n",
        "        scores.append(bleu_score)\n",
        "    return np.mean(scores)\n",
        "\n",
        "def calculate_self_bleu_per_class(df):\n",
        "    class_bleu_scores = {}\n",
        "    for label, group in df.groupby('label'):\n",
        "        texts = group['text'].tolist()\n",
        "        self_bleu_score = calculate_self_bleu(texts)\n",
        "        class_bleu_scores[label] = self_bleu_score\n",
        "    return class_bleu_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAzXLqCuVc9l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import jaccard_score\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate Jaccard Similarity between two texts\n",
        "def jaccard_similarity(text1, text2):\n",
        "    set1 = set(text1.split())\n",
        "    set2 = set(text2.split())\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union) if len(union) > 0 else 0\n",
        "\n",
        "# Function to calculate mean Jaccard similarity within each class\n",
        "def calculate_self_jaccard_similarity(df):\n",
        "    results = {}\n",
        "    for label, group in df.groupby('label'):\n",
        "        jaccard_similarities = [jaccard_similarity(text1, text2) for text1, text2 in combinations(group['text'], 2)]\n",
        "        results[label] = np.mean(jaccard_similarities) if jaccard_similarities else 0\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1fUW7ACVkMn"
      },
      "outputs": [],
      "source": [
        "label_map2 = {\"Write a Business News\":0, \"Write a Science/Technology News\":1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "5eca4793b18a4396b6de239114dfd27a",
            "6298b48d9e1048f2a13f53b10337fdcb",
            "d7b13549a76f4f008b165109c39a65fd",
            "19bf9040e6974f04a5cfdb6d82d4e487",
            "f6cbccd5dc6f489ab6ec0cc9ba0bca57",
            "7d21b013b0124192b6ceb6aa0e792bbb",
            "121102cf31c741da8bae1ef3eec96e87",
            "352eb9e459da4ce2a8a3dea76501cbdc",
            "bb8cd6a4084e46388e040eba51494844",
            "835fd2be7a034aa6959a975af8ad37bd",
            "550d6b585bf4438996a0de7efb97409a",
            "5007018b24154715bc1bc95a6d9ae0a9",
            "dff1421d80f047c287c4040544716f7b",
            "6f189b1ebda94401b40b5461d3695cca",
            "dba11c9bd561429f8a3437324be918b3",
            "e4279e23edea477d863ec0e9101806ed",
            "dbebaf5b6e6f490d8d5854a7f9235efb",
            "7e61e63ace0147289e8ec46bf9f20e70",
            "a11d248e1cbd463fb8312c73e0d41e15",
            "f98bcd03e71e4df9883a3a0cc53bdb1f",
            "4b55a2d6b2294c3bacc6828b29d2d949",
            "27a2398b4e5c4d6a8f29814e4e1564d7",
            "612ea9f54b1d404bae3558fdd4f66281",
            "01f91fcb48ae40e0b8e6c678640f2d4e",
            "eceb1b364b1b42adac2363aeb9d9211b",
            "f50b3a2246d54c41b489401c6876cc7c",
            "79570a119b2644d9abff42c1f21f1845",
            "46912612be9948dda1878ebaef738d21",
            "1853bd4bbda247149132f3043fa15794",
            "63c7ffbf49cf492e8abe0fba71c64498",
            "d66803ffcfc4477f9907a9fd7df62111",
            "e2100fafd7834280adfbc0a09f613012",
            "642e845b86e64bbf8d96ae449ae81286",
            "a222037e329c4df3a75449bf5d99d5ce",
            "7e2f5a47f17548d69450b3ee74a330e0",
            "f1908beaf0f74ff699e3ef6a9ae1d0da",
            "b60e9ae4857b4a918a74ecedf6818e49",
            "3e321b94c50a48e29bdf005e193e6e39",
            "b7d0dad210084e35ad21765a4f25a8fc",
            "0e88c6686aff4c978cfd0a503267f01f",
            "0a9b37d37d384e20895a7108c7f9bfd5",
            "abf99e1640b54091baf325401902a584",
            "d67c541ceff04f3981738b4cbaa3b48c",
            "f5529df313af4f8bb30f66c1e34d068c",
            "96b3597ade8848658328e82181fd70de",
            "a434a19a9f02442d80677f0fca4ef813",
            "5231a93c921d4e11b6cb89a427701224",
            "60235bd73bbd49e9ab9db45a38a29ee6",
            "2279aba93d5141f0b3148dd2071e5e32",
            "51e060af084f4753be03de2cf61fec20",
            "c443d4b9f919489d962aeef64f2e0caa",
            "839053455f8e4c1c9ba9b09ae6667695",
            "c8b5d3888e7b463ba6cd50a1e97e4558",
            "e036d26f23524cb88e12f81ee18b9b91",
            "d53592505afe48f99668a494e72e0051"
          ]
        },
        "collapsed": true,
        "id": "Wf_jz13j_Zui",
        "outputId": "5260f429-c735-41c3-c627-b8f153bec9c0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5eca4793b18a4396b6de239114dfd27a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5007018b24154715bc1bc95a6d9ae0a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "612ea9f54b1d404bae3558fdd4f66281",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a222037e329c4df3a75449bf5d99d5ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96b3597ade8848658328e82181fd70de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from scipy.linalg import sqrtm\n",
        "import pandas as pd\n",
        "\n",
        "# Load BERT model and tokenizer\n",
        "bert_tokenizer_base = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model_base = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model_base.to(device)\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        inputs = bert_tokenizer_base(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=320)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = bert_model_base(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "        all_embeddings.append(embeddings.cpu().numpy())\n",
        "        torch.cuda.empty_cache()  # Clear unused memory\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Function to calculate mean and covariance\n",
        "def calculate_mean_covariance(embeddings):\n",
        "    mu = np.mean(embeddings, axis=0)\n",
        "    sigma = np.cov(embeddings, rowvar=False)\n",
        "    return mu, sigma\n",
        "\n",
        "# Function to compute Fréchet Distance\n",
        "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2):\n",
        "    diff = mu1 - mu2\n",
        "    covmean, _ = sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "    return np.sum(diff**2) + np.trace(sigma1 + sigma2 - 2*covmean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-ixJa6D-rDJ"
      },
      "outputs": [],
      "source": [
        "df_original0 = df_train[df_train['label']==0].sample(n=500, random_state=13)\n",
        "original_texts0 = df_original0['text'].tolist()\n",
        "original_embeddings0 = get_embeddings(original_texts0)\n",
        "df_original1 = df_train[df_train['label']==1].sample(n=500, random_state=13)\n",
        "original_texts1 = df_original1['text'].tolist()\n",
        "original_embeddings1 = get_embeddings(original_texts1)\n",
        "mu_orig0, sigma_orig0 = calculate_mean_covariance(original_embeddings0)\n",
        "mu_orig1, sigma_orig1 = calculate_mean_covariance(original_embeddings1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IysSuMR97zfp",
        "outputId": "a7e5ace9-af25-4895-f7bd-b612553cfaf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t: 1.3\n",
            "bert accuracy: (0.5235235235235235, {0: 0.096, 1: 0.9519038076152304})\n",
            "Jaccard similarities: {0: 0.0870428760938569, 1: 0.08918436004448158}\n",
            "Self-BLEU: {0: 2.5848432761452704, 1: 3.8890658419179096}\n",
            "10.2625502824106\n",
            "t: 1.5\n",
            "bert accuracy: (0.527, {0: 0.086, 1: 0.968})\n",
            "Jaccard similarities: {0: 0.0871861712305975, 1: 0.0871673449568837}\n",
            "Self-BLEU: {0: 2.210022240370516, 1: 2.179241245277493}\n",
            "7.953333606089343\n",
            "t: 1.7\n",
            "bert accuracy: (0.51, {0: 0.048, 1: 0.972})\n",
            "Jaccard similarities: {0: 0.08734991385116816, 1: 0.08509917597381911}\n",
            "Self-BLEU: {0: 2.3674546869335504, 1: 2.3430414437151494}\n",
            "7.832641944434352\n",
            "t: 1.9\n",
            "bert accuracy: (0.496, {0: 0.036, 1: 0.956})\n",
            "Jaccard similarities: {0: 0.0833946824675723, 1: 0.08243804312171027}\n",
            "Self-BLEU: {0: 1.2384418495637588, 1: 1.429856907100955}\n",
            "7.610371144073297\n"
          ]
        }
      ],
      "source": [
        "for t in [1.3,1.5,1.7,1.9]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=45, temperature=t, num_beams=4 , num_texts=500, repetition_penalty=1.7,seed=724)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  df_generate1 = df_text[df_text['label']==1]\n",
        "  generated_texts1 = df_generate1['text'].tolist()\n",
        "  generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "  mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "\n",
        "  fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "  print(f\"t: {t}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7ejAfubyIF6",
        "outputId": "e622a92b-9ee6-4ef2-d893-8c69fd510f00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t: 2.3\n",
            "bert accuracy: (0.968, {1: 0.968})\n",
            "Jaccard similarities: {1: 0.07856889008398389}\n",
            "Self-BLEU: {1: 2.2337209393695687}\n",
            "6.470097626178939\n",
            "t: 2.5\n",
            "bert accuracy: (0.964, {1: 0.964})\n",
            "Jaccard similarities: {1: 0.07703429900280309}\n",
            "Self-BLEU: {1: 1.823258597857071}\n",
            "6.115016316086627\n",
            "t: 2.7\n",
            "bert accuracy: (0.988, {1: 0.988})\n",
            "Jaccard similarities: {1: 0.07674379726623658}\n",
            "Self-BLEU: {1: 1.3668650412744474}\n",
            "5.5990748459883575\n",
            "t: 2.9\n",
            "bert accuracy: (0.978, {1: 0.978})\n",
            "Jaccard similarities: {1: 0.07657324046299654}\n",
            "Self-BLEU: {1: 1.4529860283786133}\n",
            "5.109976781355443\n",
            "t: 3.1\n",
            "bert accuracy: (0.964, {1: 0.964})\n",
            "Jaccard similarities: {1: 0.07446818667907666}\n",
            "Self-BLEU: {1: 1.9603892499531566}\n",
            "4.921762779387917\n"
          ]
        }
      ],
      "source": [
        "for t in [2.3,2.5,2.7,2.9,3.1]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=45, temperature=t, num_beams=4 , num_texts=500, repetition_penalty=1.7,seed=724)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  df_generate1 = df_text[df_text['label']==1]\n",
        "  generated_texts1 = df_generate1['text'].tolist()\n",
        "  generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "  mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "\n",
        "  fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "  print(f\"t: {t}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpWGjGtQCoMz",
        "outputId": "e71f7808-d94b-4127-a4e6-737ddece46c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t: 3.3\n",
            "bert accuracy: (0.978, {1: 0.978})\n",
            "Jaccard similarities: {1: 0.07415329918789852}\n",
            "Self-BLEU: {1: 1.3921928858021606}\n",
            "4.649758382979603\n",
            "t: 3.7\n",
            "bert accuracy: (0.97, {1: 0.97})\n",
            "Jaccard similarities: {1: 0.06986815749740463}\n",
            "Self-BLEU: {1: 0.915999204020242}\n",
            "4.173382348133012\n"
          ]
        }
      ],
      "source": [
        "for t in [3.3,3.7]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=45, temperature=t, num_beams=4 , num_texts=500, repetition_penalty=1.7,seed=724)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  df_generate1 = df_text[df_text['label']==1]\n",
        "  generated_texts1 = df_generate1['text'].tolist()\n",
        "  generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "  mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "\n",
        "  fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "  print(f\"t: {t}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bYqiWaDMXxR",
        "outputId": "abf5c1c4-b054-4d85-c3c9-a95f57bdb213"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Fossil finds clues of dinosaur DNA fossil AP AP - A fossil described by the scientists who unearthed it has yielded hints of an extinct human origin, suggesting that dinosaurs may have been common to early human sexual history.What could prove? Researchers say they have found a fossil of some sort that suggests that possibly contains dinosaur bones dating back to pre-Genetic era times and suggest that the discovery is very likely to lead to ',\n",
              " 'New media tools should make the DVD players obsolete Apple Computer is making its iPod more portable--but it 39s going to take some time. By Kim Kasser. MacKasser and Paul Goulston of Phony Ink Designs have made their mark.']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_text[0:2].text.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf2CMGsEVx9u",
        "outputId": "f1982306-c854-4c06-d654-9a1b6cbb20bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k: 40\n",
            "bert accuracy: (0.964, {1: 0.964})\n",
            "Jaccard similarities: {1: 0.0682727366999546}\n",
            "Self-BLEU: {1: 1.1570350197425474}\n",
            "4.166705736035113\n",
            "k: 45\n",
            "bert accuracy: (0.978, {1: 0.978})\n",
            "Jaccard similarities: {1: 0.06839764380336283}\n",
            "Self-BLEU: {1: 0.7580151667208217}\n",
            "4.189978223949332\n",
            "k: 50\n",
            "bert accuracy: (0.972, {1: 0.972})\n",
            "Jaccard similarities: {1: 0.0656722755049557}\n",
            "Self-BLEU: {1: 1.1663597529016727}\n",
            "4.0101031876121525\n",
            "k: 55\n",
            "bert accuracy: (0.982, {1: 0.982})\n",
            "Jaccard similarities: {1: 0.0671324449138463}\n",
            "Self-BLEU: {1: 1.0160026353780716}\n",
            "4.208755718388127\n"
          ]
        }
      ],
      "source": [
        "for k in [40,45,50,55]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=k, temperature=4.7, num_beams=4 , num_texts=500, repetition_penalty=1.7,seed=724)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  df_generate1 = df_text[df_text['label']==1]\n",
        "  generated_texts1 = df_generate1['text'].tolist()\n",
        "  generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "  mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "\n",
        "  fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "  print(f\"k: {k}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  print(fid1)\n",
        "  ## this one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23iYirVlZOXv",
        "outputId": "f5197591-da68-4a88-8376-cedc44ea071f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rp: 1\n",
            "bert accuracy: (0.966, {1: 0.966})\n",
            "Jaccard similarities: {1: 0.06118992783874104}\n",
            "Self-BLEU: {1: 1.1189134341952551}\n",
            "4.056347966117926\n",
            "rp: 1.3\n",
            "bert accuracy: (0.97, {1: 0.97})\n",
            "Jaccard similarities: {1: 0.06542907639020785}\n",
            "Self-BLEU: {1: 0.9900671090866908}\n",
            "4.067178225486829\n",
            "rp: 2.1\n",
            "bert accuracy: (0.974, {1: 0.974})\n",
            "Jaccard similarities: {1: 0.06836704852548661}\n",
            "Self-BLEU: {1: 1.261080344945408}\n",
            "4.230261224738015\n",
            "rp: 2.5\n",
            "bert accuracy: (0.976, {1: 0.976})\n",
            "Jaccard similarities: {1: 0.06711456412539314}\n",
            "Self-BLEU: {1: 1.0941211899525527}\n",
            "4.214707249644949\n"
          ]
        }
      ],
      "source": [
        "for rp in [1,1.3,2.1,2.5]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=50, temperature=4.7, num_beams=4 , num_texts=500, repetition_penalty=rp,seed=724)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  df_generate1 = df_text[df_text['label']==1]\n",
        "  generated_texts1 = df_generate1['text'].tolist()\n",
        "  generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "  mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "\n",
        "  fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "  print(f\"rp: {rp}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  print(fid1)\n",
        "  ## this one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmXlOeItVR6u",
        "outputId": "d4cde963-b481-4c7c-ecf4-3723e260a4f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Nasa spacecraft to strike strike Saturn Tonight NASA will enter space with its first unmanned craft of the future, after a successful corvette launched into the international space port at 1102 AM Pacific time Wednesday. Space craft would be the first humans to do so ',\n",
              " 'FCC Cuts Price On Computer Software The European Computer Association CPDA has dropped its price on computer software - a move that could encourage manufacturers to add the software products, but is likely to draw regulatory opposition for such products. PLC will provide a link for its Web site. ltFONT faceverdana']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_text[0:2].text.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBuU_68nV5uN"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=3.1, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=729)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_0.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZGNIjUB_hKc"
      },
      "outputs": [],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_0.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeBkVMxcKs47",
        "outputId": "ead8efeb-671c-4dfb-c695-1c922651b190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.9768, {1: 0.9768})\n",
            "{1: 0.07442262581479629}\n"
          ]
        }
      ],
      "source": [
        "dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text)\n",
        "print(bert_acc)\n",
        "print(js)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRE258QuOqG9",
        "outputId": "40b5c9ee-8916-44cb-b346-35e993a3ba4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.9779, {1: 0.9779})\n",
            "{1: 0.07319351211725297}\n"
          ]
        }
      ],
      "source": [
        "df_text1=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_1.csv\")\n",
        "dataset = TextDataset(dataframe=df_text1, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text1)\n",
        "print(bert_acc)\n",
        "print(js)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN5e7-MAaKjs",
        "outputId": "eb7b5d47-1d37-42f1-b0c4-1cc042c30684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.9779, {1: 0.9779})\n",
            "{1: 0.07091136734796893}\n"
          ]
        }
      ],
      "source": [
        "df_text2=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_2.csv\")\n",
        "dataset = TextDataset(dataframe=df_text1, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text2)\n",
        "print(bert_acc)\n",
        "print(js)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap93R1YEfxeq",
        "outputId": "66127cbb-7337-4f7a-84ae-5bf645ff70ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.8417605206148489\n"
          ]
        }
      ],
      "source": [
        "df_original1 = df_train[df_train['label']==1][0:1000]\n",
        "original_texts1 = df_original1['text'].tolist()\n",
        "original_embeddings1 = get_embeddings(original_texts1)\n",
        "mu_orig1, sigma_orig1 = calculate_mean_covariance(original_embeddings1)\n",
        "df_generate1 = df_train[df_train['label']==1][1000:2000]\n",
        "generated_texts1 = df_generate1['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_saadm7gjtp",
        "outputId": "5a460abb-e3be-4024-da6e-2d7a8a781b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.183885243008145\n"
          ]
        }
      ],
      "source": [
        "df_original1 = df_train[df_train['label']==1][0:1000]\n",
        "original_texts1 = df_original1['text'].tolist()\n",
        "original_embeddings1 = get_embeddings(original_texts1)\n",
        "mu_orig1, sigma_orig1 = calculate_mean_covariance(original_embeddings1)\n",
        "df_generate1 = df_train[df_train['label']==0][1000:2000]\n",
        "generated_texts1 = df_generate1['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKaV2tr5gED4",
        "outputId": "85f75a2d-a8d4-4126-dc0e-85d0d39eff73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.21268893045666\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_0.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvJo1TwnhTOp",
        "outputId": "125f6042-df1d-459c-f8ee-e6211507c624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.0926786144048206\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_1.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqHViOn1hWg5",
        "outputId": "51d0e0d3-07b3-4c21-8745-4a9b462e3791"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.782454053963\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_2.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "T6sswhq3kUD4",
        "outputId": "b438d18f-52bf-4d78-b067-6bb691e10c83"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_text\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2886,\n        \"min\": 0,\n        \"max\": 9999,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          6252,\n          4684,\n          1731\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Write a Science/Technology News\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"SAP to support Oracle in court In a move designed to create an argument that Oracle Inc. and other groups are violating an antitrust law, SAP announced yesterday that it has joined the Electronic Data Systems Association 39s fight to block Oracle from selling its controversial Net-portable storage appliance SEAP Internet Explorer. SAP claimed to be the first global vendor to sue Oracle for copyright violations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_text"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-82e01a1e-45c3-4c2f-b630-a476300b80fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>prompt</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Oracle, SBC reach Deal to Buy Oracle Business ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Yahoo Offers Online Music Search, PayPal Reute...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Toshiba to unveil notebook memory unit Toshiba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Nvidia Introduces Powerful 3G G5 GPU Nvidia Co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>AOL Offers Web-Swap Service Microsoft has intr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9995</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>NASA 39s Titan Probe lands on Mars NASA offici...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9996</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Microsoft updates Windows XP update Microsoft ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9997</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Intel Adds Wireless Chips Intel announced that...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9998</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Nvidia To Build New GeForce X800 GPU Nvidia to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>9999</td>\n",
              "      <td>Write a Science/Technology News</td>\n",
              "      <td>Cops Bust 28 Cybercrimes AP AP - A police offi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82e01a1e-45c3-4c2f-b630-a476300b80fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82e01a1e-45c3-4c2f-b630-a476300b80fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82e01a1e-45c3-4c2f-b630-a476300b80fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3db1ac45-42cb-4332-9fde-288bd6dd647f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3db1ac45-42cb-4332-9fde-288bd6dd647f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3db1ac45-42cb-4332-9fde-288bd6dd647f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_27cfea11-0678-40d7-9868-49e3c5274063\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_text')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_27cfea11-0678-40d7-9868-49e3c5274063 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_text');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      Unnamed: 0                           prompt  \\\n",
              "0              0  Write a Science/Technology News   \n",
              "1              1  Write a Science/Technology News   \n",
              "2              2  Write a Science/Technology News   \n",
              "3              3  Write a Science/Technology News   \n",
              "4              4  Write a Science/Technology News   \n",
              "...          ...                              ...   \n",
              "9995        9995  Write a Science/Technology News   \n",
              "9996        9996  Write a Science/Technology News   \n",
              "9997        9997  Write a Science/Technology News   \n",
              "9998        9998  Write a Science/Technology News   \n",
              "9999        9999  Write a Science/Technology News   \n",
              "\n",
              "                                                   text  label  \n",
              "0     Oracle, SBC reach Deal to Buy Oracle Business ...      1  \n",
              "1     Yahoo Offers Online Music Search, PayPal Reute...      1  \n",
              "2     Toshiba to unveil notebook memory unit Toshiba...      1  \n",
              "3     Nvidia Introduces Powerful 3G G5 GPU Nvidia Co...      1  \n",
              "4     AOL Offers Web-Swap Service Microsoft has intr...      1  \n",
              "...                                                 ...    ...  \n",
              "9995  NASA 39s Titan Probe lands on Mars NASA offici...      1  \n",
              "9996  Microsoft updates Windows XP update Microsoft ...      1  \n",
              "9997  Intel Adds Wireless Chips Intel announced that...      1  \n",
              "9998  Nvidia To Build New GeForce X800 GPU Nvidia to...      1  \n",
              "9999  Cops Bust 28 Cybercrimes AP AP - A police offi...      1  \n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yelFtXdcVtiu"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=3.3, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=729)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-TWWSKBuVzwe"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=3.7, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=729)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "os5aS084Q706"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=4.1, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=729)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jtxWXJJ0StyW"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=45, temperature=4.7, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=729)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_4.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDefCCjfLbdY"
      },
      "outputs": [],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=50, temperature=4.7, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=729)\n",
        "df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "df_text.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_5.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCNpjam7l7q1"
      },
      "outputs": [],
      "source": [
        "df_original0 = df_train[df_train['label']==0]\n",
        "original_texts0 = df_original0['text'].tolist()\n",
        "original_embeddings0 = get_embeddings(original_texts0)\n",
        "mu_orig0, sigma_orig0 = calculate_mean_covariance(original_embeddings0)\n",
        "df_original1 = df_train[df_train['label']==1]\n",
        "original_texts1 = df_original1['text'].tolist()\n",
        "original_embeddings1 = get_embeddings(original_texts1)\n",
        "mu_orig1, sigma_orig1 = calculate_mean_covariance(original_embeddings1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v96oc92oeC0_",
        "outputId": "0d792f8a-5a2f-43a3-cb69-8bdece34ae26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3264456599742505\n",
            "(0.9734, {1: 0.9734})\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_5.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)\n",
        "dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "\n",
        "print(bert_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Yix3D19alYu",
        "outputId": "d9a1d363-1984-4e26-dcd7-4cf9a23b55f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2600258330227123\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_3.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IZBYIphanTu",
        "outputId": "5febefd3-d675-4a62-d747-fd129bf5ef90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.818059932058354\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_4.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig1, sigma_orig1, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZYJ3HcK0dfjV",
        "outputId": "1d254333-c578-4511-86a2-c04099ce4c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.9761, {1: 0.9761})\n",
            "{1: 0.07091136734796893}\n"
          ]
        }
      ],
      "source": [
        "df_text2=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_2.csv\")\n",
        "dataset = TextDataset(dataframe=df_text2, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text2)\n",
        "print(bert_acc)\n",
        "print(js)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "collapsed": true,
        "id": "U-wJTZB3dRj-",
        "outputId": "f6578d29-10a3-4f27-aad9-5386d8ed42d7"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1b4c4ee9c0e7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbert_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_self_jaccard_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_text3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-d8b090a4b1ff>\u001b[0m in \u001b[0;36mcalculate_self_jaccard_similarity\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mjaccard_similarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjaccard_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaccard_similarities\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjaccard_similarities\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-d8b090a4b1ff>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mjaccard_similarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjaccard_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaccard_similarities\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjaccard_similarities\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-d8b090a4b1ff>\u001b[0m in \u001b[0;36mjaccard_similarity\u001b[0;34m(text1, text2)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mset2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0munion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "df_text3=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class1_3.csv\")\n",
        "dataset = TextDataset(dataframe=df_text3, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text3)\n",
        "print(bert_acc)\n",
        "print(js)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6NQkrmpojOd",
        "outputId": "93a45b48-d9df-4f84-9a95-d36ebd1d2d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.9729, {1: 0.9729})\n"
          ]
        }
      ],
      "source": [
        "print(bert_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_RBOGZFd8FT",
        "outputId": "9072a3c6-20ae-4ed6-82f2-2d9063542616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.9213, {0: 0.9213})\n"
          ]
        }
      ],
      "source": [
        "df_text3=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class0_2.csv\")\n",
        "dataset = TextDataset(dataframe=df_text3, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "# js = calculate_self_jaccard_similarity(df_text3)\n",
        "print(bert_acc)\n",
        "# print(js)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMOP5o9ed76T",
        "outputId": "05b38f14-63f6-4391-c0a0-d921ce55b5ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.5251623554021747\n"
          ]
        }
      ],
      "source": [
        "df_text=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart_class0_2.csv\")\n",
        "generated_texts1 = df_text['text'].tolist()\n",
        "generated_embeddings1 = get_embeddings(generated_texts1)\n",
        "mu_gen1, sigma_gen1 = calculate_mean_covariance(generated_embeddings1)\n",
        "fid1 = calculate_frechet_distance(mu_orig0, sigma_orig0, mu_gen1, sigma_gen1)\n",
        "print(fid1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SevC0tsTVsVl"
      },
      "source": [
        "## other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKLYRoQdMfch"
      },
      "outputs": [],
      "source": [
        "df_text1 = generate_text(top_p=0.95, top_k=50, temperature=1.2, num_beams=4 , num_texts=10000, repetition_penalty=1.7,seed=724)\n",
        "df_text1['label'] = df_text1['prompt'].map(label_map2)\n",
        "df_text1.to_csv(\"/content/drive/MyDrive/planB/df_generated_bartall_0.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "rZJ0aRF-6pM2",
        "outputId": "46299993-5152-4330-8f82-ba364e400d08"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'generate_text' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bdf3bd7461cc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_text2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m724\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_text2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_text2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prompt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_text2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/planB/df_generated_bartall_1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generate_text' is not defined"
          ]
        }
      ],
      "source": [
        "df_text2 = generate_text(top_p=0.95, top_k=55, temperature=1.4, num_beams=4 , num_texts=10005, repetition_penalty=1.7,seed=724)\n",
        "df_text2['label'] = df_text2['prompt'].map(label_map2)\n",
        "df_text2.to_csv(\"/content/drive/MyDrive/planB/df_generated_bartall_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-wC1VcgxsiV"
      },
      "outputs": [],
      "source": [
        "dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfMoQ7DQVx90"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from scipy.linalg import sqrtm\n",
        "import pandas as pd\n",
        "\n",
        "# Load BERT model and tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to get embeddings\n",
        "def get_embeddings(texts):\n",
        "    inputs = bert_tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Use mean of token embeddings\n",
        "    return embeddings.numpy()\n",
        "\n",
        "# Function to calculate mean and covariance\n",
        "def calculate_mean_covariance(embeddings):\n",
        "    mu = np.mean(embeddings, axis=0)\n",
        "    sigma = np.cov(embeddings, rowvar=False)\n",
        "    return mu, sigma\n",
        "\n",
        "# Function to compute Fréchet Distance\n",
        "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2):\n",
        "    diff = mu1 - mu2\n",
        "    covmean, _ = sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "    return np.sum(diff**2) + np.trace(sigma1 + sigma2 - 2*covmean)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJVkXbCMVx90",
        "outputId": "593f5440-89d3-420e-d33a-6251b112bbfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fréchet Distance: 15.71881764392105\n"
          ]
        }
      ],
      "source": [
        "df_original = df_train[df_train['label']==2]\n",
        "df_generate = df_text0[df_text0['label']==0]\n",
        "original_texts = df_original['text'].tolist()\n",
        "generated_texts = df_generate['text'].tolist()\n",
        "original_embeddings = get_embeddings(original_texts)\n",
        "generated_embeddings = get_embeddings(generated_texts)\n",
        "\n",
        "# Calculate mean and covariance\n",
        "mu_orig, sigma_orig = calculate_mean_covariance(original_embeddings)\n",
        "mu_gen, sigma_gen = calculate_mean_covariance(generated_embeddings)\n",
        "\n",
        "# Compute Fréchet Distance\n",
        "fid = calculate_frechet_distance(mu_orig, sigma_orig, mu_gen, sigma_gen)\n",
        "print(\"Fréchet Distance:\", fid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-daexeOVx90",
        "outputId": "d9749897-fad2-48cd-c208-6795b867579d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fréchet Distance: 17.05582525451667\n"
          ]
        }
      ],
      "source": [
        "df_original = df_train[df_train['label']==3]\n",
        "df_generate = df_text0[df_text0['label']==1]\n",
        "original_texts = df_original['text'].tolist()\n",
        "generated_texts = df_generate['text'].tolist()\n",
        "original_embeddings = get_embeddings(original_texts)\n",
        "generated_embeddings = get_embeddings(generated_texts)\n",
        "\n",
        "# Calculate mean and covariance\n",
        "mu_orig, sigma_orig = calculate_mean_covariance(original_embeddings)\n",
        "mu_gen, sigma_gen = calculate_mean_covariance(generated_embeddings)\n",
        "\n",
        "# Compute Fréchet Distance\n",
        "fid = calculate_frechet_distance(mu_orig, sigma_orig, mu_gen, sigma_gen)\n",
        "print(\"Fréchet Distance:\", fid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUMx2J_2Vx91",
        "outputId": "cd032fa7-2f22-4485-cad2-2aa1b79f77d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fréchet Distance: 16.053433885655654\n"
          ]
        }
      ],
      "source": [
        "df_original = df_train[df_train['label']==2]\n",
        "df_generate = df_text1[df_text1['label']==0]\n",
        "original_texts = df_original['text'].tolist()\n",
        "generated_texts = df_generate['text'].tolist()\n",
        "original_embeddings = get_embeddings(original_texts)\n",
        "generated_embeddings = get_embeddings(generated_texts)\n",
        "\n",
        "# Calculate mean and covariance\n",
        "mu_orig, sigma_orig = calculate_mean_covariance(original_embeddings)\n",
        "mu_gen, sigma_gen = calculate_mean_covariance(generated_embeddings)\n",
        "\n",
        "# Compute Fréchet Distance\n",
        "fid = calculate_frechet_distance(mu_orig, sigma_orig, mu_gen, sigma_gen)\n",
        "print(\"Fréchet Distance:\", fid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVLbAZbSy30D",
        "outputId": "45d19352-308b-4cb9-e82a-cd4142a44ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fréchet Distance: 16.599486418833028\n"
          ]
        }
      ],
      "source": [
        "df_original = df_train[df_train['label']==3]\n",
        "df_generate = df_text1[df_text1['label']==1]\n",
        "original_texts = df_original['text'].tolist()\n",
        "generated_texts = df_generate['text'].tolist()\n",
        "original_embeddings = get_embeddings(original_texts)\n",
        "generated_embeddings = get_embeddings(generated_texts)\n",
        "\n",
        "# Calculate mean and covariance\n",
        "mu_orig, sigma_orig = calculate_mean_covariance(original_embeddings)\n",
        "mu_gen, sigma_gen = calculate_mean_covariance(generated_embeddings)\n",
        "\n",
        "# Compute Fréchet Distance\n",
        "fid = calculate_frechet_distance(mu_orig, sigma_orig, mu_gen, sigma_gen)\n",
        "print(\"Fréchet Distance:\", fid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUkUwZqQ7G64"
      },
      "outputs": [],
      "source": [
        "df_text1=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bartall_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTI8eWLN6uoE",
        "outputId": "782afaf3-ee9a-40f9-ad70-138c82e90e95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fréchet Distance: 12.20276166015872\n"
          ]
        }
      ],
      "source": [
        "df_original = df_train[df_train['label']==2]\n",
        "df_generate = df_text1[df_text1['label']==0]\n",
        "original_texts = df_original['text'].tolist()\n",
        "generated_texts = df_generate['text'].tolist()\n",
        "original_embeddings = get_embeddings(original_texts)\n",
        "generated_embeddings = get_embeddings(generated_texts)\n",
        "\n",
        "# Calculate mean and covariance\n",
        "mu_orig, sigma_orig = calculate_mean_covariance(original_embeddings)\n",
        "mu_gen, sigma_gen = calculate_mean_covariance(generated_embeddings)\n",
        "\n",
        "# Compute Fréchet Distance\n",
        "fid = calculate_frechet_distance(mu_orig, sigma_orig, mu_gen, sigma_gen)\n",
        "print(\"Fréchet Distance:\", fid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn5-FBuV3RgR",
        "outputId": "43c11723-ce00-4454-d2b4-6108109c841e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fréchet Distance: 1.3579296077970753\n"
          ]
        }
      ],
      "source": [
        "df_original = df_train[df_train['label']==2]\n",
        "df_generate = test_set[test_set['label']==2]\n",
        "original_texts = df_original['text'].tolist()\n",
        "generated_texts = df_generate['text'].tolist()\n",
        "original_embeddings = get_embeddings(original_texts)\n",
        "generated_embeddings = get_embeddings(generated_texts)\n",
        "\n",
        "# Calculate mean and covariance\n",
        "mu_orig, sigma_orig = calculate_mean_covariance(original_embeddings)\n",
        "mu_gen, sigma_gen = calculate_mean_covariance(generated_embeddings)\n",
        "\n",
        "# Compute Fréchet Distance\n",
        "fid = calculate_frechet_distance(mu_orig, sigma_orig, mu_gen, sigma_gen)\n",
        "print(\"Fréchet Distance:\", fid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sUhGG1gUzyU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTd9Jw8P3N8x",
        "outputId": "1c9e5910-3d43-40f2-fbbb-f184a2fa774e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.10.1 sacrebleu-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sacrebleu\n",
        "\n",
        "def calculate_self_bleu(texts):\n",
        "    scores = []\n",
        "    for i, target in enumerate(texts):\n",
        "        references = texts[:i] + texts[i+1:]\n",
        "        bleu_score = sacrebleu.corpus_bleu([target], [references]).score\n",
        "        scores.append(bleu_score)\n",
        "    return np.mean(scores)\n",
        "\n",
        "def calculate_self_bleu_per_class(df):\n",
        "    class_bleu_scores = {}\n",
        "    for label, group in df.groupby('label'):\n",
        "        texts = group['text'].tolist()\n",
        "        self_bleu_score = calculate_self_bleu(texts)\n",
        "        class_bleu_scores[label] = self_bleu_score\n",
        "    return class_bleu_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "XzqCSySj8DzC",
        "outputId": "e1e0f44d-4adc-4a99-e3d5-39334dc7f486"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-532415c92052>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_self_bleu_per_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_text1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-4c83ed91bcc8>\u001b[0m in \u001b[0;36mcalculate_self_bleu_per_class\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself_bleu_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_self_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mclass_bleu_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_bleu_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclass_bleu_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-4c83ed91bcc8>\u001b[0m in \u001b[0;36mcalculate_self_bleu\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mbleu_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msacrebleu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbleu_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sacrebleu/compat.py\u001b[0m in \u001b[0;36mcorpus_bleu\u001b[0;34m(hypotheses, references, smooth_method, smooth_value, force, lowercase, tokenize, use_effective_order)\u001b[0m\n\u001b[1;32m     35\u001b[0m         effective_order=use_effective_order)\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypotheses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sacrebleu/metrics/base.py\u001b[0m in \u001b[0;36mcorpus_score\u001b[0;34m(self, hypotheses, references, n_bootstrap)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# Collect corpus stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_corpus_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypotheses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;31m# Compute the actual system score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sacrebleu/metrics/base.py\u001b[0m in \u001b[0;36m_extract_corpus_statistics\u001b[0;34m(self, hypotheses, references)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;31m# Don't store the cache as the user is explicitly passing refs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0mref_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ref_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mref_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ref_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sacrebleu/metrics/base.py\u001b[0m in \u001b[0;36m_cache_references\u001b[0;34m(self, references)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# Get n-grams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0mref_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_reference_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_refs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sacrebleu/metrics/bleu.py\u001b[0m in \u001b[0;36m_extract_reference_info\u001b[0;34m(self, refs)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# extract n-grams for this ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mthis_ngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_all_word_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ngram_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mref_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sacrebleu/metrics/helpers.py\u001b[0m in \u001b[0;36mextract_all_word_ngrams\u001b[0;34m(line, min_order, max_order)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_order\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mngrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(calculate_self_bleu_per_class(df_text1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGlgFcR7A9tJ",
        "outputId": "d6a3f283-a848-40a2-e35d-bff6a87db4d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 0.14068970833247754}\n"
          ]
        }
      ],
      "source": [
        "text_1_0=df_text1[df_text1[\"label\"]==0].sample(n=1000, random_state=7)\n",
        "print(calculate_self_jaccard_similarity(text_1_0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bde9JriH8Qwb",
        "outputId": "b77cfb04-e7ae-4060-d5ba-725f02f5a2d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 0.14068970833247754}\n"
          ]
        }
      ],
      "source": [
        "text_1_1=df_text1[df_text1[\"label\"]==1].sample(n=1000, random_state=7)\n",
        "print(calculate_self_jaccard_similarity(text_1_0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lJEqaqGQsbl"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/planB/bert/BERT_baseline_723_6')\n",
        "bert_model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/planB/bert/BERT_baseline_723_6', num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v27Ru-DnQz61"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.targets = dataframe.label\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjNiOrFxQ1kl"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 320\n",
        "BATCH_SIZE = 16\n",
        "test_dataset = TextDataset(dataframe=df_text1, tokenizer=bert_tokenizer, max_len=MAX_LENGTH)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7UeOaaJQ3WV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()  # Put the model in evaluation mode\n",
        "\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "            logits = outputs.logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "            predictions.extend(np.argmax(logits, axis=1).flatten())\n",
        "            true_labels.extend(label_ids.flatten())\n",
        "\n",
        "    avg_accuracy = accuracy_score(true_labels, predictions)\n",
        "    print(f'Validation Accuracy: {avg_accuracy}')\n",
        "\n",
        "    # Detailed classification report\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(true_labels, predictions, target_names=['Class0', 'Class1']))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(true_labels, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHAftmDrRtbt",
        "outputId": "fc645e96-aa6a-41ef-b8c1-e44d960e15e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9343\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Class0       0.89      1.00      0.94     10000\n",
            "      Class1       0.99      0.87      0.93     10000\n",
            "\n",
            "    accuracy                           0.93     20000\n",
            "   macro avg       0.94      0.93      0.93     20000\n",
            "weighted avg       0.94      0.93      0.93     20000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[9954   46]\n",
            " [1268 8732]]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model.to(device)\n",
        "evaluate(bert_model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4YI7zdxklD2"
      },
      "outputs": [],
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "tokenizer = BartTokenizer.from_pretrained(\"/content/drive/MyDrive/model_722_bart_epoch_4\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/model_722_bart_epoch_4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V202KCcwoJKh",
        "outputId": "6c188d05-6842-48f3-ce73-2060e7ee2fa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(50265, 768, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.eval()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzyDFV9j3b0R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def generate_text_with_beams(prompt, num_texts=5, temperature=1.0, top_k=50, top_p=0.95, min_length=50, max_length=320, num_beams=5, no_repeat_ngram_size=2, early_stopping=True, seed=42, repetition_penalty=1.5):\n",
        "    if seed is not None:\n",
        "        set_seeds(seed)\n",
        "    model.eval()\n",
        "    generated_texts = []\n",
        "    for _ in range(num_texts):\n",
        "        input_ids = tokenizer.encode(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            min_length=min_length,\n",
        "            max_length=max_length,\n",
        "            num_beams=num_beams,\n",
        "            num_return_sequences=1,  # Generate one sequence at a time to ensure diversity\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "            repetition_penalty=repetition_penalty,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            early_stopping=early_stopping\n",
        "        )\n",
        "\n",
        "        text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        generated_texts.append(text)\n",
        "\n",
        "    return generated_texts\n",
        "\n",
        "def generate_text(top_p, top_k, temperature, num_beams=5, num_texts=20, seed=42, repetition_penalty=1.2):\n",
        "    prompts = [\"Write a World News\", \"Write a Sports News\", \"Write a Business News\", \"Write a Science/Technology News\"]\n",
        "    all_prompts = []\n",
        "    all_texts = []\n",
        "\n",
        "    for prompt in prompts:\n",
        "        generated_texts_for_prompt = []\n",
        "        num_iterations = num_texts // num_beams\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "            set_seeds(seed + i)\n",
        "            generated_texts = generate_text_with_beams(\n",
        "                prompt=prompt,\n",
        "                num_texts=num_beams,\n",
        "                temperature=temperature,\n",
        "                top_k=top_k,\n",
        "                top_p=top_p,\n",
        "                min_length=50,\n",
        "                max_length=200,  # Adjust max_length as needed\n",
        "                num_beams=num_beams,\n",
        "                no_repeat_ngram_size=2,\n",
        "                early_stopping=True,  # Enable early stopping\n",
        "                seed=seed + i,  # Adjust seed for each batch to maintain diversity while being reproducible\n",
        "                repetition_penalty=repetition_penalty  # Adding repetition penalty\n",
        "            )\n",
        "            generated_texts_for_prompt.extend(generated_texts)\n",
        "\n",
        "        # Ensure uniqueness and limit to the desired number of texts\n",
        "        unique_texts = list(set(generated_texts_for_prompt))[:num_texts]\n",
        "        all_prompts.extend([prompt] * len(unique_texts))\n",
        "        all_texts.extend(unique_texts)\n",
        "\n",
        "    return pd.DataFrame({'prompt': all_prompts, 'text': all_texts})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orDnX4AcOST9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=320):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.targets = dataframe.label\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpVXvmINOX_V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import jaccard_score\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate Jaccard Similarity between two texts\n",
        "def jaccard_similarity(text1, text2):\n",
        "    set1 = set(text1.split())\n",
        "    set2 = set(text2.split())\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union) if len(union) > 0 else 0\n",
        "\n",
        "# Function to calculate mean Jaccard similarity within each class\n",
        "def calculate_self_jaccard_similarity(df):\n",
        "    results = {}\n",
        "    for label, group in df.groupby('label'):\n",
        "        jaccard_similarities = [jaccard_similarity(text1, text2) for text1, text2 in combinations(group['text'], 2)]\n",
        "        results[label] = np.mean(jaccard_similarities) if jaccard_similarities else 0\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scxneg2SOZcV"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load the tokenizer and model\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/planB/bert/BERT611_half_2')\n",
        "bert_model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/planB/bert/BERT611_half_2', num_labels=4)\n",
        "\n",
        "\n",
        "bert_model_test = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/planB/bert/BERT613_half_2', num_labels=4)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model.to(device)\n",
        "bert_model_test.to(device)\n",
        "\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "            logits = outputs.logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "            predictions.extend(np.argmax(logits, axis=1).flatten())\n",
        "            true_labels.extend(label_ids.flatten())\n",
        "\n",
        "    avg_accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    # Calculate accuracy for each class\n",
        "    class_accuracies = defaultdict(list)\n",
        "    for true, pred in zip(true_labels, predictions):\n",
        "        class_accuracies[true].append(pred == true)\n",
        "\n",
        "    class_accuracy_results = {label: np.mean(acc) for label, acc in class_accuracies.items()}\n",
        "\n",
        "    return avg_accuracy, class_accuracy_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT_p--7mOqWf",
        "outputId": "f0b3f008-db63-42ba-ee7f-340e7f032b4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.10.1 sacrebleu-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sacrebleu\n",
        "\n",
        "def calculate_self_bleu(texts):\n",
        "    scores = []\n",
        "    for i, target in enumerate(texts):\n",
        "        references = texts[:i] + texts[i+1:]\n",
        "        bleu_score = sacrebleu.corpus_bleu([target], [references]).score\n",
        "        scores.append(bleu_score)\n",
        "    return np.mean(scores)\n",
        "\n",
        "def calculate_self_bleu_per_class(df):\n",
        "    class_bleu_scores = {}\n",
        "    for label, group in df.groupby('label'):\n",
        "        texts = group['text'].tolist()\n",
        "        self_bleu_score = calculate_self_bleu(texts)\n",
        "        class_bleu_scores[label] = self_bleu_score\n",
        "    return class_bleu_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNQtpbPrlbb3"
      },
      "outputs": [],
      "source": [
        "label_map2 = {\"Write a World News\":0, \"Write a Sports News\":1, \"Write a Business News\":2, \"Write a Science/Technology News\":3}\n",
        "# label_map2 = {\"World News\":0, \"Sport News\":1, \"Business News\":2, \"Science/Technology News\":3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "MbGRUD69M23C",
        "outputId": "5acb4b59-bff4-4490-d509-134ae0149db1"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-34af73f7f0c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m611\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-84addca36611>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(top_p, top_k, temperature, num_beams, num_texts, seed, repetition_penalty)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mset_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             generated_texts = generate_text_with_beams(\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mnum_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-84addca36611>\u001b[0m in \u001b[0;36mgenerate_text_with_beams\u001b[0;34m(prompt, num_texts, temperature, top_k, top_p, min_length, max_length, num_beams, no_repeat_ngram_size, early_stopping, seed, repetition_penalty)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         outputs = model.generate(\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   1954\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unchanged original behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m                 outputs = self(\n\u001b[0m\u001b[1;32m   2915\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m                     \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 )\n\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1748\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1634\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                 )\n\u001b[1;32m   1485\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1487\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;31m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    773\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;31m# reuse k, v, self_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36m_shape\u001b[0;34m(self, tensor, seq_len, bsz)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     def forward(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "df_text = generate_text(top_p=0.95, top_k=50, temperature=1.3, num_beams=4 , num_texts=10, repetition_penalty=1,seed=611)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FOCHHuscM7Ho",
        "outputId": "dd4ad784-bc90-45cd-cb4e-4b812d730659"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Iraqi troops in Iraq Kill At Least 39 Suspects Reuters Reuters - Iraqi troops killed at least 39 suspected militants in a raid on a military base in northern Iraq, officials said on Friday, adding that the militants had been killed and 39 wounded.',\n",
              " 'Pakistan suspends military action in Kashmir  AP AP - Pakistan has suspended military operations in the Kashmir valley as part of an effort to restore peace to the region, a senior Pakistani military official said on Saturday. The military said the decision was made in response to a report from the UN Security Council.',\n",
              " 'Pakistani Journalists Killed in Afghanistan Reuters - Pakistani Journalists were killed in a helicopter crash near the border with Afghanistan on Saturday, killing at least three people and wounding dozens, police said. The military said the bodies were recovered from the wreckage of the helicopter.',\n",
              " 'U.S. troops in Iraq, Afghanistan Reuters - The US military said on Friday it had made an initial military deployment of troops to Iraq and Afghanistan, as part of an effort to end hostilities in the region, to ensure a peaceful end to the conflict.',\n",
              " 'Nigeria 39s leader says he will resign as president of the Federation of African Nations in the wake of an alleged coup plot in 2004, but he said he would not leave office until he was fully ready to take charge. He said the decision was made by the government.',\n",
              " 'U.S. Air Force Bomb Kills 2 in Iraq AP AP - The US military said on Friday it killed three soldiers and wounded two others in a bombing raid in northern Iraq, killing at least two people and wounding more than 100 others.',\n",
              " 'N. Korea to Sell Nuclear Equipment The UN says it will sell nuclear technology to South Korea and Japan, but will not sell it to the South Korean government, in exchange for a smaller share of the US economy. A senior UN official says the decision will be made before the end of September.',\n",
              " 'US Secretary of State for Defense John Kerry will announce his decision on the fate of US troops stationed in Iraq and Afghanistan, the State Department said Monday. Kerry, Kerry and Kerry have agreed to meet with the US military to discuss the situation.',\n",
              " 'Tiger Woods, Matt Lauer Lead Eagles in AP AP - Tiger Woods led the Eagles to a 10-0 win over the Chicago Cubs on Saturday, extending their winning streak to 11 games in a row. Woods had a game-high five strikeouts in the first quarter, but was hampered by injuries and a broken ankle.',\n",
              " 'Spartans win 1-0 at Wrigley Field AP AP - The St. Louis Cardinals have won one of their first two games of the season, beating the New York Yankees 6-1 in the first half to reach the quarterfinals.',\n",
              " 'Dodgers 39, Padres 39 AP AP - The Miami Dolphins have beaten the Houston Astros 39-36 in the last two weeks to reach the quarterfinals of the American League Championship Series. After a three-game losing streak, they are one win away from becoming the first American team to qualify for the postseason.',\n",
              " 'Crawford, Red Sox Win in Four  AP AP - The Chicago Cubs beat the Detroit Pistons 4-1 in the fourth round of the American League Championship Series on Saturday night to take a two-game lead in series-clinching AL East.',\n",
              " 'Tiger Woods wins third straight Olympic title  AP AP - Tiger Woods won his third Olympic gold medal in four years on Sunday, becoming the first American to win three Olympic titles in a row. Woods finished with five gold medals, one short of his all-time record.',\n",
              " 'Spartans play for first time in 39 years LONDON Reuters - The South American soccer team is expected to play its first game of the new millennium in London on Saturday, when they take on the United States in the Champions League semifinals.',\n",
              " 'Staying in Touch With the Patriots The Patriots have beaten the Philadelphia Eagles, 39-31, in the American Football League opener for the first time this season. And it was all because of the Eagles. The Eagles are on a roll.',\n",
              " 'Bosnia beats Serbia to reach World Cup semifinals  Reuters - Bosnia and Herzegovina will reach the semifinals for the first time since the end of the 1998-99 season, the International Olympic Committee said on Wednesday. The tournament is expected to take place on Saturday.',\n",
              " 'Dollar Weakens on U.S. Economy The dollar fell against the euro on Wednesday as investors took profits from a holiday in the United States and Europe, while the dollar rose for the first time in three months. The yen fell for a second straight session  ',\n",
              " 'Fannie Mae, Freddie Mac Profit Declar on Weak U.S. Economy The Federal Reserve on Thursday said it was raising interest rates for its third quarter, a sign that the economy is inching toward full strength, but the outlook for the rest of the year remains bleak.',\n",
              " 'U.S. Retailers Focus on Holiday Sales The retail sector is expected to see a surge in holiday sales this year, driven by the strong holiday shopping season, the Federal Reserve said on Thursday. The Fed said it would lift its short-term interest rate by 25 basis points, but would not give a specific timeframe for when that rate will be lifted.',\n",
              " 'Wal-Mart to Sell Stores in US Stores  NEW YORK Reuters - Walmart Inc. said on Friday it would sell stores in the United States in an effort to keep up with demand for its stores, even though the retailer said it had no plans to sell any of its U.S. stores.',\n",
              " 'Dollar surges on U.S. tax bill  NEW YORK Reuters - The dollar rose against the euro on Thursday, extending its recent gains against a key European currency, helped by a strong dollar and a surge in interest rates on the yen.',\n",
              " 'U.S. stocks fall on Wall Street US stocks fell on Friday on worries about the outlook for global economic growth and a surge in oil prices, but analysts said the weakness was mainly due to the strength of the dollar and concerns about slowing growth in China.',\n",
              " 'U.S. Small Business Growth Stocks Gain  NEW YORK Reuters - The US economy grew  unexpectedly in the fourth quarter, with job growth accelerating  but the unemployment rate hovering near a four-year low, a survey showed Thursday.',\n",
              " 'BHP Billiton to Sell US Marijuana Business Reuters - The U.S. Bank for International Business Machines Corp. said on Friday it would sell US-style marijuana businesses in a bid to boost its Canadian market share by at least 20 percent in the fourth quarter.',\n",
              " 'Boeing to Sell Mobile Phone Service The maker of wireless phone service is planning to sell the service to wireless carrier Sprint, the company said on Tuesday. The company says the carrier will sell its mobile phone services in the next few months.',\n",
              " 'Nokia 39s Vodafone 1.1.0 is available for download on the App Store, according to the company. The company has said it is ready to offer the software for free on its  mobile devices, but would be willing to pay a small fee.',\n",
              " 'Microsoft launches Windows 10, OS X and Linux Operating Systems. The company has launched the Windows XP operating system, which is designed to support the desktop and mobile operating systems. Microsoft has begun beta testing the system on Windows PCs, the company said on Wednesday.',\n",
              " 'Cisco Launches Mobile Phone App  NEW YORK Reuters - Cisco Systems has launched a mobile phone app for the home phone market  with the goal of offering users the ability to call their friends and relatives for free on the phone, according to a new report.',\n",
              " 'Microsoft Rolls Out Linux-based Linux Solution Microsoft Corp. is rolling out a new version of the Linux operating system, which allows users to create their own personal Linux desktop environment. The company said it has launched the software version in the U.S. and Europe for the first time.',\n",
              " 'Mozilla Launches Mobile Phone Service Mozilla 39s mobile phone service is rolling out in the next few weeks, allowing users to connect with one another without having to pay a monthly fee. The service, which Mozilla says is free, is designed to help users connect to their phone.',\n",
              " 'Microsoft, Google Partner on Web Services Microsoft Corp. and Google Inc. have agreed to work on a web services package for Web services that will be available to anyone who wants to use the Internet, according to a joint statement from the companies.',\n",
              " 'Dartificial intelligence is a key part of the battle against the threat of computer viruses, researchers said Tuesday. The threat came from a threat that could spread to the Internet, which some experts say could kill the internet entirely, they said.']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_text.text.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCrQFf7aVjRY",
        "outputId": "d6133eb3-3234-4f27-c2a5-d0a13c816792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "top_k: 53\n",
            "bert accuracy: (0.96, {1: 0.9900990099009901, 3: 0.9411764705882353, 0: 0.9578947368421052, 2: 0.9509803921568627})\n",
            "Jaccard similarities: {0: 0.1546937782671968, 1: 0.12329236104122708, 2: 0.1357759885645806, 3: 0.10681470354254556}\n",
            "Self-BLEU: {0: 5.539936406049439, 1: 2.3601559338398683, 2: 6.301246408694692, 3: 2.9587081236278174}\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "  dataset = TextDataset(dataframe=df_BART, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=8, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  bert_acc_ag = evaluate(bert_model_ag, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  print(f\"top_k: {k}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")\n",
        "  '''\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6RYFGjFwfio",
        "outputId": "85f8468b-5fc2-4bb0-fcee-361a0f4e9538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "top_k: 47\n",
            "bert accuracy: (0.985, {0: 0.98, 1: 1.0, 2: 0.98, 3: 0.98})\n",
            "bert accuracy test: (0.9775, {0: 0.97, 1: 1.0, 2: 0.98, 3: 0.96})\n",
            "Jaccard similarities: {0: 0.14067809893271552, 1: 0.14401190533520303, 2: 0.16369632454867825, 3: 0.17209882496834944}\n",
            "Self-BLEU: {0: 4.131965716311886, 1: 4.623346079613982, 2: 11.378262467280184, 3: 6.129949725486852}\n",
            "top_k: 50\n",
            "bert accuracy: (0.975, {0: 0.97, 1: 0.99, 2: 0.97, 3: 0.97})\n",
            "bert accuracy test: (0.975, {0: 0.97, 1: 0.99, 2: 0.98, 3: 0.96})\n",
            "Jaccard similarities: {0: 0.13497639999035846, 1: 0.1416439360858013, 2: 0.1742633315104432, 3: 0.1686567306459168}\n",
            "Self-BLEU: {0: 2.3459336058584994, 1: 4.2850660619368375, 2: 12.244161065330607, 3: 5.579620159495602}\n",
            "top_k: 53\n",
            "bert accuracy: (0.9825, {0: 0.99, 1: 1.0, 2: 0.98, 3: 0.96})\n",
            "bert accuracy test: (0.985, {0: 0.99, 1: 1.0, 2: 0.99, 3: 0.96})\n",
            "Jaccard similarities: {0: 0.13677639351999893, 1: 0.14227985594404347, 2: 0.16424890461723762, 3: 0.16362226705529348}\n",
            "Self-BLEU: {0: 3.514322150376501, 1: 4.389581097582931, 2: 8.61544575090022, 3: 4.486998739802661}\n",
            "top_k: 55\n",
            "bert accuracy: (0.975, {0: 1.0, 1: 0.99, 2: 0.95, 3: 0.96})\n",
            "bert accuracy test: (0.97, {0: 1.0, 1: 0.99, 2: 0.96, 3: 0.93})\n",
            "Jaccard similarities: {0: 0.142240764377215, 1: 0.145901702524962, 2: 0.16505825810261177, 3: 0.16736857597440505}\n",
            "Self-BLEU: {0: 5.114569388579061, 1: 5.070760254146347, 2: 11.696120653213686, 3: 3.5329663984152564}\n"
          ]
        }
      ],
      "source": [
        "for k in [47,50,53,55]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=k, temperature=1.3, num_beams=4 , num_texts=100, repetition_penalty=1.7,seed=611)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  bert_acc_test = evaluate(bert_model_test, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  print(f\"top_k: {k}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"bert accuracy test: {bert_acc_test}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VVlSDFDoKQT",
        "outputId": "a0aa381e-49ed-4b3b-cc63-a82a230b85ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "top_k: 47\n",
            "bert accuracy: (0.9775, {0: 0.98, 1: 0.98, 2: 0.99, 3: 0.96})\n",
            "bert accuracy test: (0.9775, {0: 0.98, 1: 0.98, 2: 0.99, 3: 0.96})\n",
            "Jaccard similarities: {0: 0.14767446853242291, 1: 0.14051381836245597, 2: 0.15316019859630012, 3: 0.15512926154121254}\n",
            "Self-BLEU: {0: 2.4658698937674193, 1: 5.543504553618494, 2: 4.847317171514992, 3: 4.349677943518833}\n",
            "top_k: 50\n",
            "bert accuracy: (0.9975, {0: 0.99, 1: 1.0, 2: 1.0, 3: 1.0})\n",
            "bert accuracy test: (0.9875, {0: 0.99, 1: 0.99, 2: 0.97, 3: 1.0})\n",
            "Jaccard similarities: {0: 0.1521805463826348, 1: 0.1385159116259844, 2: 0.15683318223982703, 3: 0.1584736139743345}\n",
            "Self-BLEU: {0: 8.76729684820211, 1: 3.8357909175220084, 2: 5.928027277612154, 3: 5.829476614814385}\n",
            "top_k: 53\n",
            "bert accuracy: (0.9875, {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.95})\n",
            "bert accuracy test: (0.985, {0: 1.0, 1: 0.99, 2: 1.0, 3: 0.95})\n",
            "Jaccard similarities: {0: 0.15440322092434722, 1: 0.1503552948935853, 2: 0.15162540572529487, 3: 0.15903208018695053}\n",
            "Self-BLEU: {0: 6.193909863424978, 1: 6.537117078025169, 2: 9.80857868043172, 3: 3.8355151595532364}\n",
            "top_k: 55\n",
            "bert accuracy: (0.99, {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.96})\n",
            "bert accuracy test: (0.9875, {0: 1.0, 1: 0.99, 2: 1.0, 3: 0.96})\n",
            "Jaccard similarities: {0: 0.14011852316025591, 1: 0.1431429188994109, 2: 0.1523677192866677, 3: 0.16134859576405675}\n",
            "Self-BLEU: {0: 5.869858275716752, 1: 3.837137081611297, 2: 10.377270707646511, 3: 4.275106655618746}\n"
          ]
        }
      ],
      "source": [
        "for k in [47,50,53,55]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=k, temperature=1.3, num_beams=4 , num_texts=100, repetition_penalty=1.7,seed=611)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  bert_acc_test = evaluate(bert_model_test, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  print(f\"top_k: {k}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"bert accuracy test: {bert_acc_test}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io2D0KeiFmBb",
        "outputId": "effb66c9-b7aa-483c-ccd2-a82623f3b77b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "temp: 1.2\n",
            "bert accuracy: (0.9775, {0: 0.98, 1: 1.0, 2: 0.99, 3: 0.94})\n",
            "bert accuracy test: (0.975, {0: 0.99, 1: 1.0, 2: 0.99, 3: 0.92})\n",
            "Jaccard similarities: {0: 0.1535967301500334, 1: 0.14290038251828768, 2: 0.1536245452585003, 3: 0.15541633547501504}\n",
            "Self-BLEU: {0: 5.4452125559338755, 1: 5.619466506347688, 2: 7.604275243694099, 3: 8.456351037922772}\n",
            "temp: 1.4\n",
            "bert accuracy: (0.9825, {0: 0.98, 1: 1.0, 2: 0.97, 3: 0.98})\n",
            "bert accuracy test: (0.975, {0: 0.98, 1: 1.0, 2: 0.95, 3: 0.97})\n",
            "Jaccard similarities: {0: 0.13670405511274863, 1: 0.12527183089103627, 2: 0.13330846517434275, 3: 0.1469298341837145}\n",
            "Self-BLEU: {0: 3.7210924983341114, 1: 5.74634037433728, 2: 2.924648080452917, 3: 8.270848019494315}\n",
            "temp: 1.5\n",
            "bert accuracy: (0.995, {0: 0.99, 1: 1.0, 2: 1.0, 3: 0.99})\n",
            "bert accuracy test: (0.99, {0: 1.0, 1: 1.0, 2: 0.99, 3: 0.97})\n",
            "Jaccard similarities: {0: 0.14728521874484718, 1: 0.13133402208072784, 2: 0.14607243283313287, 3: 0.13344427170111628}\n",
            "Self-BLEU: {0: 4.49005701488763, 1: 5.385326956943405, 2: 3.104003635251329, 3: 4.353332472155132}\n",
            "temp: 1.6\n",
            "bert accuracy: (0.985, {0: 0.99, 1: 0.99, 2: 0.99, 3: 0.97})\n",
            "bert accuracy test: (0.985, {0: 0.99, 1: 0.99, 2: 0.99, 3: 0.97})\n",
            "Jaccard similarities: {0: 0.1362164035853664, 1: 0.12670700071224303, 2: 0.12602182720078947, 3: 0.12509124144502398}\n",
            "Self-BLEU: {0: 3.152347131174997, 1: 3.8717334545814825, 2: 2.3763348781015177, 3: 3.205036852366118}\n"
          ]
        }
      ],
      "source": [
        "for t in [1.2,1.4,1.5,1.6]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=50, temperature=t, num_beams=4 , num_texts=100, repetition_penalty=1,seed=611)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  bert_acc_test = evaluate(bert_model_test, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  print(f\"temp: {t}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"bert accuracy test: {bert_acc_test}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "OvLLHws4KO1P",
        "outputId": "15038c53-6474-471b-baeb-1a8710b99e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "temp: 1.2\n",
            "bert accuracy: (0.99, {0: 0.99, 1: 1.0, 2: 1.0, 3: 0.97})\n",
            "bert accuracy test: (0.9925, {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.97})\n",
            "Jaccard similarities: {0: 0.16692469495680134, 1: 0.14255364179542554, 2: 0.16962849725828444, 3: 0.16892443053992204}\n",
            "Self-BLEU: {0: 7.694385121300005, 1: 4.101871484633133, 2: 10.240818888516358, 3: 4.302335119658982}\n",
            "temp: 1.4\n",
            "bert accuracy: (0.98, {0: 0.99, 1: 1.0, 2: 1.0, 3: 0.93})\n",
            "bert accuracy test: (0.9775, {0: 0.99, 1: 1.0, 2: 1.0, 3: 0.92})\n",
            "Jaccard similarities: {0: 0.1455908403254702, 1: 0.13370877565836686, 2: 0.1415974253889051, 3: 0.15460546763326138}\n",
            "Self-BLEU: {0: 3.9533197662363206, 1: 4.298911077510723, 2: 3.307725955786069, 3: 5.731214337494558}\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-a45bf3e6eb23>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdf_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m611\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mdf_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prompt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbert_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-84addca36611>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(top_p, top_k, temperature, num_beams, num_texts, seed, repetition_penalty)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mset_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             generated_texts = generate_text_with_beams(\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mnum_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-84addca36611>\u001b[0m in \u001b[0;36mgenerate_text_with_beams\u001b[0;34m(prompt, num_texts, temperature, top_k, top_p, min_length, max_length, num_beams, no_repeat_ngram_size, early_stopping, seed, repetition_penalty)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         outputs = model.generate(\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   1954\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m             \u001b[0;31m# stateless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2981\u001b[0;31m             beam_outputs = beam_scorer.process(\n\u001b[0m\u001b[1;32m   2982\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m                 \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/beam_search.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id, beam_indices, group_index, decoder_prompt_len)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mbatch_beam_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnext_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;31m# add to generated hypotheses if end of sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meos_token_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnext_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                     \u001b[0;31m# if beam_token does not belong to top num_beams tokens, it should not be added\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0mis_beam_token_worse_than_top_num_beams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_token_rank\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for t in [1.2,1.4,1.5,1.6]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=50, temperature=t, num_beams=4 , num_texts=100, repetition_penalty=1.7,seed=611)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  bert_acc_test = evaluate(bert_model_test, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  print(f\"temp: {t}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"bert accuracy test: {bert_acc_test}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqk6QqJwPdvL",
        "outputId": "9e095ec9-70ff-496c-9686-be18cb3566ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "temp: 1.2\n",
            "bert accuracy: (0.98, {0: 0.96, 1: 1.0, 2: 0.99, 3: 0.97})\n",
            "bert accuracy test: (0.9725, {0: 0.98, 1: 0.99, 2: 0.95, 3: 0.97})\n",
            "Jaccard similarities: {0: 0.15641776862493517, 1: 0.13762651268851406, 2: 0.14942832080177632, 3: 0.17096600377332957}\n",
            "Self-BLEU: {0: 3.6973724694662113, 1: 5.510478748692128, 2: 5.282894727860917, 3: 6.148517202395925}\n",
            "temp: 1.4\n",
            "bert accuracy: (0.99, {0: 0.99, 1: 1.0, 2: 1.0, 3: 0.97})\n",
            "bert accuracy test: (0.9825, {0: 0.99, 1: 1.0, 2: 0.99, 3: 0.95})\n",
            "Jaccard similarities: {0: 0.1549490423853397, 1: 0.13609098478029463, 2: 0.13867162824248058, 3: 0.1565163668826492}\n",
            "Self-BLEU: {0: 3.700804454163212, 1: 4.848572425849049, 2: 8.176757883651408, 3: 4.162351425753526}\n",
            "temp: 1.5\n",
            "bert accuracy: (0.9825, {0: 0.99, 1: 1.0, 2: 0.97, 3: 0.97})\n",
            "bert accuracy test: (0.9775, {0: 0.99, 1: 1.0, 2: 0.96, 3: 0.96})\n",
            "Jaccard similarities: {0: 0.13763309906493776, 1: 0.13379551786827815, 2: 0.1419002132679115, 3: 0.14626787246502562}\n",
            "Self-BLEU: {0: 3.541654337458682, 1: 3.472930274458655, 2: 3.0158366981498728, 3: 2.4795049805022247}\n",
            "temp: 1.6\n",
            "bert accuracy: (0.98, {0: 0.97, 1: 1.0, 2: 0.98, 3: 0.97})\n",
            "bert accuracy test: (0.98, {0: 0.98, 1: 1.0, 2: 0.96, 3: 0.98})\n",
            "Jaccard similarities: {0: 0.12962396931215567, 1: 0.12766931258476977, 2: 0.1364675884865112, 3: 0.13938729727849428}\n",
            "Self-BLEU: {0: 4.653414817200922, 1: 2.8500344101381847, 2: 5.480902203629403, 3: 3.000604560539965}\n"
          ]
        }
      ],
      "source": [
        "for t in [1.2,1.4,1.5,1.6]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=55, temperature=t, num_beams=4 , num_texts=100, repetition_penalty=1.7,seed=611)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=320)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  bert_acc_test = evaluate(bert_model_test, loader)\n",
        "  js = calculate_self_jaccard_similarity(df_text)\n",
        "  sb = calculate_self_bleu_per_class(df_text)\n",
        "  print(f\"temp: {t}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"bert accuracy test: {bert_acc_test}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjJ6o3tVaTso"
      },
      "outputs": [],
      "source": [
        "df_text0 = generate_text(top_p=0.95, top_k=50, temperature=1.3, num_beams=4 , num_texts=600, repetition_penalty=1.7,seed=611)\n",
        "df_text0['label'] = df_text0['prompt'].map(label_map2)\n",
        "df_text0.to_csv(\"/content/drive/MyDrive/planB/df_generated_bartall_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfJJg4hfQGBK"
      },
      "outputs": [],
      "source": [
        "df_text0 = generate_text(top_p=0.95, top_k=55, temperature=1.3, num_beams=4 , num_texts=600, repetition_penalty=1.7,seed=611)\n",
        "df_text0['label'] = df_text0['prompt'].map(label_map2)\n",
        "df_text0.to_csv(\"/content/drive/MyDrive/planB/df_generated_bartall_0.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDMuroJyQROU"
      },
      "outputs": [],
      "source": [
        "df_text0 = generate_text(top_p=0.95, top_k=55, temperature=1.6, num_beams=4 , num_texts=600, repetition_penalty=1,seed=611)\n",
        "df_text0['label'] = df_text0['prompt'].map(label_map2)\n",
        "df_text0.to_csv(\"/content/drive/MyDrive/planB/df_generated_bartall_2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMZb0I5ukujv",
        "outputId": "41496cdb-068e-40ce-9537-799c98524778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert accuracy: (0.9775, {0: 0.9883333333333333, 1: 0.995, 2: 0.9783333333333334, 3: 0.9483333333333334})\n",
            "bert accuracy test: (0.97375, {0: 0.99, 1: 0.9916666666666667, 2: 0.9716666666666667, 3: 0.9416666666666667})\n",
            "Jaccard similarities: {0: 0.12852174870001049, 1: 0.12118574728904863, 2: 0.12630426061016808, 3: 0.12701263847992897}\n",
            "Self-BLEU: {0: 1.6222599773364461, 1: 3.3259993130776806, 2: 6.913054882490829, 3: 3.602974141980892}\n"
          ]
        }
      ],
      "source": [
        "## all 2\n",
        "dataset = TextDataset(dataframe=df_text0, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "bert_acc_test = evaluate(bert_model_test, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text0)\n",
        "sb = calculate_self_bleu_per_class(df_text0)\n",
        "\n",
        "print(f\"bert accuracy: {bert_acc}\")\n",
        "print(f\"bert accuracy test: {bert_acc_test}\")\n",
        "print(f\"Jaccard similarities: {js}\")\n",
        "print(f\"Self-BLEU: {sb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZuTs7EFkq6D",
        "outputId": "0deaf386-8b73-4426-ffe7-b9a49f08df65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert accuracy: (0.9866666666666667, {0: 0.9866666666666667, 1: 0.9966666666666667, 2: 0.9916666666666667, 3: 0.9716666666666667})\n",
            "bert accuracy test: (0.9845833333333334, {0: 0.9933333333333333, 1: 0.9933333333333333, 2: 0.9816666666666667, 3: 0.97})\n",
            "Jaccard similarities: {0: 0.15792642113542213, 1: 0.1430546126739633, 2: 0.1541496428375523, 3: 0.1617372274052592}\n",
            "Self-BLEU: {0: 6.640209666101523, 1: 5.3373389182610635, 2: 6.38432482999989, 3: 4.705580714887631}\n"
          ]
        }
      ],
      "source": [
        "## all 1\n",
        "dataset = TextDataset(dataframe=df_text0, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "bert_acc_test = evaluate(bert_model_test, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text0)\n",
        "sb = calculate_self_bleu_per_class(df_text0)\n",
        "\n",
        "print(f\"bert accuracy: {bert_acc}\")\n",
        "print(f\"bert accuracy test: {bert_acc_test}\")\n",
        "print(f\"Jaccard similarities: {js}\")\n",
        "print(f\"Self-BLEU: {sb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRAIlF8ovdHf",
        "outputId": "4c4b5707-d3c9-4617-db24-514833782128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert accuracy: (0.9845833333333334, {0: 0.99, 1: 0.9966666666666667, 2: 0.995, 3: 0.9566666666666667})\n",
            "bert accuracy test: (0.9829166666666667, {0: 0.995, 1: 0.9866666666666667, 2: 0.985, 3: 0.965})\n",
            "Jaccard similarities: {0: 0.15050207066069718, 1: 0.140960365250401, 2: 0.15147204123493685, 3: 0.1570379000011103}\n",
            "Self-BLEU: {0: 5.6813036315698335, 1: 4.333808496890731, 2: 11.426461986735081, 3: 6.113334556653601}\n"
          ]
        }
      ],
      "source": [
        "## all 0\n",
        "dataset = TextDataset(dataframe=df_text0, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "bert_acc_test = evaluate(bert_model_test, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text0)\n",
        "sb = calculate_self_bleu_per_class(df_text0)\n",
        "\n",
        "print(f\"bert accuracy: {bert_acc}\")\n",
        "print(f\"bert accuracy test: {bert_acc_test}\")\n",
        "print(f\"Jaccard similarities: {js}\")\n",
        "print(f\"Self-BLEU: {sb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hq5w5lnJtr_V"
      },
      "outputs": [],
      "source": [
        "df_text0 = generate_text(top_p=0.95, top_k=55, temperature=1.3, num_beams=4 , num_texts=600, repetition_penalty=1.7,seed=611)\n",
        "df_text0['label'] = df_text0['prompt'].map(label_map2)\n",
        "df_text0.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart300_2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rA2nJ7Qjtwr_"
      },
      "outputs": [],
      "source": [
        "df_text0 = generate_text(top_p=0.95, top_k=55, temperature=1.3, num_beams=4 , num_texts=600, repetition_penalty=1.9,seed=611)\n",
        "df_text0['label'] = df_text0['prompt'].map(label_map2)\n",
        "df_text0.to_csv(\"/content/drive/MyDrive/planB/df_generated_bart300_3.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFE8DFOkk88E"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBfPfw8NzSE8"
      },
      "outputs": [],
      "source": [
        "df_text0=pd.read_csv(\"/content/drive/MyDrive/planB/df_generated_bart300_0.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJXZObQU3A7B",
        "outputId": "0014353a-0271-48d2-c371-e48e50fd9fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert accuracy: (0.9816666666666667, {0: 0.99, 1: 0.9916666666666667, 2: 0.98, 3: 0.965})\n",
            "bert accuracy test: (0.9770833333333333, {0: 0.99, 1: 0.9883333333333333, 2: 0.9633333333333334, 3: 0.9666666666666667})\n",
            "Jaccard similarities: {0: 0.141587262913951, 1: 0.12340321118667312, 2: 0.1515325593266859, 3: 0.17569754554733163}\n",
            "Self-BLEU: {0: 2.5195661219666476, 1: 6.129392816229647, 2: 9.507321405085314, 3: 8.557186187687437}\n"
          ]
        }
      ],
      "source": [
        "dataset = TextDataset(dataframe=df_text0, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "bert_acc_test = evaluate(bert_model_test, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text0)\n",
        "sb = calculate_self_bleu_per_class(df_text0)\n",
        "\n",
        "print(f\"bert accuracy: {bert_acc}\")\n",
        "print(f\"bert accuracy test: {bert_acc_test}\")\n",
        "print(f\"Jaccard similarities: {js}\")\n",
        "print(f\"Self-BLEU: {sb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Oarhq38zR_V",
        "outputId": "c2081f19-f3a7-4288-a09f-e933e064f7db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert accuracy: (0.9841666666666666, {0: 0.9966666666666667, 1: 0.9916666666666667, 2: 0.9833333333333333, 3: 0.965})\n",
            "bert accuracy test: (0.9779166666666667, {0: 0.995, 1: 0.9883333333333333, 2: 0.9683333333333334, 3: 0.96})\n",
            "Jaccard similarities: {0: 0.13586357238209182, 1: 0.11845386333304575, 2: 0.14952601976826219, 3: 0.1557771000804527}\n",
            "Self-BLEU: {0: 4.669816859370167, 1: 3.4167383927607844, 2: 4.234192052148225, 3: 2.695258355083081}\n"
          ]
        }
      ],
      "source": [
        "dataset = TextDataset(dataframe=df_text0, tokenizer=bert_tokenizer, max_len=320)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "bert_acc = evaluate(bert_model, loader)\n",
        "bert_acc_test = evaluate(bert_model_test, loader)\n",
        "js = calculate_self_jaccard_similarity(df_text0)\n",
        "sb = calculate_self_bleu_per_class(df_text0)\n",
        "\n",
        "print(f\"bert accuracy: {bert_acc}\")\n",
        "print(f\"bert accuracy test: {bert_acc_test}\")\n",
        "print(f\"Jaccard similarities: {js}\")\n",
        "print(f\"Self-BLEU: {sb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ejhbpbN3ga",
        "outputId": "18731aa2-f8f0-44b6-9819-d5317e306481"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pqL9OryuN9Si",
        "outputId": "1064cdf7-185a-4d89-8070-3a0b46470368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No 'widgets' metadata found.\n",
            "Notebook cleaned and saved.\n"
          ]
        }
      ],
      "source": [
        "import nbformat\n",
        "\n",
        "# Path to your notebook\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/BART_generate.ipynb'\n",
        "\n",
        "# Load notebook\n",
        "with open(path) as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "# Clean metadata\n",
        "if 'widgets' in nb['metadata']:\n",
        "    del nb['metadata']['widgets']\n",
        "    print(\"Removed 'widgets' metadata.\")\n",
        "else:\n",
        "    print(\"No 'widgets' metadata found.\")\n",
        "\n",
        "# Save the cleaned notebook (overwrite original)\n",
        "with open(path, 'w') as f:\n",
        "    nbformat.write(nb, f)\n",
        "\n",
        "print(\"Notebook cleaned and saved.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "v-E4kknUXL2D",
        "sm_a3dq9Vx9r",
        "SevC0tsTVsVl"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyN94iIvp5Lg1EWw7HFWn+ej",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}