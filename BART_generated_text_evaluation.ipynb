{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WangKun00293/bart-bert-project/blob/main/BART_generated_text_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDPb7Bgx-TVG",
        "outputId": "a0d74db1-85db-4f18-a301-5df024447aac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6ifc8eW-cwd"
      },
      "outputs": [],
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "tokenizer = BartTokenizer.from_pretrained(\"/content/drive/MyDrive/model_41_bart_epoch_6\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/model_41_bart_epoch_6\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adwmLp79-fQw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.eval()\n",
        "model.to(device)\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebR_Z3k0-38s"
      },
      "outputs": [],
      "source": [
        "def generate_text_with_beams(prompt, num_texts=5, temperature=1.0, top_k=50, top_p=0.95, min_length=50, max_length=200, num_beams=5, no_repeat_ngram_size=2):\n",
        "    model.eval()  # Ensure the model is in evaluation mode\n",
        "    generated_texts = []\n",
        "    for _ in range(num_texts):\n",
        "        # Encode the prompt and ensure it's on the correct device\n",
        "        input_ids = tokenizer.encode(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "        # Generate text using the model with specified hyperparameters\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            min_length=min_length,\n",
        "            max_length=max_length,\n",
        "            num_beams=num_beams,\n",
        "            num_return_sequences=1,  # Generate one sequence at a time to ensure diversity\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "            do_sample=True,  # Enable sampling even with num_beams for diversity\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        # Decode and add the generated text\n",
        "        text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        generated_texts.append(text)\n",
        "\n",
        "    return generated_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPb7RNHE-msM"
      },
      "outputs": [],
      "source": [
        "def generate_text(top_p, top_k, temperature, num_beams=5, num_texts=20):\n",
        "    prompts = [\"Write a World News\", \"Write a Sport News\", \"Write a Business News\", \"Write a Science/Technology News\"]\n",
        "    all_prompts = []\n",
        "    all_texts = []\n",
        "\n",
        "    for prompt in prompts:\n",
        "        generated_texts_for_prompt = []\n",
        "        num_iterations = num_texts // num_beams\n",
        "\n",
        "        for _ in range(num_iterations):\n",
        "            generated_texts = generate_text_with_beams(\n",
        "                prompt=prompt,\n",
        "                num_texts=num_beams,\n",
        "                temperature=temperature,\n",
        "                top_k=top_k,\n",
        "                top_p=top_p,\n",
        "                min_length=50,\n",
        "                max_length=200,\n",
        "                num_beams=num_beams,\n",
        "                no_repeat_ngram_size=2\n",
        "            )\n",
        "            generated_texts_for_prompt.extend(generated_texts)\n",
        "\n",
        "        # Ensure uniqueness and limit to the desired number of texts\n",
        "        unique_texts = list(set(generated_texts_for_prompt))[:num_texts]\n",
        "        all_prompts.extend([prompt] * len(unique_texts))\n",
        "        all_texts.extend(unique_texts)\n",
        "\n",
        "    return pd.DataFrame({'prompt': all_prompts, 'text': all_texts})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAgWfGAf_mXc",
        "outputId": "88e59ea1-4995-494c-c0b7-0e7fef1ce73f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.1-py3-none-any.whl (106 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m102.4/106.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu\n",
        "import pandas as pd\n",
        "from sklearn.metrics import jaccard_score\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "from nltk.util import ngrams\n",
        "import sacrebleu\n",
        "\n",
        "# Assuming df_generate is your DataFrame and 'text' is the column with your text data\n",
        "\n",
        "# Function to calculate Jaccard Similarity between two texts\n",
        "def jaccard_similarity(text1, text2):\n",
        "    set1 = set(text1.split())\n",
        "    set2 = set(text2.split())\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union) if len(union) > 0 else 0\n",
        "def jac_sim(df):\n",
        "  jaccard_similarities = [jaccard_similarity(text1, text2) for text1, text2 in combinations(df['text'], 2)]\n",
        "  return np.mean(jaccard_similarities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJuCf4b7_q4b"
      },
      "outputs": [],
      "source": [
        "def calculate_self_bleu(texts):\n",
        "    scores = []\n",
        "    for i, target in enumerate(texts):\n",
        "        references = texts[:i] + texts[i+1:]\n",
        "        bleu_score = sacrebleu.corpus_bleu([target], [references]).score\n",
        "        scores.append(bleu_score)\n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ssAnlw6BxvF"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/planB/bert/BERT402_epoch_8')\n",
        "bert_model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/planB/bert/BERT402_epoch_8', num_labels=4)\n",
        "bert_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr8KU0fyBsJ1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "            logits = outputs.logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "            predictions.extend(np.argmax(logits, axis=1).flatten())\n",
        "            true_labels.extend(label_ids.flatten())\n",
        "\n",
        "    avg_accuracy = accuracy_score(true_labels, predictions)\n",
        "    return avg_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9chIlZLXCdVM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.targets = dataframe.label\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdYSIgJUDDbs"
      },
      "outputs": [],
      "source": [
        "label_map2 = {\"Write a World News\":0, \"Write a Sport News\":1, \"Write a Business News\":2, \"Write a Science/Technology News\":3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98P_194r_IFt",
        "outputId": "6ed9cd76-ff24-4f30-fc85-84ada596e962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top_k: 30\n",
            "bert accuracy: 0.975\n",
            "Jaccard similarities: 0.11556402156160839\n",
            "Self-BLEU: 4.670611437286693\n",
            "top_k: 35\n",
            "bert accuracy: 0.9875\n",
            "Jaccard similarities: 0.11300647411542006\n",
            "Self-BLEU: 1.5987585476199417\n",
            "top_k: 40\n",
            "bert accuracy: 0.95\n",
            "Jaccard similarities: 0.1089032057190632\n",
            "Self-BLEU: 6.016486747472774\n",
            "top_k: 45\n",
            "bert accuracy: 0.95\n",
            "Jaccard similarities: 0.11288165675814596\n",
            "Self-BLEU: 1.573621752863128\n",
            "top_k: 50\n",
            "bert accuracy: 0.925\n",
            "Jaccard similarities: 0.10938293006051303\n",
            "Self-BLEU: 5.104405490910682\n"
          ]
        }
      ],
      "source": [
        "for k in [30,35,40,45,50]:\n",
        "  df_text = generate_text(top_p=0.95, top_k=k, temperature=1.2, num_beams=5, num_texts=20)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=200)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = jac_sim(df_text)\n",
        "  sb = calculate_self_bleu(df_text['text'].tolist())\n",
        "  print(f\"top_k: {k}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in [30,35,40,45,50]:\n",
        "  df_text = generate_text(top_p=0.9, top_k=k, temperature=1.2, num_beams=5, num_texts=20)\n",
        "  df_text['label'] = df_text['prompt'].map(label_map2)\n",
        "  dataset = TextDataset(dataframe=df_text, tokenizer=bert_tokenizer, max_len=200)\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "  bert_acc = evaluate(bert_model, loader)\n",
        "  js = jac_sim(df_text)\n",
        "  sb = calculate_self_bleu(df_text['text'].tolist())\n",
        "  print(f\"top_k: {k}\")\n",
        "  print(f\"bert accuracy: {bert_acc}\")\n",
        "  print(f\"Jaccard similarities: {js}\")\n",
        "  print(f\"Self-BLEU: {sb}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBHW2_N7NtiA",
        "outputId": "2338df42-913d-4edc-b16a-d16a09a58cfb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top_k: 30\n",
            "bert accuracy: 0.95\n",
            "Jaccard similarities: 0.11840843498377501\n",
            "Self-BLEU: 3.6100798168248467\n",
            "top_k: 35\n",
            "bert accuracy: 0.9375\n",
            "Jaccard similarities: 0.1081574646435496\n",
            "Self-BLEU: 3.9766781795788084\n",
            "top_k: 40\n",
            "bert accuracy: 0.925\n",
            "Jaccard similarities: 0.11306758988903559\n",
            "Self-BLEU: 2.9220130559379016\n",
            "top_k: 45\n",
            "bert accuracy: 0.9\n",
            "Jaccard similarities: 0.11283803651925471\n",
            "Self-BLEU: 2.292040146031241\n",
            "top_k: 50\n",
            "bert accuracy: 0.95\n",
            "Jaccard similarities: 0.10839751304980673\n",
            "Self-BLEU: 4.363161682245089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set temperature=1.2, top_k=35, top_p=0.95\n",
        "df_generated = generate_text(top_p=0.95, top_k=35, temperature=1.2, num_beams=5, num_texts=2000)\n",
        "df_generated.to_csv(\"/content/drive/MyDrive/planB/df_generated_all.csv\")"
      ],
      "metadata": {
        "id": "rhe7tm_ZYjsS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyPx+imkjHCOEk8DTrM5to",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}